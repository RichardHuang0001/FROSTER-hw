nohup: ignoring input
config files: ['configs/Kinetics/TemporalCLIP_vitb16_8x16_STAdapter_HMDB51.yaml']
[12/16 20:45:34][INFO] train_net.py:  942: --Train with config:
[12/16 20:45:34][INFO] train_net.py:  943: {'AUG': {'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': False,
         'GEN_MASK_LOADER': False,
         'INTERPOLATION': 'bicubic',
         'MASK_FRAMES': False,
         'MASK_RATIO': 0.0,
         'MASK_TUBE': False,
         'MASK_WINDOW_SIZE': [8, 7, 7],
         'MAX_MASK_PATCHES_PER_BLOCK': None,
         'NUM_SAMPLE': 1,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train_all.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'GLOBAL_SYNC': False,
        'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'CONTRASTIVE': {'BN_MLP': False,
                 'BN_SYNC_MLP': False,
                 'DELTA_CLIPS_MAX': inf,
                 'DELTA_CLIPS_MIN': -inf,
                 'DIM': 128,
                 'INTERP_MEMORY': False,
                 'KNN_ON': True,
                 'LENGTH': 239975,
                 'LOCAL_SHUFFLE_BN': True,
                 'MEM_TYPE': '1d',
                 'MLP_DIM': 2048,
                 'MOCO_MULTI_VIEW_QUEUE': False,
                 'MOMENTUM': 0.5,
                 'MOMENTUM_ANNEALING': False,
                 'NUM_CLASSES_DOWNSTREAM': 400,
                 'NUM_MLP_LAYERS': 1,
                 'PREDICTOR_DEPTHS': [],
                 'QUEUE_LEN': 65536,
                 'SEQUENTIAL': False,
                 'SIMCLR_DIST_ON': True,
                 'SWAV_QEUE_LEN': 0,
                 'T': 0.07,
                 'TYPE': 'mem'},
 'DATA': {'COLOR_RND_GRAYSCALE': 0.0,
          'DECODING_BACKEND': 'pyav',
          'DECODING_SHORT_SIZE': 256,
          'DUMMY_LOAD': False,
          'ENSEMBLE_METHOD': 'sum',
          'IN22K_TRAINVAL': False,
          'IN22k_VAL_IN1K': '',
          'INDEX_LABEL_MAPPING_FILE': '/mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/train_rephrased.json',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'IN_VAL_CROP_RATIO': 0.875,
          'LOADER_CHUNK_OVERALL_SIZE': 0,
          'LOADER_CHUNK_SIZE': 0,
          'MEAN': [0.48145466, 0.4578275, 0.40821073],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 8,
          'PATH_LABEL_SEPARATOR': ',',
          'PATH_PREFIX': '/mnt/SSD8T/home/huangwei/projects/FROSTER/data/hmdb51',
          'PATH_TO_DATA_DIR': '/mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb',
          'PATH_TO_PRELOAD_IMDB': '',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 16,
          'SKIP_ROWS': 0,
          'SSL_BLUR_SIGMA_MAX': [0.0, 2.0],
          'SSL_BLUR_SIGMA_MIN': [0.0, 0.1],
          'SSL_COLOR_BRI_CON_SAT': [0.4, 0.4, 0.4],
          'SSL_COLOR_HUE': 0.1,
          'SSL_COLOR_JITTER': False,
          'SSL_MOCOV2_AUG': False,
          'STD': [0.26862954, 0.26130258, 0.27577711],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TIME_DIFF_PROB': 0.0,
          'TRAIN_CROP_NUM_SPATIAL': 1,
          'TRAIN_CROP_NUM_TEMPORAL': 1,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [],
          'TRAIN_JITTER_FPS': 0.0,
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [224, 256],
          'TRAIN_JITTER_SCALES_RELATIVE': [],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': True},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'IMAGENET_SIMPLELABEL_PATH': None,
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MASK': {'DECODER_DEPTH': 0,
          'DECODER_EMBED_DIM': 512,
          'DECODER_SEP_POS_EMBED': False,
          'DEC_KV_KERNEL': [],
          'DEC_KV_STRIDE': [],
          'ENABLE': False,
          'HEAD_TYPE': 'separate',
          'MAE_ON': False,
          'MAE_RND_MASK': False,
          'NORM_PRED_PIXEL': True,
          'PER_FRAME_MASKING': False,
          'PRED_HOG': False,
          'PRETRAIN_DEPTH': [15],
          'SCALE_INIT_BY_DEPTH': False,
          'TIME_STRIDE_LOSS': True},
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': False,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ADAPT_FINETUNE_FACTOR': 1.0,
           'ARCH': 'vitb16',
           'CLS_LOSS_RATIO': 1.0,
           'CONTEXT_LENGTH': 77,
           'DEFAULT_FINETUNE_FACTOR': 1.0,
           'DETACH_FINAL_FC': False,
           'DISTILLATION_RATIO': 2.0,
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'ENSEMBLE_PRED': False,
           'ENSEMBLE_RAWMODEL_RATIO': 0.0,
           'EXPERT_FINETUNE_FACTOR': 1.0,
           'EXPERT_INSERT_LAYERS': [10, 11],
           'FC_INIT_STD': 0.01,
           'FINETUNE_FACTOR': 1.0,
           'FP16_ALLREDUCE': False,
           'FROZEN_BN': False,
           'HEAD_ACT': 'softmax',
           'KEEP_RAW_MODEL': True,
           'LOSS_FREQ_TYPE': 'mse',
           'LOSS_FUNC': 'soft_cross_entropy',
           'MLP_FINETUNE_FACTOR': 1.0,
           'MODEL_NAME': 'TemporalClipVideo',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 26,
           'NUM_EXPERTS': 0,
           'PROMPT_NUM': 1,
           'RAW_MODEL_DISTILLATION': True,
           'RECORD_ROUTING': False,
           'ROUTING_FINETUNE_FACTOR': 1.0,
           'ROUTING_FREQUENCE_CONSTRAIN': 0.5,
           'ROUTING_FREQ_CONS_FACTOR': 1.0,
           'ROUTING_TYPE': 'patch-level',
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'maskmvit',
                                   'vitb32',
                                   'vitb16',
                                   'vitl14'],
           'STATIC_GRAPH': False,
           'TEMPORAL_MODELING_TYPE': 'expand_temporal_view',
           'TEXT_PROMPT': False,
           'USE_CHECKPOINT': False},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 16,
          'DIM_MUL': [],
          'DIM_MUL_IN_ATT': False,
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.1,
          'EMBED_DIM': 96,
          'HEAD_INIT_SCALE': 1.0,
          'HEAD_MUL': [],
          'LAYER_SCALE_INIT_VALUE': 0.0,
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [2, 4, 4],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': None,
          'POOL_KV_STRIDE': [],
          'POOL_KV_STRIDE_ADAPTIVE': None,
          'POOL_Q_STRIDE': [],
          'QKV_BIAS': True,
          'REL_POS_SPATIAL': False,
          'REL_POS_TEMPORAL': False,
          'REL_POS_ZERO_INIT': False,
          'RESIDUAL_POOLING': False,
          'REV': {'BUFFER_LAYERS': [],
                  'ENABLE': False,
                  'PRE_Q_FUSION': 'avg',
                  'RESPATH_FUSE': 'concat',
                  'RES_PATH': 'conv'},
          'SEPARATE_QKV': False,
          'SEP_POS_EMBED': False,
          'USE_ABS_POS': True,
          'USE_FIXED_SINCOS_POS': False,
          'USE_MEAN_POOLING': False,
          'ZERO_DECAY_POS_CLS': True},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 8,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '/mnt/SSD8T/home/huangwei/projects/FROSTER/checkpoints/basetraining/B2N_hmdb51_froster_exp02',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False,
            'ZERO_INIT_FINAL_CONV': False},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 3.33e-06,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'BETAS': (0.9, 0.999),
            'CLIP_GRAD_L2NORM': 1.0,
            'CLIP_GRAD_VAL': None,
            'COSINE_AFTER_WARMUP': True,
            'COSINE_END_LR': 3.33e-08,
            'COSINE_RESTART_EPOCH': 0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LARS_ON': False,
            'LAYER_DECAY': 1.0,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 12,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 2.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 3.33e-08,
            'WEIGHT_DECAY': 0.01,
            'ZERO_WD_1D_PARAM': True},
 'TASK': '',
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 240,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'CLIP_ORI_PATH': None,
          'CUSTOM_LOAD': False,
          'CUSTOM_LOAD_FILE': None,
          'DATASET': 'kinetics',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 3,
          'NUM_SPATIAL_CROPS': 1,
          'NUM_TEMPORAL_CLIPS': [],
          'OPENSET': False,
          'PATCHING_MODEL': False,
          'PATCHING_RATIO': 0.5,
          'SAVE_RESULTS_PATH': '',
          'UPDATE_STATE': False},
 'TEST_FILE': 'test.csv',
 'TRAIN': {'ADAPT_ZS_CONS_RATIO': False,
           'AUTO_RESUME': True,
           'BATCH_SIZE': 32,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_IN_INIT': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'pytorch',
           'CLIP_ORI_PATH': '/mnt/SSD8T/home/huangwei/.cache/clip/ViT-B-16.pt',
           'CUSTOM_LOAD': False,
           'CUSTOM_LOAD_FILE': None,
           'DATASET': 'kinetics',
           'ENABLE': True,
           'EVAL_PERIOD': 1,
           'EWC_CONSTRAIN_RATIO': 1.0,
           'EWC_IDENTITY_FISHER': False,
           'EWC_IGNORE_LOGIT_SCALE': False,
           'EWC_LOAD_FILE': None,
           'EWC_SET': False,
           'KILL_LOSS_EXPLOSION_FACTOR': 0.0,
           'LINEAR_CONNECT_CLIMB': False,
           'LINEAR_CONNECT_LOSS_RATIO': 0.0,
           'LINEAR_CONNECT_SAMPLE': True,
           'LINEAR_CONNECT_SAMPLE_L': 0.4,
           'LINEAR_CONNECT_SAMPLE_R': 0.6,
           'MIXED_PRECISION': True,
           'ZS_CONS': False,
           'ZS_CONS_RATIO': 0.8,
           'ZS_INIT_CONS': False,
           'ZS_RESTART_CONS': False,
           'ZS_RESTART_EPOCH': -1},
 'TRAIN_FILE': 'train_all.csv',
 'TUNE_HEAD': False,
 'VAL_FILE': 'val.csv',
 'VAL_MODE': False,
 'VIS_MASK': CfgNode({'ENABLE': False}),
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/16 20:45:39][INFO] temporalclip_video_model.py:  657: load pretrained CLIP:<All keys matched successfully>
[12/16 20:45:46][INFO] temporalclip_video_model.py:  657: load pretrained CLIP:<All keys matched successfully>
[12/16 20:45:48][INFO] train_net.py:  951: total trainable parameters:
[12/16 20:45:48][INFO] train_net.py:  952: ['module.model.positional_embedding',
 'module.model.text_projection',
 'module.model.logit_scale',
 'module.model.visual.class_embedding',
 'module.model.visual.positional_embedding',
 'module.model.visual.proj',
 'module.model.visual.conv1.weight',
 'module.model.visual.ln_pre.weight',
 'module.model.visual.ln_pre.bias',
 'module.model.visual.transformer.resblocks.0.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.0.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.0.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.0.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.0.ln_1.weight',
 'module.model.visual.transformer.resblocks.0.ln_1.bias',
 'module.model.visual.transformer.resblocks.0.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.0.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.0.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.0.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.0.ln_2.weight',
 'module.model.visual.transformer.resblocks.0.ln_2.bias',
 'module.model.visual.transformer.resblocks.1.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.1.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.1.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.1.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.1.ln_1.weight',
 'module.model.visual.transformer.resblocks.1.ln_1.bias',
 'module.model.visual.transformer.resblocks.1.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.1.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.1.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.1.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.1.ln_2.weight',
 'module.model.visual.transformer.resblocks.1.ln_2.bias',
 'module.model.visual.transformer.resblocks.2.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.2.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.2.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.2.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.2.ln_1.weight',
 'module.model.visual.transformer.resblocks.2.ln_1.bias',
 'module.model.visual.transformer.resblocks.2.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.2.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.2.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.2.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.2.ln_2.weight',
 'module.model.visual.transformer.resblocks.2.ln_2.bias',
 'module.model.visual.transformer.resblocks.3.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.3.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.3.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.3.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.3.ln_1.weight',
 'module.model.visual.transformer.resblocks.3.ln_1.bias',
 'module.model.visual.transformer.resblocks.3.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.3.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.3.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.3.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.3.ln_2.weight',
 'module.model.visual.transformer.resblocks.3.ln_2.bias',
 'module.model.visual.transformer.resblocks.4.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.4.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.4.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.4.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.4.ln_1.weight',
 'module.model.visual.transformer.resblocks.4.ln_1.bias',
 'module.model.visual.transformer.resblocks.4.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.4.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.4.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.4.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.4.ln_2.weight',
 'module.model.visual.transformer.resblocks.4.ln_2.bias',
 'module.model.visual.transformer.resblocks.5.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.5.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.5.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.5.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.5.ln_1.weight',
 'module.model.visual.transformer.resblocks.5.ln_1.bias',
 'module.model.visual.transformer.resblocks.5.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.5.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.5.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.5.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.5.ln_2.weight',
 'module.model.visual.transformer.resblocks.5.ln_2.bias',
 'module.model.visual.transformer.resblocks.6.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.6.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.6.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.6.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.6.ln_1.weight',
 'module.model.visual.transformer.resblocks.6.ln_1.bias',
 'module.model.visual.transformer.resblocks.6.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.6.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.6.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.6.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.6.ln_2.weight',
 'module.model.visual.transformer.resblocks.6.ln_2.bias',
 'module.model.visual.transformer.resblocks.7.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.7.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.7.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.7.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.7.ln_1.weight',
 'module.model.visual.transformer.resblocks.7.ln_1.bias',
 'module.model.visual.transformer.resblocks.7.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.7.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.7.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.7.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.7.ln_2.weight',
 'module.model.visual.transformer.resblocks.7.ln_2.bias',
 'module.model.visual.transformer.resblocks.8.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.8.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.8.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.8.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.8.ln_1.weight',
 'module.model.visual.transformer.resblocks.8.ln_1.bias',
 'module.model.visual.transformer.resblocks.8.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.8.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.8.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.8.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.8.ln_2.weight',
 'module.model.visual.transformer.resblocks.8.ln_2.bias',
 'module.model.visual.transformer.resblocks.9.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.9.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.9.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.9.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.9.ln_1.weight',
 'module.model.visual.transformer.resblocks.9.ln_1.bias',
 'module.model.visual.transformer.resblocks.9.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.9.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.9.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.9.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.9.ln_2.weight',
 'module.model.visual.transformer.resblocks.9.ln_2.bias',
 'module.model.visual.transformer.resblocks.10.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.10.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.10.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.10.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.10.ln_1.weight',
 'module.model.visual.transformer.resblocks.10.ln_1.bias',
 'module.model.visual.transformer.resblocks.10.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.10.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.10.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.10.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.10.ln_2.weight',
 'module.model.visual.transformer.resblocks.10.ln_2.bias',
 'module.model.visual.transformer.resblocks.11.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.11.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.11.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.11.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.11.ln_1.weight',
 'module.model.visual.transformer.resblocks.11.ln_1.bias',
 'module.model.visual.transformer.resblocks.11.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.11.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.11.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.11.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.11.ln_2.weight',
 'module.model.visual.transformer.resblocks.11.ln_2.bias',
 'module.model.visual.ln_post.weight',
 'module.model.visual.ln_post.bias',
 'module.model.transformer.resblocks.0.attn.in_proj_weight',
 'module.model.transformer.resblocks.0.attn.in_proj_bias',
 'module.model.transformer.resblocks.0.attn.out_proj.weight',
 'module.model.transformer.resblocks.0.attn.out_proj.bias',
 'module.model.transformer.resblocks.0.ln_1.weight',
 'module.model.transformer.resblocks.0.ln_1.bias',
 'module.model.transformer.resblocks.0.mlp.c_fc.weight',
 'module.model.transformer.resblocks.0.mlp.c_fc.bias',
 'module.model.transformer.resblocks.0.mlp.c_proj.weight',
 'module.model.transformer.resblocks.0.mlp.c_proj.bias',
 'module.model.transformer.resblocks.0.ln_2.weight',
 'module.model.transformer.resblocks.0.ln_2.bias',
 'module.model.transformer.resblocks.1.attn.in_proj_weight',
 'module.model.transformer.resblocks.1.attn.in_proj_bias',
 'module.model.transformer.resblocks.1.attn.out_proj.weight',
 'module.model.transformer.resblocks.1.attn.out_proj.bias',
 'module.model.transformer.resblocks.1.ln_1.weight',
 'module.model.transformer.resblocks.1.ln_1.bias',
 'module.model.transformer.resblocks.1.mlp.c_fc.weight',
 'module.model.transformer.resblocks.1.mlp.c_fc.bias',
 'module.model.transformer.resblocks.1.mlp.c_proj.weight',
 'module.model.transformer.resblocks.1.mlp.c_proj.bias',
 'module.model.transformer.resblocks.1.ln_2.weight',
 'module.model.transformer.resblocks.1.ln_2.bias',
 'module.model.transformer.resblocks.2.attn.in_proj_weight',
 'module.model.transformer.resblocks.2.attn.in_proj_bias',
 'module.model.transformer.resblocks.2.attn.out_proj.weight',
 'module.model.transformer.resblocks.2.attn.out_proj.bias',
 'module.model.transformer.resblocks.2.ln_1.weight',
 'module.model.transformer.resblocks.2.ln_1.bias',
 'module.model.transformer.resblocks.2.mlp.c_fc.weight',
 'module.model.transformer.resblocks.2.mlp.c_fc.bias',
 'module.model.transformer.resblocks.2.mlp.c_proj.weight',
 'module.model.transformer.resblocks.2.mlp.c_proj.bias',
 'module.model.transformer.resblocks.2.ln_2.weight',
 'module.model.transformer.resblocks.2.ln_2.bias',
 'module.model.transformer.resblocks.3.attn.in_proj_weight',
 'module.model.transformer.resblocks.3.attn.in_proj_bias',
 'module.model.transformer.resblocks.3.attn.out_proj.weight',
 'module.model.transformer.resblocks.3.attn.out_proj.bias',
 'module.model.transformer.resblocks.3.ln_1.weight',
 'module.model.transformer.resblocks.3.ln_1.bias',
 'module.model.transformer.resblocks.3.mlp.c_fc.weight',
 'module.model.transformer.resblocks.3.mlp.c_fc.bias',
 'module.model.transformer.resblocks.3.mlp.c_proj.weight',
 'module.model.transformer.resblocks.3.mlp.c_proj.bias',
 'module.model.transformer.resblocks.3.ln_2.weight',
 'module.model.transformer.resblocks.3.ln_2.bias',
 'module.model.transformer.resblocks.4.attn.in_proj_weight',
 'module.model.transformer.resblocks.4.attn.in_proj_bias',
 'module.model.transformer.resblocks.4.attn.out_proj.weight',
 'module.model.transformer.resblocks.4.attn.out_proj.bias',
 'module.model.transformer.resblocks.4.ln_1.weight',
 'module.model.transformer.resblocks.4.ln_1.bias',
 'module.model.transformer.resblocks.4.mlp.c_fc.weight',
 'module.model.transformer.resblocks.4.mlp.c_fc.bias',
 'module.model.transformer.resblocks.4.mlp.c_proj.weight',
 'module.model.transformer.resblocks.4.mlp.c_proj.bias',
 'module.model.transformer.resblocks.4.ln_2.weight',
 'module.model.transformer.resblocks.4.ln_2.bias',
 'module.model.transformer.resblocks.5.attn.in_proj_weight',
 'module.model.transformer.resblocks.5.attn.in_proj_bias',
 'module.model.transformer.resblocks.5.attn.out_proj.weight',
 'module.model.transformer.resblocks.5.attn.out_proj.bias',
 'module.model.transformer.resblocks.5.ln_1.weight',
 'module.model.transformer.resblocks.5.ln_1.bias',
 'module.model.transformer.resblocks.5.mlp.c_fc.weight',
 'module.model.transformer.resblocks.5.mlp.c_fc.bias',
 'module.model.transformer.resblocks.5.mlp.c_proj.weight',
 'module.model.transformer.resblocks.5.mlp.c_proj.bias',
 'module.model.transformer.resblocks.5.ln_2.weight',
 'module.model.transformer.resblocks.5.ln_2.bias',
 'module.model.transformer.resblocks.6.attn.in_proj_weight',
 'module.model.transformer.resblocks.6.attn.in_proj_bias',
 'module.model.transformer.resblocks.6.attn.out_proj.weight',
 'module.model.transformer.resblocks.6.attn.out_proj.bias',
 'module.model.transformer.resblocks.6.ln_1.weight',
 'module.model.transformer.resblocks.6.ln_1.bias',
 'module.model.transformer.resblocks.6.mlp.c_fc.weight',
 'module.model.transformer.resblocks.6.mlp.c_fc.bias',
 'module.model.transformer.resblocks.6.mlp.c_proj.weight',
 'module.model.transformer.resblocks.6.mlp.c_proj.bias',
 'module.model.transformer.resblocks.6.ln_2.weight',
 'module.model.transformer.resblocks.6.ln_2.bias',
 'module.model.transformer.resblocks.7.attn.in_proj_weight',
 'module.model.transformer.resblocks.7.attn.in_proj_bias',
 'module.model.transformer.resblocks.7.attn.out_proj.weight',
 'module.model.transformer.resblocks.7.attn.out_proj.bias',
 'module.model.transformer.resblocks.7.ln_1.weight',
 'module.model.transformer.resblocks.7.ln_1.bias',
 'module.model.transformer.resblocks.7.mlp.c_fc.weight',
 'module.model.transformer.resblocks.7.mlp.c_fc.bias',
 'module.model.transformer.resblocks.7.mlp.c_proj.weight',
 'module.model.transformer.resblocks.7.mlp.c_proj.bias',
 'module.model.transformer.resblocks.7.ln_2.weight',
 'module.model.transformer.resblocks.7.ln_2.bias',
 'module.model.transformer.resblocks.8.attn.in_proj_weight',
 'module.model.transformer.resblocks.8.attn.in_proj_bias',
 'module.model.transformer.resblocks.8.attn.out_proj.weight',
 'module.model.transformer.resblocks.8.attn.out_proj.bias',
 'module.model.transformer.resblocks.8.ln_1.weight',
 'module.model.transformer.resblocks.8.ln_1.bias',
 'module.model.transformer.resblocks.8.mlp.c_fc.weight',
 'module.model.transformer.resblocks.8.mlp.c_fc.bias',
 'module.model.transformer.resblocks.8.mlp.c_proj.weight',
 'module.model.transformer.resblocks.8.mlp.c_proj.bias',
 'module.model.transformer.resblocks.8.ln_2.weight',
 'module.model.transformer.resblocks.8.ln_2.bias',
 'module.model.transformer.resblocks.9.attn.in_proj_weight',
 'module.model.transformer.resblocks.9.attn.in_proj_bias',
 'module.model.transformer.resblocks.9.attn.out_proj.weight',
 'module.model.transformer.resblocks.9.attn.out_proj.bias',
 'module.model.transformer.resblocks.9.ln_1.weight',
 'module.model.transformer.resblocks.9.ln_1.bias',
 'module.model.transformer.resblocks.9.mlp.c_fc.weight',
 'module.model.transformer.resblocks.9.mlp.c_fc.bias',
 'module.model.transformer.resblocks.9.mlp.c_proj.weight',
 'module.model.transformer.resblocks.9.mlp.c_proj.bias',
 'module.model.transformer.resblocks.9.ln_2.weight',
 'module.model.transformer.resblocks.9.ln_2.bias',
 'module.model.transformer.resblocks.10.attn.in_proj_weight',
 'module.model.transformer.resblocks.10.attn.in_proj_bias',
 'module.model.transformer.resblocks.10.attn.out_proj.weight',
 'module.model.transformer.resblocks.10.attn.out_proj.bias',
 'module.model.transformer.resblocks.10.ln_1.weight',
 'module.model.transformer.resblocks.10.ln_1.bias',
 'module.model.transformer.resblocks.10.mlp.c_fc.weight',
 'module.model.transformer.resblocks.10.mlp.c_fc.bias',
 'module.model.transformer.resblocks.10.mlp.c_proj.weight',
 'module.model.transformer.resblocks.10.mlp.c_proj.bias',
 'module.model.transformer.resblocks.10.ln_2.weight',
 'module.model.transformer.resblocks.10.ln_2.bias',
 'module.model.transformer.resblocks.11.attn.in_proj_weight',
 'module.model.transformer.resblocks.11.attn.in_proj_bias',
 'module.model.transformer.resblocks.11.attn.out_proj.weight',
 'module.model.transformer.resblocks.11.attn.out_proj.bias',
 'module.model.transformer.resblocks.11.ln_1.weight',
 'module.model.transformer.resblocks.11.ln_1.bias',
 'module.model.transformer.resblocks.11.mlp.c_fc.weight',
 'module.model.transformer.resblocks.11.mlp.c_fc.bias',
 'module.model.transformer.resblocks.11.mlp.c_proj.weight',
 'module.model.transformer.resblocks.11.mlp.c_proj.bias',
 'module.model.transformer.resblocks.11.ln_2.weight',
 'module.model.transformer.resblocks.11.ln_2.bias',
 'module.model.token_embedding.weight',
 'module.model.ln_final.weight',
 'module.model.ln_final.bias',
 'module.projector_v.0.weight',
 'module.projector_v.2.weight',
 'module.projector_t.0.weight',
 'module.projector_t.2.weight']
[12/16 20:45:48][INFO] misc.py:  185: Model:
DistributedDataParallel(
  (module): TemporalClipVideo(
    (model): WCLIP(
      (visual): TemporalVisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): TSTransformer(
          (resblocks): Sequential(
            (0): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (raw_model): WCLIP(
      (visual): TemporalVisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): TSTransformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (projector_v): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): GELU()
      (2): Linear(in_features=512, out_features=512, bias=False)
    )
    (projector_t): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): GELU()
      (2): Linear(in_features=512, out_features=512, bias=False)
    )
  )
)
[12/16 20:45:48][INFO] misc.py:  187: Params: 300,290,050
[12/16 20:45:48][INFO] misc.py:  188: Mem: 1.6999154090881348 MB
[12/16 20:45:48][INFO] misc.py:  197: nvidia-smi
Mon Dec 16 20:45:48 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  Off |
| 42%   24C    P2    59W / 450W |   5062MiB / 24564MiB |     19%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:23:00.0 Off |                  Off |
| 41%   25C    P2    56W / 450W |   5062MiB / 24564MiB |      5%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:41:00.0 Off |                  Off |
| 41%   27C    P2    61W / 450W |   5062MiB / 24564MiB |     49%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:61:00.0 Off |                  Off |
| 40%   26C    P2    56W / 450W |   5062MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   4  NVIDIA GeForce ...  Off  | 00000000:81:00.0 Off |                  Off |
| 42%   26C    P2    61W / 450W |   5062MiB / 24564MiB |     71%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   5  NVIDIA GeForce ...  Off  | 00000000:A1:00.0 Off |                  Off |
| 41%   25C    P2    63W / 450W |   5062MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   6  NVIDIA GeForce ...  Off  | 00000000:C1:00.0 Off |                  Off |
| 42%   25C    P2    52W / 450W |   5062MiB / 24564MiB |      8%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   7  NVIDIA GeForce ...  Off  | 00000000:E1:00.0 Off |                  Off |
| 39%   25C    P2    59W / 450W |   5062MiB / 24564MiB |     58%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    0   N/A  N/A   1651926      C   .../envs/slowfast/bin/python     5054MiB |
|    1   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    1   N/A  N/A   1651927      C   .../envs/slowfast/bin/python     5054MiB |
|    2   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    2   N/A  N/A   1651928      C   .../envs/slowfast/bin/python     5054MiB |
|    3   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    3   N/A  N/A   1651929      C   .../envs/slowfast/bin/python     5054MiB |
|    4   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    4   N/A  N/A   1651930      C   .../envs/slowfast/bin/python     5054MiB |
|    5   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    5   N/A  N/A   1651934      C   .../envs/slowfast/bin/python     5054MiB |
|    6   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    6   N/A  N/A   1651935      C   .../envs/slowfast/bin/python     5054MiB |
|    7   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    7   N/A  N/A   1651937      C   .../envs/slowfast/bin/python     5054MiB |
+-----------------------------------------------------------------------------+
bn 0, non bn 107, zero 199, no grad 302
[12/16 20:45:49][INFO] kinetics.py:   94: Constructing Kinetics train...
path: ---------------------------- /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/train_all.csv
[12/16 20:45:49][INFO] kinetics.py:  172: Constructing kinetics dataloader (size: 1820 skip_rows 0) from /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/train_all.csv 
[12/16 20:45:49][INFO] kinetics.py:   94: Constructing Kinetics val...
path: ---------------------------- /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/val.csv
[12/16 20:45:49][INFO] kinetics.py:  172: Constructing kinetics dataloader (size: 774 skip_rows 0) from /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/val.csv 
[12/16 20:45:49][INFO] kinetics.py:   94: Constructing Kinetics train...
path: ---------------------------- /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/train_all.csv
[12/16 20:45:49][INFO] kinetics.py:  172: Constructing kinetics dataloader (size: 1820 skip_rows 0) from /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/train_all.csv 
[12/16 20:45:49][INFO] train_net.py: 1134: Start epoch: 1
[12/16 20:45:49][INFO] train_net.py:  304: total trainable params:
[12/16 20:45:49][INFO] train_net.py:  307: module.model.positional_embedding
[12/16 20:45:49][INFO] train_net.py:  307: module.model.text_projection
[12/16 20:45:49][INFO] train_net.py:  307: module.model.logit_scale
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.proj
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.ln_final.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.model.ln_final.bias
[12/16 20:45:49][INFO] train_net.py:  307: module.projector_v.0.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.projector_v.2.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.projector_t.0.weight
[12/16 20:45:49][INFO] train_net.py:  307: module.projector_t.2.weight
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
exponential temporal pooling in train
alpha:0.2
[12/16 20:46:09][INFO] train_net.py:  491: Distillation Loss: 0.05448472
[12/16 20:46:09][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:46:15][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.62252200, "dt_data": 0.00043155, "dt_net": 0.62208986, "epoch": "1/12", "eta": "0:06:59", "gpu_mem": "10.91G", "grad_norm": 86.32976532, "iter": "10/57", "loss": 1.70031470, "lr": 2.9E-7, "top1_err": 48.43750000, "top5_err": 18.75000000}
exponential temporal pooling in train
alpha:0.2
[12/16 20:46:15][INFO] train_net.py:  491: Distillation Loss: 0.06757933
[12/16 20:46:15][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:46:21][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60419142, "dt_data": 0.00065432, "dt_net": 0.60353513, "epoch": "1/12", "eta": "0:06:41", "gpu_mem": "10.91G", "grad_norm": 72.83393097, "iter": "20/57", "loss": 1.42349142, "lr": 5.8E-7, "top1_err": 35.93750000, "top5_err": 15.62500000}
exponential temporal pooling in train
alpha:0.2
[12/16 20:46:21][INFO] train_net.py:  491: Distillation Loss: 0.04547405
[12/16 20:46:21][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:46:27][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.61810384, "dt_data": 0.00059616, "dt_net": 0.61750563, "epoch": "1/12", "eta": "0:06:44", "gpu_mem": "10.91G", "grad_norm": 69.23932648, "iter": "30/57", "loss": 1.29274011, "lr": 8.7E-7, "top1_err": 35.93750000, "top5_err": 12.50000000}
exponential temporal pooling in train
alpha:0.2
[12/16 20:46:27][INFO] train_net.py:  491: Distillation Loss: 0.05331504
[12/16 20:46:27][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:46:33][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.61053260, "dt_data": 0.00053319, "dt_net": 0.60999859, "epoch": "1/12", "eta": "0:06:33", "gpu_mem": "10.91G", "grad_norm": 78.29817963, "iter": "40/57", "loss": 1.05663812, "lr": 0.00000116, "top1_err": 31.25000000, "top5_err": 7.81250000}
exponential temporal pooling in train
alpha:0.2
[12/16 20:46:34][INFO] train_net.py:  491: Distillation Loss: 0.06385171
[12/16 20:46:34][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:46:40][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60891581, "dt_data": 0.00026482, "dt_net": 0.60864995, "epoch": "1/12", "eta": "0:06:26", "gpu_mem": "10.91G", "grad_norm": 59.95879364, "iter": "50/57", "loss": 1.04353744, "lr": 0.00000145, "top1_err": 26.56250000, "top5_err": 3.12500000}
exponential temporal pooling in train
alpha:0.2
[12/16 20:46:40][INFO] train_net.py:  491: Distillation Loss: 0.06303066
[12/16 20:46:40][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:46:46][INFO] logging.py:   99: json_stats: {"RAM": "49.88/251.74G", "_type": "train_epoch", "dt": 2.10520336, "dt_data": 2.10520262, "dt_net": 0.60710407, "epoch": "1/12", "eta": "0:21:59", "gpu_mem": "10.91G", "grad_norm": 46.58204651, "loss": 1.26553039, "lr": 0.00000165, "top1_err": 34.53947368, "top5_err": 11.12938596}
[12/16 20:46:46][INFO] train_net.py: 1338: Epoch 0 takes 57.25s. Epochs from 0 to 0 take 57.25s in average and 57.25s in median.
[12/16 20:46:46][INFO] train_net.py: 1344: For epoch 0, each iteraction takes 1.00s in average. From epoch 0 to 0, each iteraction takes 1.00s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:47:12][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:00:04", "gpu_mem": "10.91G", "iter": "10/25", "time_diff": 0.29408613, "top1_err": 25.00000000, "top5_err": 6.25000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:47:15][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:00:01", "gpu_mem": "10.91G", "iter": "20/25", "time_diff": 0.29434229, "top1_err": 29.68750000, "top5_err": 6.25000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:47:18][INFO] logging.py:   99: json_stats: {"RAM": "52.56/251.74G", "_type": "val_epoch", "epoch": "1/12", "gpu_mem": "10.91G", "min_top1_err": 30.79896907, "min_top5_err": 7.98969072, "time_diff": 1.84677244, "top1_err": 30.79896907, "top5_err": 7.98969072}
[12/16 20:47:18][INFO] train_net.py:  304: total trainable params:
[12/16 20:47:18][INFO] train_net.py:  307: module.model.positional_embedding
[12/16 20:47:18][INFO] train_net.py:  307: module.model.text_projection
[12/16 20:47:18][INFO] train_net.py:  307: module.model.logit_scale
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.proj
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.ln_final.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.model.ln_final.bias
[12/16 20:47:18][INFO] train_net.py:  307: module.projector_v.0.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.projector_v.2.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.projector_t.0.weight
[12/16 20:47:18][INFO] train_net.py:  307: module.projector_t.2.weight
exponential temporal pooling in train
alpha:0.2
[12/16 20:47:38][INFO] train_net.py:  491: Distillation Loss: 0.05521268
[12/16 20:47:38][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:47:45][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60665737, "dt_data": 0.00052118, "dt_net": 0.60613530, "epoch": "2/12", "eta": "0:06:14", "gpu_mem": "10.91G", "grad_norm": 53.92259979, "iter": "10/57", "loss": 0.79735160, "lr": 0.00000194, "top1_err": 21.87500000, "top5_err": 1.56250000}
exponential temporal pooling in train
alpha:0.2
[12/16 20:47:45][INFO] train_net.py:  491: Distillation Loss: 0.07368362
[12/16 20:47:45][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:47:51][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60222575, "dt_data": 0.00038741, "dt_net": 0.60183766, "epoch": "2/12", "eta": "0:06:05", "gpu_mem": "10.91G", "grad_norm": 41.97033691, "iter": "20/57", "loss": 0.88476905, "lr": 0.00000223, "top1_err": 23.43750000, "top5_err": 4.68750000}
exponential temporal pooling in train
alpha:0.2
[12/16 20:47:52][INFO] train_net.py:  491: Distillation Loss: 0.06486452
[12/16 20:47:52][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:47:58][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.61251928, "dt_data": 0.00051276, "dt_net": 0.61200442, "epoch": "2/12", "eta": "0:06:05", "gpu_mem": "10.91G", "grad_norm": 43.63741302, "iter": "30/57", "loss": 0.80036014, "lr": 0.00000252, "top1_err": 20.31250000, "top5_err": 3.12500000}
exponential temporal pooling in train
alpha:0.2
[12/16 20:47:58][INFO] train_net.py:  491: Distillation Loss: 0.05801105
[12/16 20:47:58][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:48:04][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.61748553, "dt_data": 0.00034328, "dt_net": 0.61714203, "epoch": "2/12", "eta": "0:06:02", "gpu_mem": "10.91G", "grad_norm": 48.98504257, "iter": "40/57", "loss": 0.70781955, "lr": 0.00000281, "top1_err": 15.62500000, "top5_err": 1.56250000}
exponential temporal pooling in train
alpha:0.2
[12/16 20:48:04][INFO] train_net.py:  491: Distillation Loss: 0.06234443
[12/16 20:48:04][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:48:10][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60572175, "dt_data": 0.00023951, "dt_net": 0.60548070, "epoch": "2/12", "eta": "0:05:49", "gpu_mem": "10.91G", "grad_norm": 57.43072510, "iter": "50/57", "loss": 0.67352423, "lr": 0.00000310, "top1_err": 18.75000000, "top5_err": 1.56250000}
exponential temporal pooling in train
alpha:0.2
[12/16 20:48:10][INFO] train_net.py:  491: Distillation Loss: 0.07239407
[12/16 20:48:10][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:48:16][INFO] logging.py:   99: json_stats: {"RAM": "54.95/251.74G", "_type": "train_epoch", "dt": 1.82974535, "dt_data": 1.82974523, "dt_net": 0.61551243, "epoch": "2/12", "eta": "0:17:22", "gpu_mem": "10.91G", "grad_norm": 47.09145737, "loss": 0.80341480, "lr": 0.00000330, "top1_err": 21.38157895, "top5_err": 3.17982456}
[12/16 20:48:16][INFO] train_net.py: 1338: Epoch 1 takes 57.47s. Epochs from 0 to 1 take 57.36s in average and 57.36s in median.
[12/16 20:48:16][INFO] train_net.py: 1344: For epoch 1, each iteraction takes 1.01s in average. From epoch 0 to 1, each iteraction takes 1.01s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:48:42][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:00:04", "gpu_mem": "10.91G", "iter": "10/25", "time_diff": 0.29801683, "top1_err": 25.00000000, "top5_err": 4.68750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:48:45][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:00:01", "gpu_mem": "10.91G", "iter": "20/25", "time_diff": 0.29570718, "top1_err": 26.56250000, "top5_err": 4.68750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:48:48][INFO] logging.py:   99: json_stats: {"RAM": "56.80/251.74G", "_type": "val_epoch", "epoch": "2/12", "gpu_mem": "10.91G", "min_top1_err": 27.96391753, "min_top5_err": 5.67010309, "time_diff": 1.67112453, "top1_err": 27.96391753, "top5_err": 5.67010309}
[12/16 20:48:48][INFO] train_net.py:  304: total trainable params:
[12/16 20:48:48][INFO] train_net.py:  307: module.model.positional_embedding
[12/16 20:48:48][INFO] train_net.py:  307: module.model.text_projection
[12/16 20:48:48][INFO] train_net.py:  307: module.model.logit_scale
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.proj
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.ln_final.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.model.ln_final.bias
[12/16 20:48:48][INFO] train_net.py:  307: module.projector_v.0.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.projector_v.2.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.projector_t.0.weight
[12/16 20:48:48][INFO] train_net.py:  307: module.projector_t.2.weight
exponential temporal pooling in train
alpha:0.2
[12/16 20:49:08][INFO] train_net.py:  491: Distillation Loss: 0.06679589
[12/16 20:49:08][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:49:16][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60948101, "dt_data": 0.00051113, "dt_net": 0.60896882, "epoch": "3/12", "eta": "0:05:41", "gpu_mem": "10.91G", "grad_norm": 48.54781723, "iter": "10/57", "loss": 0.65250120, "lr": 0.00000333, "top1_err": 15.62500000, "top5_err": 3.12500000}
exponential temporal pooling in train
alpha:0.2
[12/16 20:49:16][INFO] train_net.py:  491: Distillation Loss: 0.07326645
[12/16 20:49:16][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:49:22][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.61874390, "dt_data": 0.00082420, "dt_net": 0.61791690, "epoch": "3/12", "eta": "0:05:40", "gpu_mem": "10.91G", "grad_norm": 43.75469589, "iter": "20/57", "loss": 0.57907450, "lr": 0.00000332, "top1_err": 12.50000000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:49:22][INFO] train_net.py:  491: Distillation Loss: 0.08110946
[12/16 20:49:22][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:49:28][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60429967, "dt_data": 0.00049024, "dt_net": 0.60380820, "epoch": "3/12", "eta": "0:05:26", "gpu_mem": "10.91G", "grad_norm": 35.19137955, "iter": "30/57", "loss": 0.47871216, "lr": 0.00000331, "top1_err": 9.37500000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:49:28][INFO] train_net.py:  491: Distillation Loss: 0.05951118
[12/16 20:49:28][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:49:34][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.62381262, "dt_data": 0.00072586, "dt_net": 0.62308554, "epoch": "3/12", "eta": "0:05:30", "gpu_mem": "10.91G", "grad_norm": 41.65745926, "iter": "40/57", "loss": 0.49877797, "lr": 0.00000329, "top1_err": 12.50000000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:49:34][INFO] train_net.py:  491: Distillation Loss: 0.07677543
[12/16 20:49:34][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:49:40][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60672478, "dt_data": 0.00020924, "dt_net": 0.60651402, "epoch": "3/12", "eta": "0:05:15", "gpu_mem": "10.91G", "grad_norm": 35.74653625, "iter": "50/57", "loss": 0.54634050, "lr": 0.00000327, "top1_err": 10.93750000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:49:40][INFO] train_net.py:  491: Distillation Loss: 0.07949269
[12/16 20:49:40][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:49:46][INFO] logging.py:   99: json_stats: {"RAM": "50.13/251.74G", "_type": "train_epoch", "dt": 2.01572979, "dt_data": 2.01572940, "dt_net": 0.60808001, "epoch": "3/12", "eta": "0:17:14", "gpu_mem": "10.91G", "grad_norm": 55.07543182, "loss": 0.57095564, "lr": 0.00000325, "top1_err": 13.48684211, "top5_err": 1.42543860}
[12/16 20:49:46][INFO] train_net.py: 1338: Epoch 2 takes 58.02s. Epochs from 0 to 2 take 57.58s in average and 57.47s in median.
[12/16 20:49:46][INFO] train_net.py: 1344: For epoch 2, each iteraction takes 1.02s in average. From epoch 0 to 2, each iteraction takes 1.01s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:50:13][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:00:04", "gpu_mem": "10.91G", "iter": "10/25", "time_diff": 0.29583072, "top1_err": 25.00000000, "top5_err": 6.25000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:50:16][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:00:01", "gpu_mem": "10.91G", "iter": "20/25", "time_diff": 0.30025490, "top1_err": 26.56250000, "top5_err": 4.68750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:50:19][INFO] logging.py:   99: json_stats: {"RAM": "49.97/251.74G", "_type": "val_epoch", "epoch": "3/12", "gpu_mem": "10.91G", "min_top1_err": 27.96391753, "min_top5_err": 5.67010309, "time_diff": 1.93958030, "top1_err": 28.22164948, "top5_err": 5.79896907}
[12/16 20:50:19][INFO] train_net.py:  304: total trainable params:
[12/16 20:50:19][INFO] train_net.py:  307: module.model.positional_embedding
[12/16 20:50:19][INFO] train_net.py:  307: module.model.text_projection
[12/16 20:50:19][INFO] train_net.py:  307: module.model.logit_scale
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.proj
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.ln_final.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.model.ln_final.bias
[12/16 20:50:19][INFO] train_net.py:  307: module.projector_v.0.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.projector_v.2.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.projector_t.0.weight
[12/16 20:50:19][INFO] train_net.py:  307: module.projector_t.2.weight
exponential temporal pooling in train
alpha:0.2
[12/16 20:50:39][INFO] train_net.py:  491: Distillation Loss: 0.06654382
[12/16 20:50:39][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:50:45][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60368866, "dt_data": 0.00044433, "dt_net": 0.60324323, "epoch": "4/12", "eta": "0:05:03", "gpu_mem": "10.91G", "grad_norm": 33.77915573, "iter": "10/57", "loss": 0.50745811, "lr": 0.00000322, "top1_err": 12.50000000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:50:45][INFO] train_net.py:  491: Distillation Loss: 0.06642050
[12/16 20:50:45][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:50:51][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.62470895, "dt_data": 0.00037229, "dt_net": 0.62433543, "epoch": "4/12", "eta": "0:05:07", "gpu_mem": "10.91G", "grad_norm": 35.28024673, "iter": "20/57", "loss": 0.41659698, "lr": 0.00000319, "top1_err": 6.25000000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:50:52][INFO] train_net.py:  491: Distillation Loss: 0.07942194
[12/16 20:50:52][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:50:58][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.61077401, "dt_data": 0.00043784, "dt_net": 0.61033519, "epoch": "4/12", "eta": "0:04:55", "gpu_mem": "10.91G", "grad_norm": 25.51965523, "iter": "30/57", "loss": 0.50013530, "lr": 0.00000315, "top1_err": 9.37500000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:50:58][INFO] train_net.py:  491: Distillation Loss: 0.07032758
[12/16 20:50:58][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:51:04][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60880675, "dt_data": 0.00040783, "dt_net": 0.60839811, "epoch": "4/12", "eta": "0:04:47", "gpu_mem": "10.91G", "grad_norm": 25.70980835, "iter": "40/57", "loss": 0.36665018, "lr": 0.00000310, "top1_err": 6.25000000, "top5_err": 1.56250000}
exponential temporal pooling in train
alpha:0.2
[12/16 20:51:04][INFO] train_net.py:  491: Distillation Loss: 0.08249843
[12/16 20:51:04][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:51:10][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60169721, "dt_data": 0.00020753, "dt_net": 0.60148901, "epoch": "4/12", "eta": "0:04:38", "gpu_mem": "10.91G", "grad_norm": 50.09862900, "iter": "50/57", "loss": 0.42325957, "lr": 0.00000306, "top1_err": 6.25000000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:51:10][INFO] train_net.py:  491: Distillation Loss: 0.08497751
[12/16 20:51:10][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:51:16][INFO] logging.py:   99: json_stats: {"RAM": "51.45/251.74G", "_type": "train_epoch", "dt": 2.17260620, "dt_data": 2.17260630, "dt_net": 0.60902749, "epoch": "4/12", "eta": "0:16:30", "gpu_mem": "10.91G", "grad_norm": 31.54770279, "loss": 0.44032646, "lr": 0.00000302, "top1_err": 8.88157895, "top5_err": 1.09649123}
[12/16 20:51:16][INFO] train_net.py: 1338: Epoch 3 takes 57.28s. Epochs from 0 to 3 take 57.50s in average and 57.37s in median.
[12/16 20:51:16][INFO] train_net.py: 1344: For epoch 3, each iteraction takes 1.00s in average. From epoch 0 to 3, each iteraction takes 1.01s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:51:42][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:00:04", "gpu_mem": "10.91G", "iter": "10/25", "time_diff": 0.29181548, "top1_err": 23.43750000, "top5_err": 3.12500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:51:45][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:00:01", "gpu_mem": "10.91G", "iter": "20/25", "time_diff": 0.29110714, "top1_err": 23.43750000, "top5_err": 4.68750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:51:48][INFO] logging.py:   99: json_stats: {"RAM": "49.96/251.74G", "_type": "val_epoch", "epoch": "4/12", "gpu_mem": "10.91G", "min_top1_err": 26.28865979, "min_top5_err": 4.63917526, "time_diff": 1.84996178, "top1_err": 26.28865979, "top5_err": 4.63917526}
[12/16 20:51:48][INFO] train_net.py:  304: total trainable params:
[12/16 20:51:48][INFO] train_net.py:  307: module.model.positional_embedding
[12/16 20:51:48][INFO] train_net.py:  307: module.model.text_projection
[12/16 20:51:48][INFO] train_net.py:  307: module.model.logit_scale
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.proj
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.ln_final.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.model.ln_final.bias
[12/16 20:51:48][INFO] train_net.py:  307: module.projector_v.0.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.projector_v.2.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.projector_t.0.weight
[12/16 20:51:48][INFO] train_net.py:  307: module.projector_t.2.weight
exponential temporal pooling in train
alpha:0.2
[12/16 20:52:09][INFO] train_net.py:  491: Distillation Loss: 0.06595266
[12/16 20:52:09][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:52:15][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60586539, "dt_data": 0.00058676, "dt_net": 0.60527738, "epoch": "5/12", "eta": "0:04:30", "gpu_mem": "10.91G", "grad_norm": 41.71987534, "iter": "10/57", "loss": 0.40396349, "lr": 0.00000297, "top1_err": 7.81250000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:52:15][INFO] train_net.py:  491: Distillation Loss: 0.08608395
[12/16 20:52:15][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:52:21][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.61812608, "dt_data": 0.00061483, "dt_net": 0.61751088, "epoch": "5/12", "eta": "0:04:29", "gpu_mem": "10.91G", "grad_norm": 27.34797478, "iter": "20/57", "loss": 0.27467582, "lr": 0.00000291, "top1_err": 4.68750000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:52:21][INFO] train_net.py:  491: Distillation Loss: 0.07830721
[12/16 20:52:21][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:52:27][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.61558548, "dt_data": 0.00050466, "dt_net": 0.61507997, "epoch": "5/12", "eta": "0:04:22", "gpu_mem": "10.91G", "grad_norm": 26.47323227, "iter": "30/57", "loss": 0.32154176, "lr": 0.00000284, "top1_err": 6.25000000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:52:27][INFO] train_net.py:  491: Distillation Loss: 0.07132739
[12/16 20:52:27][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:52:34][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60908225, "dt_data": 0.00059180, "dt_net": 0.60848847, "epoch": "5/12", "eta": "0:04:13", "gpu_mem": "10.91G", "grad_norm": 26.88830757, "iter": "40/57", "loss": 0.28275260, "lr": 0.00000278, "top1_err": 3.12500000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:52:34][INFO] train_net.py:  491: Distillation Loss: 0.06814182
[12/16 20:52:34][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:52:40][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60250596, "dt_data": 0.00022650, "dt_net": 0.60227834, "epoch": "5/12", "eta": "0:04:04", "gpu_mem": "10.91G", "grad_norm": 36.74798203, "iter": "50/57", "loss": 0.30934361, "lr": 0.00000271, "top1_err": 6.25000000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:52:40][INFO] train_net.py:  491: Distillation Loss: 0.08005798
[12/16 20:52:40][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:52:46][INFO] logging.py:   99: json_stats: {"RAM": "51.65/251.74G", "_type": "train_epoch", "dt": 2.18498457, "dt_data": 2.18498443, "dt_net": 0.60437950, "epoch": "5/12", "eta": "0:14:31", "gpu_mem": "10.91G", "grad_norm": 13.32339668, "loss": 0.35292006, "lr": 0.00000266, "top1_err": 5.75657895, "top5_err": 0.43859649}
[12/16 20:52:46][INFO] train_net.py: 1338: Epoch 4 takes 57.53s. Epochs from 0 to 4 take 57.51s in average and 57.47s in median.
[12/16 20:52:46][INFO] train_net.py: 1344: For epoch 4, each iteraction takes 1.01s in average. From epoch 0 to 4, each iteraction takes 1.01s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:53:12][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:00:04", "gpu_mem": "10.91G", "iter": "10/25", "time_diff": 0.29687919, "top1_err": 25.00000000, "top5_err": 3.12500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:53:15][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:00:01", "gpu_mem": "10.91G", "iter": "20/25", "time_diff": 0.29639572, "top1_err": 26.56250000, "top5_err": 3.12500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:53:19][INFO] logging.py:   99: json_stats: {"RAM": "50.13/251.74G", "_type": "val_epoch", "epoch": "5/12", "gpu_mem": "10.91G", "min_top1_err": 26.28865979, "min_top5_err": 4.63917526, "time_diff": 2.25341265, "top1_err": 27.57731959, "top5_err": 5.67010309}
[12/16 20:53:19][INFO] train_net.py:  304: total trainable params:
[12/16 20:53:19][INFO] train_net.py:  307: module.model.positional_embedding
[12/16 20:53:19][INFO] train_net.py:  307: module.model.text_projection
[12/16 20:53:19][INFO] train_net.py:  307: module.model.logit_scale
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.proj
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.ln_final.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.model.ln_final.bias
[12/16 20:53:19][INFO] train_net.py:  307: module.projector_v.0.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.projector_v.2.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.projector_t.0.weight
[12/16 20:53:19][INFO] train_net.py:  307: module.projector_t.2.weight
exponential temporal pooling in train
alpha:0.2
[12/16 20:53:39][INFO] train_net.py:  491: Distillation Loss: 0.07181007
[12/16 20:53:39][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:53:46][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.61990080, "dt_data": 0.00039715, "dt_net": 0.61950287, "epoch": "6/12", "eta": "0:04:01", "gpu_mem": "10.91G", "grad_norm": 29.33754349, "iter": "10/57", "loss": 0.33104371, "lr": 0.00000258, "top1_err": 6.25000000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:53:46][INFO] train_net.py:  491: Distillation Loss: 0.06037295
[12/16 20:53:46][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:53:52][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60722251, "dt_data": 0.00039647, "dt_net": 0.60682618, "epoch": "6/12", "eta": "0:03:50", "gpu_mem": "10.91G", "grad_norm": 45.25617981, "iter": "20/57", "loss": 0.26659285, "lr": 0.00000251, "top1_err": 3.12500000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:53:52][INFO] train_net.py:  491: Distillation Loss: 0.05993402
[12/16 20:53:52][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:53:58][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.61068223, "dt_data": 0.00060131, "dt_net": 0.61007857, "epoch": "6/12", "eta": "0:03:45", "gpu_mem": "10.91G", "grad_norm": 11.11816406, "iter": "30/57", "loss": 0.30959637, "lr": 0.00000243, "top1_err": 3.12500000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:53:58][INFO] train_net.py:  491: Distillation Loss: 0.06163758
[12/16 20:53:58][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:54:04][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.61285974, "dt_data": 0.00046499, "dt_net": 0.61239362, "epoch": "6/12", "eta": "0:03:40", "gpu_mem": "10.91G", "grad_norm": 15.79911041, "iter": "40/57", "loss": 0.26092538, "lr": 0.00000234, "top1_err": 3.12500000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:54:04][INFO] train_net.py:  491: Distillation Loss: 0.06120515
[12/16 20:54:04][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:54:10][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60554684, "dt_data": 0.00020296, "dt_net": 0.60534248, "epoch": "6/12", "eta": "0:03:31", "gpu_mem": "10.91G", "grad_norm": 26.96723747, "iter": "50/57", "loss": 0.23038022, "lr": 0.00000226, "top1_err": 3.12500000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:54:10][INFO] train_net.py:  491: Distillation Loss: 0.07984585
[12/16 20:54:10][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:54:16][INFO] logging.py:   99: json_stats: {"RAM": "51.83/251.74G", "_type": "train_epoch", "dt": 1.73927858, "dt_data": 1.73927822, "dt_net": 0.60711122, "epoch": "6/12", "eta": "0:09:54", "gpu_mem": "10.91G", "grad_norm": 27.07832336, "loss": 0.28909047, "lr": 0.00000220, "top1_err": 4.00219298, "top5_err": 0.32894737}
[12/16 20:54:16][INFO] train_net.py: 1338: Epoch 5 takes 56.76s. Epochs from 0 to 5 take 57.39s in average and 57.37s in median.
[12/16 20:54:16][INFO] train_net.py: 1344: For epoch 5, each iteraction takes 1.00s in average. From epoch 0 to 5, each iteraction takes 1.01s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:54:42][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:00:04", "gpu_mem": "10.91G", "iter": "10/25", "time_diff": 0.29476305, "top1_err": 26.56250000, "top5_err": 3.12500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:54:45][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:00:01", "gpu_mem": "10.91G", "iter": "20/25", "time_diff": 0.29553639, "top1_err": 26.56250000, "top5_err": 6.25000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:54:48][INFO] logging.py:   99: json_stats: {"RAM": "50.03/251.74G", "_type": "val_epoch", "epoch": "6/12", "gpu_mem": "10.91G", "min_top1_err": 26.28865979, "min_top5_err": 4.63917526, "time_diff": 1.88340903, "top1_err": 27.31958763, "top5_err": 4.76804124}
[12/16 20:54:48][INFO] train_net.py:  304: total trainable params:
[12/16 20:54:48][INFO] train_net.py:  307: module.model.positional_embedding
[12/16 20:54:48][INFO] train_net.py:  307: module.model.text_projection
[12/16 20:54:48][INFO] train_net.py:  307: module.model.logit_scale
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.proj
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.ln_final.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.model.ln_final.bias
[12/16 20:54:48][INFO] train_net.py:  307: module.projector_v.0.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.projector_v.2.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.projector_t.0.weight
[12/16 20:54:48][INFO] train_net.py:  307: module.projector_t.2.weight
exponential temporal pooling in train
alpha:0.2
[12/16 20:55:08][INFO] train_net.py:  491: Distillation Loss: 0.08407819
[12/16 20:55:08][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:55:15][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.61467451, "dt_data": 0.00053722, "dt_net": 0.61413574, "epoch": "7/12", "eta": "0:03:24", "gpu_mem": "10.91G", "grad_norm": 15.63306522, "iter": "10/57", "loss": 0.22795045, "lr": 0.00000211, "top1_err": 3.12500000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:55:15][INFO] train_net.py:  491: Distillation Loss: 0.05821085
[12/16 20:55:15][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:55:21][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.61028272, "dt_data": 0.00038320, "dt_net": 0.60989969, "epoch": "7/12", "eta": "0:03:16", "gpu_mem": "10.91G", "grad_norm": 18.17043114, "iter": "20/57", "loss": 0.20636604, "lr": 0.00000202, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:55:21][INFO] train_net.py:  491: Distillation Loss: 0.06641167
[12/16 20:55:21][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:55:27][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.62583310, "dt_data": 0.00038026, "dt_net": 0.62545084, "epoch": "7/12", "eta": "0:03:15", "gpu_mem": "10.91G", "grad_norm": 22.96180916, "iter": "30/57", "loss": 0.20287886, "lr": 0.00000194, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:55:27][INFO] train_net.py:  491: Distillation Loss: 0.06912595
[12/16 20:55:27][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:55:33][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60028560, "dt_data": 0.00042969, "dt_net": 0.59985572, "epoch": "7/12", "eta": "0:03:01", "gpu_mem": "10.91G", "grad_norm": 13.72101498, "iter": "40/57", "loss": 0.18816973, "lr": 0.00000184, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:55:33][INFO] train_net.py:  491: Distillation Loss: 0.05950862
[12/16 20:55:33][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:55:39][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60634550, "dt_data": 0.00028028, "dt_net": 0.60606315, "epoch": "7/12", "eta": "0:02:57", "gpu_mem": "10.91G", "grad_norm": 36.97308350, "iter": "50/57", "loss": 0.21872737, "lr": 0.00000175, "top1_err": 1.56250000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:55:39][INFO] train_net.py:  491: Distillation Loss: 0.05126047
[12/16 20:55:39][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:55:46][INFO] logging.py:   99: json_stats: {"RAM": "49.88/251.74G", "_type": "train_epoch", "dt": 2.28572167, "dt_data": 2.28572095, "dt_net": 0.60332908, "epoch": "7/12", "eta": "0:10:51", "gpu_mem": "10.91G", "grad_norm": 13.26180935, "loss": 0.22590996, "lr": 0.00000169, "top1_err": 1.80921053, "top5_err": 0.05482456}
[12/16 20:55:46][INFO] train_net.py: 1338: Epoch 6 takes 57.53s. Epochs from 0 to 6 take 57.41s in average and 57.47s in median.
[12/16 20:55:46][INFO] train_net.py: 1344: For epoch 6, each iteraction takes 1.01s in average. From epoch 0 to 6, each iteraction takes 1.01s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:56:11][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:00:04", "gpu_mem": "10.91G", "iter": "10/25", "time_diff": 0.29035928, "top1_err": 23.43750000, "top5_err": 3.12500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:56:14][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:00:01", "gpu_mem": "10.91G", "iter": "20/25", "time_diff": 0.29282981, "top1_err": 25.00000000, "top5_err": 6.25000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:56:18][INFO] logging.py:   99: json_stats: {"RAM": "49.93/251.74G", "_type": "val_epoch", "epoch": "7/12", "gpu_mem": "10.91G", "min_top1_err": 26.03092784, "min_top5_err": 4.38144330, "time_diff": 1.81307300, "top1_err": 26.03092784, "top5_err": 4.38144330}
[12/16 20:56:18][INFO] train_net.py:  304: total trainable params:
[12/16 20:56:18][INFO] train_net.py:  307: module.model.positional_embedding
[12/16 20:56:18][INFO] train_net.py:  307: module.model.text_projection
[12/16 20:56:18][INFO] train_net.py:  307: module.model.logit_scale
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.proj
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.ln_final.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.model.ln_final.bias
[12/16 20:56:18][INFO] train_net.py:  307: module.projector_v.0.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.projector_v.2.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.projector_t.0.weight
[12/16 20:56:18][INFO] train_net.py:  307: module.projector_t.2.weight
exponential temporal pooling in train
alpha:0.2
[12/16 20:56:38][INFO] train_net.py:  491: Distillation Loss: 0.07151216
[12/16 20:56:38][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:56:44][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.61049229, "dt_data": 0.00026713, "dt_net": 0.61022317, "epoch": "8/12", "eta": "0:02:47", "gpu_mem": "10.91G", "grad_norm": 11.90001678, "iter": "10/57", "loss": 0.19040956, "lr": 0.00000160, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:56:44][INFO] train_net.py:  491: Distillation Loss: 0.07034564
[12/16 20:56:44][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:56:51][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.62499447, "dt_data": 0.00049600, "dt_net": 0.62449670, "epoch": "8/12", "eta": "0:02:45", "gpu_mem": "10.91G", "grad_norm": 12.51470757, "iter": "20/57", "loss": 0.17079949, "lr": 0.00000151, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:56:51][INFO] train_net.py:  491: Distillation Loss: 0.05966449
[12/16 20:56:51][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:56:57][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60360987, "dt_data": 0.00052198, "dt_net": 0.60308546, "epoch": "8/12", "eta": "0:02:33", "gpu_mem": "10.91G", "grad_norm": 11.88426113, "iter": "30/57", "loss": 0.17924149, "lr": 0.00000142, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:56:57][INFO] train_net.py:  491: Distillation Loss: 0.05715674
[12/16 20:56:57][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:57:03][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60587285, "dt_data": 0.00038740, "dt_net": 0.60548436, "epoch": "8/12", "eta": "0:02:28", "gpu_mem": "10.91G", "grad_norm": 33.34998703, "iter": "40/57", "loss": 0.18761130, "lr": 0.00000133, "top1_err": 1.56250000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:57:03][INFO] train_net.py:  491: Distillation Loss: 0.05169636
[12/16 20:57:03][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:57:09][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.61219843, "dt_data": 0.00016979, "dt_net": 0.61202818, "epoch": "8/12", "eta": "0:02:23", "gpu_mem": "10.91G", "grad_norm": 10.78487015, "iter": "50/57", "loss": 0.21391411, "lr": 0.00000124, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:57:09][INFO] train_net.py:  491: Distillation Loss: 0.06833279
[12/16 20:57:09][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:57:15][INFO] logging.py:   99: json_stats: {"RAM": "50.01/251.74G", "_type": "train_epoch", "dt": 2.31988257, "dt_data": 2.31988215, "dt_net": 0.60945719, "epoch": "8/12", "eta": "0:08:48", "gpu_mem": "10.91G", "grad_norm": 46.12945938, "loss": 0.20093911, "lr": 0.00000118, "top1_err": 1.26096491, "top5_err": 0.10964912}
[12/16 20:57:15][INFO] train_net.py: 1338: Epoch 7 takes 57.68s. Epochs from 0 to 7 take 57.44s in average and 57.50s in median.
[12/16 20:57:15][INFO] train_net.py: 1344: For epoch 7, each iteraction takes 1.01s in average. From epoch 0 to 7, each iteraction takes 1.01s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:57:41][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:00:04", "gpu_mem": "10.91G", "iter": "10/25", "time_diff": 0.29882257, "top1_err": 25.00000000, "top5_err": 3.12500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:57:44][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:00:01", "gpu_mem": "10.91G", "iter": "20/25", "time_diff": 0.29062992, "top1_err": 25.00000000, "top5_err": 7.81250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:57:47][INFO] logging.py:   99: json_stats: {"RAM": "50.10/251.74G", "_type": "val_epoch", "epoch": "8/12", "gpu_mem": "10.91G", "min_top1_err": 26.03092784, "min_top5_err": 4.38144330, "time_diff": 1.81096637, "top1_err": 26.93298969, "top5_err": 5.54123711}
[12/16 20:57:47][INFO] train_net.py:  304: total trainable params:
[12/16 20:57:47][INFO] train_net.py:  307: module.model.positional_embedding
[12/16 20:57:47][INFO] train_net.py:  307: module.model.text_projection
[12/16 20:57:47][INFO] train_net.py:  307: module.model.logit_scale
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.proj
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.ln_final.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.model.ln_final.bias
[12/16 20:57:47][INFO] train_net.py:  307: module.projector_v.0.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.projector_v.2.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.projector_t.0.weight
[12/16 20:57:47][INFO] train_net.py:  307: module.projector_t.2.weight
exponential temporal pooling in train
alpha:0.2
[12/16 20:58:07][INFO] train_net.py:  491: Distillation Loss: 0.04796463
[12/16 20:58:07][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:58:14][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60868465, "dt_data": 0.00041954, "dt_net": 0.60826408, "epoch": "9/12", "eta": "0:02:12", "gpu_mem": "10.91G", "grad_norm": 38.85821915, "iter": "10/57", "loss": 0.15760124, "lr": 0.00000110, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:58:14][INFO] train_net.py:  491: Distillation Loss: 0.06344610
[12/16 20:58:14][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:58:20][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.61026537, "dt_data": 0.00046990, "dt_net": 0.60979484, "epoch": "9/12", "eta": "0:02:06", "gpu_mem": "10.91G", "grad_norm": 19.56997871, "iter": "20/57", "loss": 0.17735112, "lr": 0.00000101, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:58:20][INFO] train_net.py:  491: Distillation Loss: 0.05821419
[12/16 20:58:20][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:58:26][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60608854, "dt_data": 0.00036788, "dt_net": 0.60571908, "epoch": "9/12", "eta": "0:02:00", "gpu_mem": "10.91G", "grad_norm": 4.38535738, "iter": "30/57", "loss": 0.18633530, "lr": 9.3E-7, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:58:27][INFO] train_net.py:  491: Distillation Loss: 0.05543894
[12/16 20:58:27][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:58:33][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60824154, "dt_data": 0.00039237, "dt_net": 0.60784827, "epoch": "9/12", "eta": "0:01:54", "gpu_mem": "10.91G", "grad_norm": 8.44221020, "iter": "40/57", "loss": 0.17259697, "lr": 8.5E-7, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:58:33][INFO] train_net.py:  491: Distillation Loss: 0.04960883
[12/16 20:58:33][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:58:39][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60326782, "dt_data": 0.00019712, "dt_net": 0.60306958, "epoch": "9/12", "eta": "0:01:47", "gpu_mem": "10.91G", "grad_norm": 32.88663101, "iter": "50/57", "loss": 0.20573232, "lr": 7.7E-7, "top1_err": 1.56250000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:58:39][INFO] train_net.py:  491: Distillation Loss: 0.05107719
[12/16 20:58:39][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:58:45][INFO] logging.py:   99: json_stats: {"RAM": "49.90/251.74G", "_type": "train_epoch", "dt": 2.25899145, "dt_data": 2.25899104, "dt_net": 0.60445398, "epoch": "9/12", "eta": "0:06:26", "gpu_mem": "10.91G", "grad_norm": 16.74035645, "loss": 0.18477941, "lr": 7.2E-7, "top1_err": 0.87719298, "top5_err": 0.10964912}
[12/16 20:58:45][INFO] train_net.py: 1338: Epoch 8 takes 57.63s. Epochs from 0 to 8 take 57.46s in average and 57.53s in median.
[12/16 20:58:45][INFO] train_net.py: 1344: For epoch 8, each iteraction takes 1.01s in average. From epoch 0 to 8, each iteraction takes 1.01s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:59:11][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:00:04", "gpu_mem": "10.91G", "iter": "10/25", "time_diff": 0.29633149, "top1_err": 26.56250000, "top5_err": 3.12500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:59:14][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:00:01", "gpu_mem": "10.91G", "iter": "20/25", "time_diff": 0.29384864, "top1_err": 28.12500000, "top5_err": 4.68750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 20:59:17][INFO] logging.py:   99: json_stats: {"RAM": "50.79/251.74G", "_type": "val_epoch", "epoch": "9/12", "gpu_mem": "10.91G", "min_top1_err": 26.03092784, "min_top5_err": 4.38144330, "time_diff": 1.81315196, "top1_err": 27.31958763, "top5_err": 5.02577320}
[12/16 20:59:17][INFO] train_net.py:  304: total trainable params:
[12/16 20:59:17][INFO] train_net.py:  307: module.model.positional_embedding
[12/16 20:59:17][INFO] train_net.py:  307: module.model.text_projection
[12/16 20:59:17][INFO] train_net.py:  307: module.model.logit_scale
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.proj
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.ln_final.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.model.ln_final.bias
[12/16 20:59:17][INFO] train_net.py:  307: module.projector_v.0.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.projector_v.2.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.projector_t.0.weight
[12/16 20:59:17][INFO] train_net.py:  307: module.projector_t.2.weight
exponential temporal pooling in train
alpha:0.2
[12/16 20:59:37][INFO] train_net.py:  491: Distillation Loss: 0.06167889
[12/16 20:59:37][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:59:44][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.61559724, "dt_data": 0.00037478, "dt_net": 0.61522121, "epoch": "10/12", "eta": "0:01:39", "gpu_mem": "10.91G", "grad_norm": 4.32678032, "iter": "10/57", "loss": 0.15874062, "lr": 6.5E-7, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:59:44][INFO] train_net.py:  491: Distillation Loss: 0.07471550
[12/16 20:59:44][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:59:50][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.61658289, "dt_data": 0.00050097, "dt_net": 0.61608045, "epoch": "10/12", "eta": "0:01:33", "gpu_mem": "10.91G", "grad_norm": 8.42283726, "iter": "20/57", "loss": 0.14913654, "lr": 5.8E-7, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:59:50][INFO] train_net.py:  491: Distillation Loss: 0.05258840
[12/16 20:59:50][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 20:59:56][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.61647212, "dt_data": 0.00051105, "dt_net": 0.61596082, "epoch": "10/12", "eta": "0:01:26", "gpu_mem": "10.91G", "grad_norm": 3.77460337, "iter": "30/57", "loss": 0.17568215, "lr": 5.1E-7, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 20:59:56][INFO] train_net.py:  491: Distillation Loss: 0.06425083
[12/16 20:59:56][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 21:00:02][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.61097640, "dt_data": 0.00063799, "dt_net": 0.61033691, "epoch": "10/12", "eta": "0:01:20", "gpu_mem": "10.91G", "grad_norm": 9.97257233, "iter": "40/57", "loss": 0.15658598, "lr": 4.5E-7, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 21:00:03][INFO] train_net.py:  491: Distillation Loss: 0.04604506
[12/16 21:00:03][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 21:00:09][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60917948, "dt_data": 0.00019610, "dt_net": 0.60898287, "epoch": "10/12", "eta": "0:01:13", "gpu_mem": "10.91G", "grad_norm": 9.73472595, "iter": "50/57", "loss": 0.16519188, "lr": 3.9E-7, "top1_err": 1.56250000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 21:00:09][INFO] train_net.py:  491: Distillation Loss: 0.06168443
[12/16 21:00:09][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 21:00:15][INFO] logging.py:   99: json_stats: {"RAM": "49.97/251.74G", "_type": "train_epoch", "dt": 2.30252814, "dt_data": 2.30252696, "dt_net": 0.60130495, "epoch": "10/12", "eta": "0:04:22", "gpu_mem": "10.91G", "grad_norm": 9.95663357, "loss": 0.16566882, "lr": 3.5E-7, "top1_err": 0.87719298, "top5_err": 0E-8}
[12/16 21:00:15][INFO] train_net.py: 1338: Epoch 9 takes 57.66s. Epochs from 0 to 9 take 57.48s in average and 57.53s in median.
[12/16 21:00:15][INFO] train_net.py: 1344: For epoch 9, each iteraction takes 1.01s in average. From epoch 0 to 9, each iteraction takes 1.01s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 21:00:41][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:00:04", "gpu_mem": "10.91G", "iter": "10/25", "time_diff": 0.29270048, "top1_err": 25.00000000, "top5_err": 6.25000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 21:00:44][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:00:01", "gpu_mem": "10.91G", "iter": "20/25", "time_diff": 0.29065152, "top1_err": 28.12500000, "top5_err": 3.12500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 21:00:47][INFO] logging.py:   99: json_stats: {"RAM": "50.36/251.74G", "_type": "val_epoch", "epoch": "10/12", "gpu_mem": "10.91G", "min_top1_err": 26.03092784, "min_top5_err": 4.38144330, "time_diff": 2.27033002, "top1_err": 26.67525773, "top5_err": 5.67010309}
[12/16 21:00:47][INFO] train_net.py:  304: total trainable params:
[12/16 21:00:47][INFO] train_net.py:  307: module.model.positional_embedding
[12/16 21:00:47][INFO] train_net.py:  307: module.model.text_projection
[12/16 21:00:47][INFO] train_net.py:  307: module.model.logit_scale
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.proj
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.ln_final.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.model.ln_final.bias
[12/16 21:00:47][INFO] train_net.py:  307: module.projector_v.0.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.projector_v.2.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.projector_t.0.weight
[12/16 21:00:47][INFO] train_net.py:  307: module.projector_t.2.weight
exponential temporal pooling in train
alpha:0.2
[12/16 21:01:08][INFO] train_net.py:  491: Distillation Loss: 0.06250048
[12/16 21:01:08][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 21:01:14][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.61482425, "dt_data": 0.00048647, "dt_net": 0.61433668, "epoch": "11/12", "eta": "0:01:03", "gpu_mem": "10.91G", "grad_norm": 7.71655321, "iter": "10/57", "loss": 0.14930829, "lr": 3.0E-7, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 21:01:14][INFO] train_net.py:  491: Distillation Loss: 0.05608737
[12/16 21:01:14][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 21:01:20][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60633571, "dt_data": 0.00049912, "dt_net": 0.60583379, "epoch": "11/12", "eta": "0:00:56", "gpu_mem": "10.91G", "grad_norm": 7.21980762, "iter": "20/57", "loss": 0.15046370, "lr": 2.5E-7, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 21:01:20][INFO] train_net.py:  491: Distillation Loss: 0.06462520
[12/16 21:01:20][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 21:01:26][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60538523, "dt_data": 0.00023625, "dt_net": 0.60514814, "epoch": "11/12", "eta": "0:00:50", "gpu_mem": "10.91G", "grad_norm": 16.55526161, "iter": "30/57", "loss": 0.15861094, "lr": 2.1E-7, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 21:01:26][INFO] train_net.py:  491: Distillation Loss: 0.05531222
[12/16 21:01:26][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 21:01:32][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.61684218, "dt_data": 0.00036517, "dt_net": 0.61647534, "epoch": "11/12", "eta": "0:00:45", "gpu_mem": "10.91G", "grad_norm": 16.09049225, "iter": "40/57", "loss": 0.13831309, "lr": 1.7E-7, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 21:01:32][INFO] train_net.py:  491: Distillation Loss: 0.06490582
[12/16 21:01:32][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 21:01:38][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60907767, "dt_data": 0.00025553, "dt_net": 0.60882065, "epoch": "11/12", "eta": "0:00:38", "gpu_mem": "10.91G", "grad_norm": 19.64861488, "iter": "50/57", "loss": 0.15388227, "lr": 1.4E-7, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 21:01:39][INFO] train_net.py:  491: Distillation Loss: 0.04213691
[12/16 21:01:39][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 21:01:45][INFO] logging.py:   99: json_stats: {"RAM": "49.99/251.74G", "_type": "train_epoch", "dt": 2.30981541, "dt_data": 2.30981457, "dt_net": 0.60708133, "epoch": "11/12", "eta": "0:02:11", "gpu_mem": "10.91G", "grad_norm": 23.70068169, "loss": 0.15705153, "lr": 1.2E-7, "top1_err": 0.54824561, "top5_err": 0E-8}
[12/16 21:01:45][INFO] train_net.py: 1338: Epoch 10 takes 57.57s. Epochs from 0 to 10 take 57.49s in average and 57.53s in median.
[12/16 21:01:45][INFO] train_net.py: 1344: For epoch 10, each iteraction takes 1.01s in average. From epoch 0 to 10, each iteraction takes 1.01s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 21:02:11][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:00:04", "gpu_mem": "10.91G", "iter": "10/25", "time_diff": 0.28888983, "top1_err": 21.87500000, "top5_err": 3.12500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 21:02:14][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:00:01", "gpu_mem": "10.91G", "iter": "20/25", "time_diff": 0.29151918, "top1_err": 25.00000000, "top5_err": 4.68750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 21:02:17][INFO] logging.py:   99: json_stats: {"RAM": "50.41/251.74G", "_type": "val_epoch", "epoch": "11/12", "gpu_mem": "10.91G", "min_top1_err": 25.90206186, "min_top5_err": 4.38144330, "time_diff": 1.89759632, "top1_err": 25.90206186, "top5_err": 5.41237113}
[12/16 21:02:17][INFO] train_net.py:  304: total trainable params:
[12/16 21:02:17][INFO] train_net.py:  307: module.model.positional_embedding
[12/16 21:02:17][INFO] train_net.py:  307: module.model.text_projection
[12/16 21:02:17][INFO] train_net.py:  307: module.model.logit_scale
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.proj
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.ln_final.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.model.ln_final.bias
[12/16 21:02:17][INFO] train_net.py:  307: module.projector_v.0.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.projector_v.2.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.projector_t.0.weight
[12/16 21:02:17][INFO] train_net.py:  307: module.projector_t.2.weight
exponential temporal pooling in train
alpha:0.2
[12/16 21:02:37][INFO] train_net.py:  491: Distillation Loss: 0.05164766
[12/16 21:02:37][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 21:02:44][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60384433, "dt_data": 0.00051948, "dt_net": 0.60332388, "epoch": "12/12", "eta": "0:00:28", "gpu_mem": "10.91G", "grad_norm": 12.00108433, "iter": "10/57", "loss": 0.14827160, "lr": 9E-8, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 21:02:44][INFO] train_net.py:  491: Distillation Loss: 0.06884921
[12/16 21:02:44][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 21:02:50][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60398217, "dt_data": 0.00043207, "dt_net": 0.60355054, "epoch": "12/12", "eta": "0:00:22", "gpu_mem": "10.91G", "grad_norm": 10.56843662, "iter": "20/57", "loss": 0.14087054, "lr": 7E-8, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 21:02:50][INFO] train_net.py:  491: Distillation Loss: 0.05552804
[12/16 21:02:50][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 21:02:56][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60508074, "dt_data": 0.00039409, "dt_net": 0.60468550, "epoch": "12/12", "eta": "0:00:16", "gpu_mem": "10.91G", "grad_norm": 10.85408115, "iter": "30/57", "loss": 0.14811793, "lr": 5E-8, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 21:02:56][INFO] train_net.py:  491: Distillation Loss: 0.06736904
[12/16 21:02:56][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 21:03:02][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60000555, "dt_data": 0.00051299, "dt_net": 0.59949172, "epoch": "12/12", "eta": "0:00:10", "gpu_mem": "10.91G", "grad_norm": 16.55506897, "iter": "40/57", "loss": 0.14429968, "lr": 4E-8, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 21:03:02][INFO] train_net.py:  491: Distillation Loss: 0.05198485
[12/16 21:03:02][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 21:03:08][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.60188333, "dt_data": 0.00016740, "dt_net": 0.60171531, "epoch": "12/12", "eta": "0:00:04", "gpu_mem": "10.91G", "grad_norm": 10.55474091, "iter": "50/57", "loss": 0.14682713, "lr": 3E-8, "top1_err": 0E-8, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/16 21:03:08][INFO] train_net.py:  491: Distillation Loss: 0.05208230
[12/16 21:03:08][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 21:03:14][INFO] logging.py:   99: json_stats: {"RAM": "57.04/251.74G", "_type": "train_epoch", "dt": 1.64602585, "dt_data": 1.64602562, "dt_net": 0.60272453, "epoch": "12/12", "eta": "0:00:00", "gpu_mem": "10.91G", "grad_norm": 9.65498066, "loss": 0.15060250, "lr": 3E-8, "top1_err": 0.38377193, "top5_err": 0E-8}
[12/16 21:03:14][INFO] train_net.py: 1338: Epoch 11 takes 56.76s. Epochs from 0 to 11 take 57.43s in average and 57.53s in median.
[12/16 21:03:14][INFO] train_net.py: 1344: For epoch 11, each iteraction takes 1.00s in average. From epoch 0 to 11, each iteraction takes 1.01s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 21:03:40][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:00:04", "gpu_mem": "10.91G", "iter": "10/25", "time_diff": 0.29826650, "top1_err": 26.56250000, "top5_err": 3.12500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 21:03:43][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:00:01", "gpu_mem": "10.91G", "iter": "20/25", "time_diff": 0.29254808, "top1_err": 26.56250000, "top5_err": 4.68750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 21:03:47][INFO] logging.py:   99: json_stats: {"RAM": "49.89/251.74G", "_type": "val_epoch", "epoch": "12/12", "gpu_mem": "10.91G", "min_top1_err": 25.90206186, "min_top5_err": 4.38144330, "time_diff": 2.27926337, "top1_err": 27.44845361, "top5_err": 4.76804124}
[12/16 21:03:47][INFO] train_net.py: 1443: training done: _p300.29_f10.00 _t0.96_m10.91 _a74.10 Top5 Acc: 95.62 MEM: 10.91 f: 10.0000
[12/16 21:03:52][INFO] test_net.py:  319: Test with config:
[12/16 21:03:52][INFO] test_net.py:  320: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: False
  GEN_MASK_LOADER: False
  INTERPOLATION: bicubic
  MASK_FRAMES: False
  MASK_RATIO: 0.0
  MASK_TUBE: False
  MASK_WINDOW_SIZE: [8, 7, 7]
  MAX_MASK_PATCHES_PER_BLOCK: None
  NUM_SAMPLE: 1
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  BGR: False
  DETECTION_SCORE_THRESH: 0.9
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: /mnt/fair-flash3-east/ava_trainval_frames.img/
  FRAME_LIST_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  FULL_TEST_ON_VAL: False
  GROUNDTRUTH_FILE: ava_val_v2.2.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: ava_action_list_v2.2_for_activitynet_2019.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_val_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train_v2.2.csv']
  TRAIN_LISTS: ['train_all.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  GLOBAL_SYNC: False
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
CONTRASTIVE:
  BN_MLP: False
  BN_SYNC_MLP: False
  DELTA_CLIPS_MAX: inf
  DELTA_CLIPS_MIN: -inf
  DIM: 128
  INTERP_MEMORY: False
  KNN_ON: True
  LENGTH: 239975
  LOCAL_SHUFFLE_BN: True
  MEM_TYPE: 1d
  MLP_DIM: 2048
  MOCO_MULTI_VIEW_QUEUE: False
  MOMENTUM: 0.5
  MOMENTUM_ANNEALING: False
  NUM_CLASSES_DOWNSTREAM: 400
  NUM_MLP_LAYERS: 1
  PREDICTOR_DEPTHS: []
  QUEUE_LEN: 65536
  SEQUENTIAL: False
  SIMCLR_DIST_ON: True
  SWAV_QEUE_LEN: 0
  T: 0.07
  TYPE: mem
DATA:
  COLOR_RND_GRAYSCALE: 0.0
  DECODING_BACKEND: pyav
  DECODING_SHORT_SIZE: 256
  DUMMY_LOAD: False
  ENSEMBLE_METHOD: sum
  IN22K_TRAINVAL: False
  IN22k_VAL_IN1K: 
  INDEX_LABEL_MAPPING_FILE: /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/train_rephrased.json
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  IN_VAL_CROP_RATIO: 0.875
  LOADER_CHUNK_OVERALL_SIZE: 0
  LOADER_CHUNK_SIZE: 0
  MEAN: [0.48145466, 0.4578275, 0.40821073]
  MULTI_LABEL: False
  NUM_FRAMES: 8
  PATH_LABEL_SEPARATOR: ,
  PATH_PREFIX: /mnt/SSD8T/home/huangwei/projects/FROSTER/data/hmdb51
  PATH_TO_DATA_DIR: /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb
  PATH_TO_PRELOAD_IMDB: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 16
  SKIP_ROWS: 0
  SSL_BLUR_SIGMA_MAX: [0.0, 2.0]
  SSL_BLUR_SIGMA_MIN: [0.0, 0.1]
  SSL_COLOR_BRI_CON_SAT: [0.4, 0.4, 0.4]
  SSL_COLOR_HUE: 0.1
  SSL_COLOR_JITTER: False
  SSL_MOCOV2_AUG: False
  STD: [0.26862954, 0.26130258, 0.27577711]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TIME_DIFF_PROB: 0.0
  TRAIN_CROP_NUM_SPATIAL: 1
  TRAIN_CROP_NUM_TEMPORAL: 1
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: []
  TRAIN_JITTER_FPS: 0.0
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [224, 256]
  TRAIN_JITTER_SCALES_RELATIVE: []
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: False
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
IMAGENET_SIMPLELABEL_PATH: None
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MASK:
  DECODER_DEPTH: 0
  DECODER_EMBED_DIM: 512
  DECODER_SEP_POS_EMBED: False
  DEC_KV_KERNEL: []
  DEC_KV_STRIDE: []
  ENABLE: False
  HEAD_TYPE: separate
  MAE_ON: False
  MAE_RND_MASK: False
  NORM_PRED_PIXEL: True
  PER_FRAME_MASKING: False
  PRED_HOG: False
  PRETRAIN_DEPTH: [15]
  SCALE_INIT_BY_DEPTH: False
  TIME_STRIDE_LOSS: True
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: False
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ADAPT_FINETUNE_FACTOR: 1.0
  ARCH: vitb16
  CLS_LOSS_RATIO: 1.0
  CONTEXT_LENGTH: 77
  DEFAULT_FINETUNE_FACTOR: 1.0
  DETACH_FINAL_FC: False
  DISTILLATION_RATIO: 2.0
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  ENSEMBLE_PRED: False
  ENSEMBLE_RAWMODEL_RATIO: 0.0
  EXPERT_FINETUNE_FACTOR: 1.0
  EXPERT_INSERT_LAYERS: [10, 11]
  FC_INIT_STD: 0.01
  FINETUNE_FACTOR: 1.0
  FP16_ALLREDUCE: False
  FROZEN_BN: False
  HEAD_ACT: softmax
  KEEP_RAW_MODEL: True
  LOSS_FREQ_TYPE: mse
  LOSS_FUNC: soft_cross_entropy
  MLP_FINETUNE_FACTOR: 1.0
  MODEL_NAME: TemporalClipVideo
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 26
  NUM_EXPERTS: 0
  PROMPT_NUM: 1
  RAW_MODEL_DISTILLATION: True
  RECORD_ROUTING: False
  ROUTING_FINETUNE_FACTOR: 1.0
  ROUTING_FREQUENCE_CONSTRAIN: 0.5
  ROUTING_FREQ_CONS_FACTOR: 1.0
  ROUTING_TYPE: patch-level
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'maskmvit', 'vitb32', 'vitb16', 'vitl14']
  STATIC_GRAPH: False
  TEMPORAL_MODELING_TYPE: expand_temporal_view
  TEXT_PROMPT: False
  USE_CHECKPOINT: False
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 16
  DIM_MUL: []
  DIM_MUL_IN_ATT: False
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.1
  EMBED_DIM: 96
  HEAD_INIT_SCALE: 1.0
  HEAD_MUL: []
  LAYER_SCALE_INIT_VALUE: 0.0
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [2, 4, 4]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: None
  POOL_KV_STRIDE: []
  POOL_KV_STRIDE_ADAPTIVE: None
  POOL_Q_STRIDE: []
  QKV_BIAS: True
  REL_POS_SPATIAL: False
  REL_POS_TEMPORAL: False
  REL_POS_ZERO_INIT: False
  RESIDUAL_POOLING: False
  REV:
    BUFFER_LAYERS: []
    ENABLE: False
    PRE_Q_FUSION: avg
    RESPATH_FUSE: concat
    RES_PATH: conv
  SEPARATE_QKV: False
  SEP_POS_EMBED: False
  USE_ABS_POS: True
  USE_FIXED_SINCOS_POS: False
  USE_MEAN_POOLING: False
  ZERO_DECAY_POS_CLS: True
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 8
NUM_SHARDS: 1
OUTPUT_DIR: /mnt/SSD8T/home/huangwei/projects/FROSTER/checkpoints/basetraining/B2N_hmdb51_froster_exp02
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
  ZERO_INIT_FINAL_CONV: False
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 3.33e-06
  BASE_LR_SCALE_NUM_SHARDS: True
  BETAS: (0.9, 0.999)
  CLIP_GRAD_L2NORM: 1.0
  CLIP_GRAD_VAL: None
  COSINE_AFTER_WARMUP: True
  COSINE_END_LR: 3.33e-08
  COSINE_RESTART_EPOCH: 0
  DAMPENING: 0.0
  GAMMA: 0.1
  LARS_ON: False
  LAYER_DECAY: 1.0
  LRS: []
  LR_POLICY: cosine
  MAX_EPOCH: 12
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: []
  STEP_SIZE: 1
  WARMUP_EPOCHS: 2.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 3.33e-08
  WEIGHT_DECAY: 0.01
  ZERO_WD_1D_PARAM: True
TASK: 
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 240
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_TYPE: pytorch
  CLIP_ORI_PATH: None
  CUSTOM_LOAD: False
  CUSTOM_LOAD_FILE: None
  DATASET: kinetics
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 3
  NUM_SPATIAL_CROPS: 1
  NUM_TEMPORAL_CLIPS: [3]
  OPENSET: False
  PATCHING_MODEL: False
  PATCHING_RATIO: 0.5
  SAVE_RESULTS_PATH: 
  UPDATE_STATE: False
TEST_FILE: test.csv
TRAIN:
  ADAPT_ZS_CONS_RATIO: False
  AUTO_RESUME: True
  BATCH_SIZE: 32
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_INFLATE: False
  CHECKPOINT_IN_INIT: False
  CHECKPOINT_PERIOD: 1
  CHECKPOINT_TYPE: pytorch
  CLIP_ORI_PATH: /mnt/SSD8T/home/huangwei/.cache/clip/ViT-B-16.pt
  CUSTOM_LOAD: False
  CUSTOM_LOAD_FILE: None
  DATASET: kinetics
  ENABLE: True
  EVAL_PERIOD: 1
  EWC_CONSTRAIN_RATIO: 1.0
  EWC_IDENTITY_FISHER: False
  EWC_IGNORE_LOGIT_SCALE: False
  EWC_LOAD_FILE: None
  EWC_SET: False
  KILL_LOSS_EXPLOSION_FACTOR: 0.0
  LINEAR_CONNECT_CLIMB: False
  LINEAR_CONNECT_LOSS_RATIO: 0.0
  LINEAR_CONNECT_SAMPLE: True
  LINEAR_CONNECT_SAMPLE_L: 0.4
  LINEAR_CONNECT_SAMPLE_R: 0.6
  MIXED_PRECISION: True
  ZS_CONS: False
  ZS_CONS_RATIO: 0.8
  ZS_INIT_CONS: False
  ZS_RESTART_CONS: False
  ZS_RESTART_EPOCH: -1
TRAIN_FILE: train_all.csv
TUNE_HEAD: False
VAL_FILE: val.csv
VAL_MODE: False
VIS_MASK:
  ENABLE: False
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[12/16 21:03:56][INFO] temporalclip_video_model.py:  657: load pretrained CLIP:<All keys matched successfully>
[12/16 21:04:04][INFO] temporalclip_video_model.py:  657: load pretrained CLIP:<All keys matched successfully>
[12/16 21:04:05][INFO] checkpoint.py:  222: Loading network weights from /mnt/SSD8T/home/huangwei/projects/FROSTER/checkpoints/basetraining/B2N_hmdb51_froster_exp02/checkpoints/checkpoint_epoch_00012.pyth.
missing keys: []
unexpected keys: []
[12/16 21:04:07][INFO] misc.py:  185: Model:
DistributedDataParallel(
  (module): TemporalClipVideo(
    (model): WCLIP(
      (visual): TemporalVisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): TSTransformer(
          (resblocks): Sequential(
            (0): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (raw_model): WCLIP(
      (visual): TemporalVisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): TSTransformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (projector_v): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): GELU()
      (2): Linear(in_features=512, out_features=512, bias=False)
    )
    (projector_t): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): GELU()
      (2): Linear(in_features=512, out_features=512, bias=False)
    )
  )
)
[12/16 21:04:07][INFO] misc.py:  187: Params: 300,290,050
[12/16 21:04:07][INFO] misc.py:  188: Mem: 1.6999154090881348 MB
[12/16 21:04:07][INFO] misc.py:  197: nvidia-smi
Mon Dec 16 21:04:07 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  Off |
| 42%   29C    P2    66W / 450W |   5062MiB / 24564MiB |     23%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:23:00.0 Off |                  Off |
| 41%   29C    P2    65W / 450W |   5062MiB / 24564MiB |     14%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:41:00.0 Off |                  Off |
| 41%   31C    P2    72W / 450W |   5062MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:61:00.0 Off |                  Off |
| 40%   30C    P2    69W / 450W |   5062MiB / 24564MiB |     13%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   4  NVIDIA GeForce ...  Off  | 00000000:81:00.0 Off |                  Off |
| 42%   29C    P2    65W / 450W |   5062MiB / 24564MiB |     11%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   5  NVIDIA GeForce ...  Off  | 00000000:A1:00.0 Off |                  Off |
| 41%   28C    P2    65W / 450W |   5062MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   6  NVIDIA GeForce ...  Off  | 00000000:C1:00.0 Off |                  Off |
| 42%   29C    P2    60W / 450W |   5062MiB / 24564MiB |      4%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   7  NVIDIA GeForce ...  Off  | 00000000:E1:00.0 Off |                  Off |
| 39%   28C    P2    66W / 450W |   5062MiB / 24564MiB |      4%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    0   N/A  N/A   1766188      C   .../envs/slowfast/bin/python     5054MiB |
|    1   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    1   N/A  N/A   1766189      C   .../envs/slowfast/bin/python     5054MiB |
|    2   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    2   N/A  N/A   1766190      C   .../envs/slowfast/bin/python     5054MiB |
|    3   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    3   N/A  N/A   1766191      C   .../envs/slowfast/bin/python     5054MiB |
|    4   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    4   N/A  N/A   1766193      C   .../envs/slowfast/bin/python     5054MiB |
|    5   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    5   N/A  N/A   1766194      C   .../envs/slowfast/bin/python     5054MiB |
|    6   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    6   N/A  N/A   1766196      C   .../envs/slowfast/bin/python     5054MiB |
|    7   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    7   N/A  N/A   1766198      C   .../envs/slowfast/bin/python     5054MiB |
+-----------------------------------------------------------------------------+
[12/16 21:04:08][INFO] misc.py:  185: Model:
DistributedDataParallel(
  (module): TemporalClipVideo(
    (model): WCLIP(
      (visual): TemporalVisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): TSTransformer(
          (resblocks): Sequential(
            (0): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (raw_model): WCLIP(
      (visual): TemporalVisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): TSTransformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (projector_v): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): GELU()
      (2): Linear(in_features=512, out_features=512, bias=False)
    )
    (projector_t): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): GELU()
      (2): Linear(in_features=512, out_features=512, bias=False)
    )
  )
)
[12/16 21:04:08][INFO] misc.py:  187: Params: 300,290,050
[12/16 21:04:08][INFO] misc.py:  188: Mem: 1.6999154090881348 MB
[12/16 21:04:08][INFO] misc.py:  197: nvidia-smi
Mon Dec 16 21:04:08 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  Off |
| 42%   28C    P2    64W / 450W |   5062MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:23:00.0 Off |                  Off |
| 41%   28C    P2    61W / 450W |   5062MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:41:00.0 Off |                  Off |
| 41%   30C    P2    63W / 450W |   5062MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:61:00.0 Off |                  Off |
| 40%   29C    P2    59W / 450W |   5062MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   4  NVIDIA GeForce ...  Off  | 00000000:81:00.0 Off |                  Off |
| 42%   29C    P2    62W / 450W |   5062MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   5  NVIDIA GeForce ...  Off  | 00000000:A1:00.0 Off |                  Off |
| 41%   28C    P2    65W / 450W |   5062MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   6  NVIDIA GeForce ...  Off  | 00000000:C1:00.0 Off |                  Off |
| 42%   28C    P2    54W / 450W |   5062MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   7  NVIDIA GeForce ...  Off  | 00000000:E1:00.0 Off |                  Off |
| 40%   27C    P2    61W / 450W |   5062MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    0   N/A  N/A   1766188      C   .../envs/slowfast/bin/python     5054MiB |
|    1   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    1   N/A  N/A   1766189      C   .../envs/slowfast/bin/python     5054MiB |
|    2   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    2   N/A  N/A   1766190      C   .../envs/slowfast/bin/python     5054MiB |
|    3   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    3   N/A  N/A   1766191      C   .../envs/slowfast/bin/python     5054MiB |
|    4   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    4   N/A  N/A   1766193      C   .../envs/slowfast/bin/python     5054MiB |
|    5   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    5   N/A  N/A   1766194      C   .../envs/slowfast/bin/python     5054MiB |
|    6   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    6   N/A  N/A   1766196      C   .../envs/slowfast/bin/python     5054MiB |
|    7   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    7   N/A  N/A   1766198      C   .../envs/slowfast/bin/python     5054MiB |
+-----------------------------------------------------------------------------+
[12/16 21:04:09][INFO] kinetics.py:   94: Constructing Kinetics test...
path: ---------------------------- /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/test.csv
[12/16 21:04:09][INFO] kinetics.py:  172: Constructing kinetics dataloader (size: 2250 skip_rows 0) from /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/test.csv 
[12/16 21:04:09][INFO] test_net.py:  434: Testing model for 10 iterations
exponential temporal pooling in test
alpha:0.2
[12/16 21:04:34][INFO] logging.py:   99: json_stats: {"cur_iter": "1", "eta": "0:04:08", "split": "test_iter", "time_diff": 24.89600859}
exponential temporal pooling in test
alpha:0.2
[12/16 21:04:34][INFO] logging.py:   99: json_stats: {"cur_iter": "2", "eta": "0:00:06", "split": "test_iter", "time_diff": 0.68037580}
exponential temporal pooling in test
alpha:0.2
[12/16 21:04:35][INFO] logging.py:   99: json_stats: {"cur_iter": "3", "eta": "0:00:04", "split": "test_iter", "time_diff": 0.58336307}
exponential temporal pooling in test
alpha:0.2
[12/16 21:04:36][INFO] logging.py:   99: json_stats: {"cur_iter": "4", "eta": "0:00:04", "split": "test_iter", "time_diff": 0.58075688}
exponential temporal pooling in test
alpha:0.2
[12/16 21:04:36][INFO] logging.py:   99: json_stats: {"cur_iter": "5", "eta": "0:00:03", "split": "test_iter", "time_diff": 0.57731962}
exponential temporal pooling in test
alpha:0.2
[12/16 21:04:37][INFO] logging.py:   99: json_stats: {"cur_iter": "6", "eta": "0:00:02", "split": "test_iter", "time_diff": 0.57554981}
exponential temporal pooling in test
alpha:0.2
[12/16 21:04:37][INFO] logging.py:   99: json_stats: {"cur_iter": "7", "eta": "0:00:02", "split": "test_iter", "time_diff": 0.58189866}
exponential temporal pooling in test
alpha:0.2
[12/16 21:04:38][INFO] logging.py:   99: json_stats: {"cur_iter": "8", "eta": "0:00:01", "split": "test_iter", "time_diff": 0.57369960}
exponential temporal pooling in test
alpha:0.2
[12/16 21:04:39][INFO] logging.py:   99: json_stats: {"cur_iter": "9", "eta": "0:00:01", "split": "test_iter", "time_diff": 0.57735684}
exponential temporal pooling in test
alpha:0.2
[12/16 21:04:39][INFO] logging.py:   99: json_stats: {"cur_iter": "10", "eta": "0:00:00", "split": "test_iter", "time_diff": 0.32975230}
[12/16 21:04:41][WARNING] meters.py:  394: clip count Ids=tensor([[ 14,  53, 175, 519, 639, 669]]) = tensor([4, 4, 4, 4, 4, 4]) (should be 3)
[12/16 21:04:41][INFO] logging.py:   99: json_stats: {"split": "test_final", "top1_acc": "8.80", "top5_acc": "22.13"}
[12/16 21:04:41][INFO] test_net.py:  474: Finalized testing with 3 temporal clips and 1 spatial crops
[12/16 21:04:41][INFO] test_net.py:  496: _p300.29_f10.00_3a8.80 Top5 Acc: 22.13 MEM: 7.04 f: 10.0000
[12/16 21:04:41][INFO] test_net.py:  497: _p300.29_f10.00_3a8.80
clip count Ids=tensor([[ 14,  53, 175, 519, 639, 669]]) = tensor([4, 4, 4, 4, 4, 4]) (should be 3)
clip count Ids=tensor([[ 14,  53, 175, 519, 639, 669]]) = tensor([4, 4, 4, 4, 4, 4]) (should be 3)
clip count Ids=tensor([[ 14,  53, 175, 519, 639, 669]]) = tensor([4, 4, 4, 4, 4, 4]) (should be 3)
clip count Ids=tensor([[ 14,  53, 175, 519, 639, 669]]) = tensor([4, 4, 4, 4, 4, 4]) (should be 3)
clip count Ids=tensor([[ 14,  53, 175, 519, 639, 669]]) = tensor([4, 4, 4, 4, 4, 4]) (should be 3)
clip count Ids=tensor([[ 14,  53, 175, 519, 639, 669]]) = tensor([4, 4, 4, 4, 4, 4]) (should be 3)
clip count Ids=tensor([[ 14,  53, 175, 519, 639, 669]]) = tensor([4, 4, 4, 4, 4, 4]) (should be 3)
