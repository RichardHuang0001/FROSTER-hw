nohup: ignoring input
config files: ['configs/Kinetics/TemporalCLIP_vitb16_8x16_STAdapter_HMDB51.yaml']
[12/02 23:55:00][INFO] test_net.py:  319: Test with config:
[12/02 23:55:00][INFO] test_net.py:  320: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: False
  GEN_MASK_LOADER: False
  INTERPOLATION: bicubic
  MASK_FRAMES: False
  MASK_RATIO: 0.0
  MASK_TUBE: False
  MASK_WINDOW_SIZE: [8, 7, 7]
  MAX_MASK_PATCHES_PER_BLOCK: None
  NUM_SAMPLE: 2
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  BGR: False
  DETECTION_SCORE_THRESH: 0.9
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: /mnt/fair-flash3-east/ava_trainval_frames.img/
  FRAME_LIST_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  FULL_TEST_ON_VAL: False
  GROUNDTRUTH_FILE: ava_val_v2.2.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: ava_action_list_v2.2_for_activitynet_2019.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_val_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train_v2.2.csv']
  TRAIN_LISTS: ['train_all.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  GLOBAL_SYNC: False
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
CONTRASTIVE:
  BN_MLP: False
  BN_SYNC_MLP: False
  DELTA_CLIPS_MAX: inf
  DELTA_CLIPS_MIN: -inf
  DIM: 128
  INTERP_MEMORY: False
  KNN_ON: True
  LENGTH: 239975
  LOCAL_SHUFFLE_BN: True
  MEM_TYPE: 1d
  MLP_DIM: 2048
  MOCO_MULTI_VIEW_QUEUE: False
  MOMENTUM: 0.5
  MOMENTUM_ANNEALING: False
  NUM_CLASSES_DOWNSTREAM: 400
  NUM_MLP_LAYERS: 1
  PREDICTOR_DEPTHS: []
  QUEUE_LEN: 65536
  SEQUENTIAL: False
  SIMCLR_DIST_ON: True
  SWAV_QEUE_LEN: 0
  T: 0.07
  TYPE: mem
DATA:
  COLOR_RND_GRAYSCALE: 0.0
  DECODING_BACKEND: pyav
  DECODING_SHORT_SIZE: 256
  DUMMY_LOAD: False
  ENSEMBLE_METHOD: sum
  IN22K_TRAINVAL: False
  IN22k_VAL_IN1K: 
  INDEX_LABEL_MAPPING_FILE: /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/train_rephrased.json
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  IN_VAL_CROP_RATIO: 0.875
  LOADER_CHUNK_OVERALL_SIZE: 0
  LOADER_CHUNK_SIZE: 0
  MEAN: [0.48145466, 0.4578275, 0.40821073]
  MULTI_LABEL: False
  NUM_FRAMES: 8
  PATH_LABEL_SEPARATOR: ,
  PATH_PREFIX: /mnt/SSD8T/home/huangwei/projects/FROSTER/data/hmdb51
  PATH_TO_DATA_DIR: /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb
  PATH_TO_PRELOAD_IMDB: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 16
  SKIP_ROWS: 0
  SSL_BLUR_SIGMA_MAX: [0.0, 2.0]
  SSL_BLUR_SIGMA_MIN: [0.0, 0.1]
  SSL_COLOR_BRI_CON_SAT: [0.4, 0.4, 0.4]
  SSL_COLOR_HUE: 0.1
  SSL_COLOR_JITTER: False
  SSL_MOCOV2_AUG: False
  STD: [0.26862954, 0.26130258, 0.27577711]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TIME_DIFF_PROB: 0.0
  TRAIN_CROP_NUM_SPATIAL: 1
  TRAIN_CROP_NUM_TEMPORAL: 1
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: []
  TRAIN_JITTER_FPS: 0.0
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [224, 256]
  TRAIN_JITTER_SCALES_RELATIVE: []
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 4
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: False
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
IMAGENET_SIMPLELABEL_PATH: None
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MASK:
  DECODER_DEPTH: 0
  DECODER_EMBED_DIM: 512
  DECODER_SEP_POS_EMBED: False
  DEC_KV_KERNEL: []
  DEC_KV_STRIDE: []
  ENABLE: False
  HEAD_TYPE: separate
  MAE_ON: False
  MAE_RND_MASK: False
  NORM_PRED_PIXEL: True
  PER_FRAME_MASKING: False
  PRED_HOG: False
  PRETRAIN_DEPTH: [15]
  SCALE_INIT_BY_DEPTH: False
  TIME_STRIDE_LOSS: True
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: False
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ADAPT_FINETUNE_FACTOR: 1.0
  ARCH: vitb16
  CLS_LOSS_RATIO: 1.0
  CONTEXT_LENGTH: 77
  DEFAULT_FINETUNE_FACTOR: 1.0
  DETACH_FINAL_FC: False
  DISTILLATION_RATIO: 2.0
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  ENSEMBLE_PRED: False
  ENSEMBLE_RAWMODEL_RATIO: 0.0
  EXPERT_FINETUNE_FACTOR: 1.0
  EXPERT_INSERT_LAYERS: [10, 11]
  FC_INIT_STD: 0.01
  FINETUNE_FACTOR: 1.0
  FP16_ALLREDUCE: False
  FROZEN_BN: False
  HEAD_ACT: softmax
  KEEP_RAW_MODEL: False
  LOSS_FREQ_TYPE: mse
  LOSS_FUNC: cross_entropy
  MLP_FINETUNE_FACTOR: 1.0
  MODEL_NAME: TemporalClipVideo
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 26
  NUM_EXPERTS: 0
  PROMPT_NUM: 1
  RAW_MODEL_DISTILLATION: False
  RECORD_ROUTING: False
  ROUTING_FINETUNE_FACTOR: 1.0
  ROUTING_FREQUENCE_CONSTRAIN: 0.5
  ROUTING_FREQ_CONS_FACTOR: 1.0
  ROUTING_TYPE: patch-level
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'maskmvit', 'vitb32', 'vitb16', 'vitl14']
  STATIC_GRAPH: False
  TEMPORAL_MODELING_TYPE: expand_temporal_view
  TEXT_PROMPT: False
  USE_CHECKPOINT: False
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 16
  DIM_MUL: []
  DIM_MUL_IN_ATT: False
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.1
  EMBED_DIM: 96
  HEAD_INIT_SCALE: 1.0
  HEAD_MUL: []
  LAYER_SCALE_INIT_VALUE: 0.0
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [2, 4, 4]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: None
  POOL_KV_STRIDE: []
  POOL_KV_STRIDE_ADAPTIVE: None
  POOL_Q_STRIDE: []
  QKV_BIAS: True
  REL_POS_SPATIAL: False
  REL_POS_TEMPORAL: False
  REL_POS_ZERO_INIT: False
  RESIDUAL_POOLING: False
  REV:
    BUFFER_LAYERS: []
    ENABLE: False
    PRE_Q_FUSION: avg
    RESPATH_FUSE: concat
    RES_PATH: conv
  SEPARATE_QKV: False
  SEP_POS_EMBED: False
  USE_ABS_POS: True
  USE_FIXED_SINCOS_POS: False
  USE_MEAN_POOLING: False
  ZERO_DECAY_POS_CLS: True
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 4
NUM_SHARDS: 1
OUTPUT_DIR: /mnt/SSD8T/home/huangwei/projects/FROSTER/checkpoints/basetraining/B2N_hmdb51_froster/testing
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
  ZERO_INIT_FINAL_CONV: False
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 3.33e-06
  BASE_LR_SCALE_NUM_SHARDS: True
  BETAS: (0.9, 0.999)
  CLIP_GRAD_L2NORM: 1.0
  CLIP_GRAD_VAL: None
  COSINE_AFTER_WARMUP: True
  COSINE_END_LR: 1e-07
  COSINE_RESTART_EPOCH: 0
  DAMPENING: 0.0
  GAMMA: 0.1
  LARS_ON: False
  LAYER_DECAY: 1.0
  LRS: []
  LR_POLICY: cosine
  MAX_EPOCH: 12
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: []
  STEP_SIZE: 1
  WARMUP_EPOCHS: 2.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-07
  WEIGHT_DECAY: 0.01
  ZERO_WD_1D_PARAM: True
TASK: 
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 120
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_TYPE: pytorch
  CLIP_ORI_PATH: /mnt/SSD8T/home/huangwei/.cache/clip/ViT-B-16.pt
  CUSTOM_LOAD: True
  CUSTOM_LOAD_FILE: /mnt/SSD8T/home/huangwei/projects/FROSTER/checkpoints/basetraining/B2N_hmdb51_froster/checkpoints/checkpoint_epoch_00012.pyth
  DATASET: kinetics
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 3
  NUM_SPATIAL_CROPS: 1
  NUM_TEMPORAL_CLIPS: [3]
  OPENSET: False
  PATCHING_MODEL: False
  PATCHING_RATIO: 0.5
  SAVE_RESULTS_PATH: temp.pyth
  UPDATE_STATE: False
TEST_FILE: val.csv
TRAIN:
  ADAPT_ZS_CONS_RATIO: False
  AUTO_RESUME: True
  BATCH_SIZE: 64
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_INFLATE: False
  CHECKPOINT_IN_INIT: False
  CHECKPOINT_PERIOD: 5
  CHECKPOINT_TYPE: pytorch
  CLIP_ORI_PATH: None
  CUSTOM_LOAD: False
  CUSTOM_LOAD_FILE: None
  DATASET: kinetics
  ENABLE: False
  EVAL_PERIOD: 5
  EWC_CONSTRAIN_RATIO: 1.0
  EWC_IDENTITY_FISHER: False
  EWC_IGNORE_LOGIT_SCALE: False
  EWC_LOAD_FILE: None
  EWC_SET: False
  KILL_LOSS_EXPLOSION_FACTOR: 0.0
  LINEAR_CONNECT_CLIMB: False
  LINEAR_CONNECT_LOSS_RATIO: 1.0
  LINEAR_CONNECT_SAMPLE: True
  LINEAR_CONNECT_SAMPLE_L: 0.4
  LINEAR_CONNECT_SAMPLE_R: 0.6
  MIXED_PRECISION: False
  ZS_CONS: False
  ZS_CONS_RATIO: 0.8
  ZS_INIT_CONS: False
  ZS_RESTART_CONS: False
  ZS_RESTART_EPOCH: -1
TRAIN_FILE: train.csv
TUNE_HEAD: False
VAL_FILE: val.csv
VAL_MODE: False
VIS_MASK:
  ENABLE: False
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[12/02 23:55:05][INFO] temporalclip_video_model.py:  604: load pretrained CLIP:<All keys matched successfully>
[12/02 23:55:10][INFO] test_net.py:  333: Loading custom network weights from /mnt/SSD8T/home/huangwei/projects/FROSTER/checkpoints/basetraining/B2N_hmdb51_froster/checkpoints/checkpoint_epoch_00012.pyth.
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.positional_embedding
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.text_projection
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.logit_scale
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.class_embedding
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.positional_embedding
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.proj
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.conv1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.ln_pre.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.ln_pre.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.0.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.0.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.0.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.0.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.1.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.1.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.1.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.1.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.2.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.2.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.2.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.2.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.3.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.3.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.3.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.3.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.4.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.4.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.4.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.4.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.5.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.5.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.5.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.5.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.6.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.6.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.6.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.6.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.7.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.7.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.7.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.7.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.8.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.8.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.8.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.8.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.9.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.9.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.9.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.9.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.10.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.10.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.10.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.10.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.11.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.11.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.11.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.transformer.resblocks.11.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.ln_post.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.visual.ln_post.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.0.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.0.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.0.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.0.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.0.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.0.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.0.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.0.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.0.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.0.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.0.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.0.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.1.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.1.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.1.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.1.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.1.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.1.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.1.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.1.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.1.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.1.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.1.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.1.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.2.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.2.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.2.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.2.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.2.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.2.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.2.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.2.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.2.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.2.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.2.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.2.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.3.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.3.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.3.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.3.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.3.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.3.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.3.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.3.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.3.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.3.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.3.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.3.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.4.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.4.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.4.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.4.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.4.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.4.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.4.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.4.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.4.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.4.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.4.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.4.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.5.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.5.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.5.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.5.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.5.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.5.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.5.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.5.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.5.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.5.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.5.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.5.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.6.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.6.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.6.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.6.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.6.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.6.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.6.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.6.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.6.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.6.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.6.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.6.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.7.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.7.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.7.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.7.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.7.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.7.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.7.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.7.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.7.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.7.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.7.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.7.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.8.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.8.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.8.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.8.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.8.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.8.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.8.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.8.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.8.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.8.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.8.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.8.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.9.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.9.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.9.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.9.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.9.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.9.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.9.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.9.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.9.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.9.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.9.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.9.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.10.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.10.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.10.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.10.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.10.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.10.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.10.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.10.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.10.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.10.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.10.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.10.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.11.attn.in_proj_weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.11.attn.in_proj_bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.11.attn.out_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.11.attn.out_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.11.ln_1.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.11.ln_1.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.11.mlp.c_fc.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.11.mlp.c_fc.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.11.mlp.c_proj.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.11.mlp.c_proj.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.11.ln_2.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.transformer.resblocks.11.ln_2.bias
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.token_embedding.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.ln_final.weight
[12/02 23:55:11][INFO] test_net.py:  404: missing parameters
[12/02 23:55:11][INFO] test_net.py:  405: module.raw_model.ln_final.bias
[12/02 23:55:11][INFO] misc.py:  185: Model:
DistributedDataParallel(
  (module): TemporalClipVideo(
    (model): WCLIP(
      (visual): TemporalVisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): TSTransformer(
          (resblocks): Sequential(
            (0): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (projector_v): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): GELU()
      (2): Linear(in_features=512, out_features=512, bias=False)
    )
    (projector_t): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): GELU()
      (2): Linear(in_features=512, out_features=512, bias=False)
    )
  )
)
[12/02 23:55:11][INFO] misc.py:  187: Params: 150,669,313
[12/02 23:55:11][INFO] misc.py:  188: Mem: 1.1396045684814453 MB
[12/02 23:55:11][INFO] misc.py:  197: nvidia-smi
Mon Dec  2 23:55:11 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  Off |
| 42%   22C    P8    29W / 450W |   4452MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:23:00.0 Off |                  Off |
| 41%   26C    P2    64W / 450W |   6976MiB / 24564MiB |     15%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:41:00.0 Off |                  Off |
| 41%   27C    P2    69W / 450W |   6944MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:61:00.0 Off |                  Off |
| 40%   26C    P2    65W / 450W |   6974MiB / 24564MiB |     13%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   4  NVIDIA GeForce ...  Off  | 00000000:81:00.0 Off |                  Off |
| 42%   26C    P2    64W / 450W |   6974MiB / 24564MiB |      5%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   5  NVIDIA GeForce ...  Off  | 00000000:A1:00.0 Off |                  Off |
| 41%   23C    P8    21W / 450W |   3104MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   6  NVIDIA GeForce ...  Off  | 00000000:C1:00.0 Off |                  Off |
| 42%   29C    P2    71W / 450W |  22502MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   7  NVIDIA GeForce ...  Off  | 00000000:E1:00.0 Off |                  Off |
| 40%   22C    P8    16W / 450W |   4290MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      2891      G   /usr/lib/xorg/Xorg                  4MiB |
|    0   N/A  N/A   4075274      C   python                           4444MiB |
|    1   N/A  N/A      2891      G   /usr/lib/xorg/Xorg                  4MiB |
|    1   N/A  N/A    629855      C   .../envs/slowfast/bin/python     3870MiB |
|    1   N/A  N/A   4075274      C   python                           3096MiB |
|    2   N/A  N/A      2891      G   /usr/lib/xorg/Xorg                  4MiB |
|    2   N/A  N/A    629856      C   .../envs/slowfast/bin/python     3870MiB |
|    2   N/A  N/A   4075274      C   python                           3066MiB |
|    3   N/A  N/A      2891      G   /usr/lib/xorg/Xorg                  4MiB |
|    3   N/A  N/A    629857      C   .../envs/slowfast/bin/python     3870MiB |
|    3   N/A  N/A   4075274      C   python                           3096MiB |
|    4   N/A  N/A      2891      G   /usr/lib/xorg/Xorg                  4MiB |
|    4   N/A  N/A    629858      C   .../envs/slowfast/bin/python     3870MiB |
|    4   N/A  N/A   4075274      C   python                           3096MiB |
|    5   N/A  N/A      2891      G   /usr/lib/xorg/Xorg                  4MiB |
|    5   N/A  N/A   4075274      C   python                           3096MiB |
|    6   N/A  N/A      2891      G   /usr/lib/xorg/Xorg                  4MiB |
|    6   N/A  N/A    147830      C   python                          19452MiB |
|    6   N/A  N/A   4075274      C   python                           3042MiB |
|    7   N/A  N/A      2891      G   /usr/lib/xorg/Xorg                  4MiB |
|    7   N/A  N/A   4075274      C   python                           4280MiB |
+-----------------------------------------------------------------------------+
[12/02 23:55:13][INFO] misc.py:  185: Model:
DistributedDataParallel(
  (module): TemporalClipVideo(
    (model): WCLIP(
      (visual): TemporalVisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): TSTransformer(
          (resblocks): Sequential(
            (0): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (projector_v): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): GELU()
      (2): Linear(in_features=512, out_features=512, bias=False)
    )
    (projector_t): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): GELU()
      (2): Linear(in_features=512, out_features=512, bias=False)
    )
  )
)
[12/02 23:55:13][INFO] misc.py:  187: Params: 150,669,313
[12/02 23:55:13][INFO] misc.py:  188: Mem: 1.1396045684814453 MB
[12/02 23:55:13][INFO] misc.py:  197: nvidia-smi
Mon Dec  2 23:55:13 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  Off |
| 42%   22C    P8    29W / 450W |   4452MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:23:00.0 Off |                  Off |
| 41%   25C    P2    61W / 450W |   6976MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:41:00.0 Off |                  Off |
| 41%   27C    P2    66W / 450W |   6944MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:61:00.0 Off |                  Off |
| 40%   26C    P2    65W / 450W |   6974MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   4  NVIDIA GeForce ...  Off  | 00000000:81:00.0 Off |                  Off |
| 42%   26C    P2    62W / 450W |   6974MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   5  NVIDIA GeForce ...  Off  | 00000000:A1:00.0 Off |                  Off |
| 41%   23C    P8    22W / 450W |   3104MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   6  NVIDIA GeForce ...  Off  | 00000000:C1:00.0 Off |                  Off |
| 42%   29C    P2    61W / 450W |  22502MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   7  NVIDIA GeForce ...  Off  | 00000000:E1:00.0 Off |                  Off |
| 40%   22C    P8    16W / 450W |   4290MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      2891      G   /usr/lib/xorg/Xorg                  4MiB |
|    0   N/A  N/A   4075274      C   python                           4444MiB |
|    1   N/A  N/A      2891      G   /usr/lib/xorg/Xorg                  4MiB |
|    1   N/A  N/A    629855      C   .../envs/slowfast/bin/python     3870MiB |
|    1   N/A  N/A   4075274      C   python                           3096MiB |
|    2   N/A  N/A      2891      G   /usr/lib/xorg/Xorg                  4MiB |
|    2   N/A  N/A    629856      C   .../envs/slowfast/bin/python     3870MiB |
|    2   N/A  N/A   4075274      C   python                           3066MiB |
|    3   N/A  N/A      2891      G   /usr/lib/xorg/Xorg                  4MiB |
|    3   N/A  N/A    629857      C   .../envs/slowfast/bin/python     3870MiB |
|    3   N/A  N/A   4075274      C   python                           3096MiB |
|    4   N/A  N/A      2891      G   /usr/lib/xorg/Xorg                  4MiB |
|    4   N/A  N/A    629858      C   .../envs/slowfast/bin/python     3870MiB |
|    4   N/A  N/A   4075274      C   python                           3096MiB |
|    5   N/A  N/A      2891      G   /usr/lib/xorg/Xorg                  4MiB |
|    5   N/A  N/A   4075274      C   python                           3096MiB |
|    6   N/A  N/A      2891      G   /usr/lib/xorg/Xorg                  4MiB |
|    6   N/A  N/A    147830      C   python                          19452MiB |
|    6   N/A  N/A   4075274      C   python                           3042MiB |
|    7   N/A  N/A      2891      G   /usr/lib/xorg/Xorg                  4MiB |
|    7   N/A  N/A   4075274      C   python                           4280MiB |
+-----------------------------------------------------------------------------+
[12/02 23:55:13][INFO] kinetics.py:   94: Constructing Kinetics test...
path: ---------------------------- /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/val.csv
[12/02 23:55:13][INFO] kinetics.py:  172: Constructing kinetics dataloader (size: 2322 skip_rows 0) from /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/val.csv 
[12/02 23:55:13][INFO] test_net.py:  434: Testing model for 20 iterations
[12/02 23:55:29][INFO] logging.py:   99: json_stats: {"cur_iter": "1", "eta": "0:05:02", "split": "test_iter", "time_diff": 15.14034333}
[12/02 23:55:30][INFO] logging.py:   99: json_stats: {"cur_iter": "2", "eta": "0:00:22", "split": "test_iter", "time_diff": 1.19707956}
[12/02 23:55:31][INFO] logging.py:   99: json_stats: {"cur_iter": "3", "eta": "0:00:10", "split": "test_iter", "time_diff": 0.58825106}
[12/02 23:55:31][INFO] logging.py:   99: json_stats: {"cur_iter": "4", "eta": "0:00:10", "split": "test_iter", "time_diff": 0.61878193}
[12/02 23:55:32][INFO] logging.py:   99: json_stats: {"cur_iter": "5", "eta": "0:00:11", "split": "test_iter", "time_diff": 0.74869955}
[12/02 23:55:33][INFO] logging.py:   99: json_stats: {"cur_iter": "6", "eta": "0:00:09", "split": "test_iter", "time_diff": 0.64779951}
[12/02 23:55:33][INFO] logging.py:   99: json_stats: {"cur_iter": "7", "eta": "0:00:08", "split": "test_iter", "time_diff": 0.62904732}
[12/02 23:55:34][INFO] logging.py:   99: json_stats: {"cur_iter": "8", "eta": "0:00:08", "split": "test_iter", "time_diff": 0.63367341}
[12/02 23:55:34][INFO] logging.py:   99: json_stats: {"cur_iter": "9", "eta": "0:00:07", "split": "test_iter", "time_diff": 0.60513968}
[12/02 23:55:35][INFO] logging.py:   99: json_stats: {"cur_iter": "10", "eta": "0:00:07", "split": "test_iter", "time_diff": 0.64763606}
[12/02 23:55:36][INFO] logging.py:   99: json_stats: {"cur_iter": "11", "eta": "0:00:06", "split": "test_iter", "time_diff": 0.64147743}
[12/02 23:55:36][INFO] logging.py:   99: json_stats: {"cur_iter": "12", "eta": "0:00:06", "split": "test_iter", "time_diff": 0.66979352}
[12/02 23:55:37][INFO] logging.py:   99: json_stats: {"cur_iter": "13", "eta": "0:00:05", "split": "test_iter", "time_diff": 0.66003477}
[12/02 23:55:38][INFO] logging.py:   99: json_stats: {"cur_iter": "14", "eta": "0:00:04", "split": "test_iter", "time_diff": 0.59575624}
[12/02 23:55:38][INFO] logging.py:   99: json_stats: {"cur_iter": "15", "eta": "0:00:03", "split": "test_iter", "time_diff": 0.57909110}
[12/02 23:55:39][INFO] logging.py:   99: json_stats: {"cur_iter": "16", "eta": "0:00:02", "split": "test_iter", "time_diff": 0.58546005}
[12/02 23:55:39][INFO] logging.py:   99: json_stats: {"cur_iter": "17", "eta": "0:00:02", "split": "test_iter", "time_diff": 0.57422992}
[12/02 23:55:40][INFO] logging.py:   99: json_stats: {"cur_iter": "18", "eta": "0:00:01", "split": "test_iter", "time_diff": 0.59207877}
[12/02 23:55:41][INFO] logging.py:   99: json_stats: {"cur_iter": "19", "eta": "0:00:01", "split": "test_iter", "time_diff": 0.57226908}
[12/02 23:55:41][INFO] logging.py:   99: json_stats: {"cur_iter": "20", "eta": "0:00:00", "split": "test_iter", "time_diff": 0.32292931}
clip count Ids=tensor([[620, 717]]) = tensor([4, 4]) (should be 3)
clip count Ids=tensor([[620, 717]]) = tensor([4, 4]) (should be 3)
clip count Ids=tensor([[620, 717]]) = tensor([4, 4]) (should be 3)
[12/02 23:55:42][INFO] test_net.py:  234: Successfully saved prediction results to /mnt/SSD8T/home/huangwei/projects/FROSTER/checkpoints/basetraining/B2N_hmdb51_froster/testing/temp.pyth
[12/02 23:55:42][WARNING] meters.py:  394: clip count Ids=tensor([[620, 717]]) = tensor([4, 4]) (should be 3)
[12/02 23:55:42][INFO] logging.py:   99: json_stats: {"split": "test_final", "top1_acc": "76.61", "top5_acc": "96.38"}
[12/02 23:55:42][INFO] test_net.py:  474: Finalized testing with 3 temporal clips and 1 spatial crops
[12/02 23:55:42][INFO] test_net.py:  496: _p150.67_f10.00_3a76.61 Top5 Acc: 96.38 MEM: 6.48 f: 10.0000
[12/02 23:55:42][INFO] test_net.py:  497: _p150.67_f10.00_3a76.61
