nohup: ignoring input
config files: ['configs/Kinetics/TemporalCLIP_vitb16_8x16_STAdapter_SSV2.yaml']
[12/16 23:53:39][INFO] train_net.py:  942: --Train with config:
[12/16 23:53:39][INFO] train_net.py:  943: {'AUG': {'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': False,
         'GEN_MASK_LOADER': False,
         'INTERPOLATION': 'bicubic',
         'MASK_FRAMES': False,
         'MASK_RATIO': 0.0,
         'MASK_TUBE': False,
         'MASK_WINDOW_SIZE': [8, 7, 7],
         'MAX_MASK_PATCHES_PER_BLOCK': None,
         'NUM_SAMPLE': 1,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train_all.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'GLOBAL_SYNC': False,
        'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'CONTRASTIVE': {'BN_MLP': False,
                 'BN_SYNC_MLP': False,
                 'DELTA_CLIPS_MAX': inf,
                 'DELTA_CLIPS_MIN': -inf,
                 'DIM': 128,
                 'INTERP_MEMORY': False,
                 'KNN_ON': True,
                 'LENGTH': 239975,
                 'LOCAL_SHUFFLE_BN': True,
                 'MEM_TYPE': '1d',
                 'MLP_DIM': 2048,
                 'MOCO_MULTI_VIEW_QUEUE': False,
                 'MOMENTUM': 0.5,
                 'MOMENTUM_ANNEALING': False,
                 'NUM_CLASSES_DOWNSTREAM': 400,
                 'NUM_MLP_LAYERS': 1,
                 'PREDICTOR_DEPTHS': [],
                 'QUEUE_LEN': 65536,
                 'SEQUENTIAL': False,
                 'SIMCLR_DIST_ON': True,
                 'SWAV_QEUE_LEN': 0,
                 'T': 0.07,
                 'TYPE': 'mem'},
 'DATA': {'COLOR_RND_GRAYSCALE': 0.0,
          'DECODING_BACKEND': 'pyav',
          'DECODING_SHORT_SIZE': 256,
          'DUMMY_LOAD': False,
          'ENSEMBLE_METHOD': 'sum',
          'IN22K_TRAINVAL': False,
          'IN22k_VAL_IN1K': '',
          'INDEX_LABEL_MAPPING_FILE': '/mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_ssv2/train_rephrased.json',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'IN_VAL_CROP_RATIO': 0.875,
          'LOADER_CHUNK_OVERALL_SIZE': 0,
          'LOADER_CHUNK_SIZE': 0,
          'MEAN': [0.48145466, 0.4578275, 0.40821073],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 8,
          'PATH_LABEL_SEPARATOR': ',',
          'PATH_PREFIX': '/mnt/SSD8T/home/huangwei/projects/FROSTER/data/ssv2/videos',
          'PATH_TO_DATA_DIR': '/mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_ssv2',
          'PATH_TO_PRELOAD_IMDB': '',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 16,
          'SKIP_ROWS': 0,
          'SSL_BLUR_SIGMA_MAX': [0.0, 2.0],
          'SSL_BLUR_SIGMA_MIN': [0.0, 0.1],
          'SSL_COLOR_BRI_CON_SAT': [0.4, 0.4, 0.4],
          'SSL_COLOR_HUE': 0.1,
          'SSL_COLOR_JITTER': False,
          'SSL_MOCOV2_AUG': False,
          'STD': [0.26862954, 0.26130258, 0.27577711],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TIME_DIFF_PROB': 0.0,
          'TRAIN_CROP_NUM_SPATIAL': 1,
          'TRAIN_CROP_NUM_TEMPORAL': 1,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [],
          'TRAIN_JITTER_FPS': 0.0,
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [224, 256],
          'TRAIN_JITTER_SCALES_RELATIVE': [],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': True},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'IMAGENET_SIMPLELABEL_PATH': None,
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MASK': {'DECODER_DEPTH': 0,
          'DECODER_EMBED_DIM': 512,
          'DECODER_SEP_POS_EMBED': False,
          'DEC_KV_KERNEL': [],
          'DEC_KV_STRIDE': [],
          'ENABLE': False,
          'HEAD_TYPE': 'separate',
          'MAE_ON': False,
          'MAE_RND_MASK': False,
          'NORM_PRED_PIXEL': True,
          'PER_FRAME_MASKING': False,
          'PRED_HOG': False,
          'PRETRAIN_DEPTH': [15],
          'SCALE_INIT_BY_DEPTH': False,
          'TIME_STRIDE_LOSS': True},
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': False,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ADAPT_FINETUNE_FACTOR': 1.0,
           'ARCH': 'vitb16',
           'CLS_LOSS_RATIO': 1.0,
           'CONTEXT_LENGTH': 77,
           'DEFAULT_FINETUNE_FACTOR': 1.0,
           'DETACH_FINAL_FC': False,
           'DISTILLATION_RATIO': 2.0,
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'ENSEMBLE_PRED': False,
           'ENSEMBLE_RAWMODEL_RATIO': 0.0,
           'EXPERT_FINETUNE_FACTOR': 1.0,
           'EXPERT_INSERT_LAYERS': [10, 11],
           'FC_INIT_STD': 0.01,
           'FINETUNE_FACTOR': 1.0,
           'FP16_ALLREDUCE': False,
           'FROZEN_BN': False,
           'HEAD_ACT': 'softmax',
           'KEEP_RAW_MODEL': True,
           'LOSS_FREQ_TYPE': 'mse',
           'LOSS_FUNC': 'soft_cross_entropy',
           'MLP_FINETUNE_FACTOR': 1.0,
           'MODEL_NAME': 'TemporalClipVideo',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 87,
           'NUM_EXPERTS': 0,
           'PROMPT_NUM': 1,
           'RAW_MODEL_DISTILLATION': True,
           'RECORD_ROUTING': False,
           'ROUTING_FINETUNE_FACTOR': 1.0,
           'ROUTING_FREQUENCE_CONSTRAIN': 0.5,
           'ROUTING_FREQ_CONS_FACTOR': 1.0,
           'ROUTING_TYPE': 'patch-level',
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'maskmvit',
                                   'vitb32',
                                   'vitb16',
                                   'vitl14'],
           'STATIC_GRAPH': False,
           'TEMPORAL_MODELING_TYPE': 'expand_temporal_view',
           'TEXT_PROMPT': False,
           'USE_CHECKPOINT': False},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 16,
          'DIM_MUL': [],
          'DIM_MUL_IN_ATT': False,
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.1,
          'EMBED_DIM': 96,
          'HEAD_INIT_SCALE': 1.0,
          'HEAD_MUL': [],
          'LAYER_SCALE_INIT_VALUE': 0.0,
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [2, 4, 4],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': None,
          'POOL_KV_STRIDE': [],
          'POOL_KV_STRIDE_ADAPTIVE': None,
          'POOL_Q_STRIDE': [],
          'QKV_BIAS': True,
          'REL_POS_SPATIAL': False,
          'REL_POS_TEMPORAL': False,
          'REL_POS_ZERO_INIT': False,
          'RESIDUAL_POOLING': False,
          'REV': {'BUFFER_LAYERS': [],
                  'ENABLE': False,
                  'PRE_Q_FUSION': 'avg',
                  'RESPATH_FUSE': 'concat',
                  'RES_PATH': 'conv'},
          'SEPARATE_QKV': False,
          'SEP_POS_EMBED': False,
          'USE_ABS_POS': True,
          'USE_FIXED_SINCOS_POS': False,
          'USE_MEAN_POOLING': False,
          'ZERO_DECAY_POS_CLS': True},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 8,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '/mnt/SSD8T/home/huangwei/projects/FROSTER/checkpoints/basetraining/B2N_ssv2_froster_exp02',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False,
            'ZERO_INIT_FINAL_CONV': False},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 3.33e-06,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'BETAS': (0.9, 0.999),
            'CLIP_GRAD_L2NORM': 1.0,
            'CLIP_GRAD_VAL': None,
            'COSINE_AFTER_WARMUP': True,
            'COSINE_END_LR': 3.33e-08,
            'COSINE_RESTART_EPOCH': 0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LARS_ON': False,
            'LAYER_DECAY': 1.0,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 12,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 2.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 3.33e-08,
            'WEIGHT_DECAY': 0.01,
            'ZERO_WD_1D_PARAM': True},
 'TASK': '',
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 240,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'CLIP_ORI_PATH': None,
          'CUSTOM_LOAD': False,
          'CUSTOM_LOAD_FILE': None,
          'DATASET': 'kinetics',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 3,
          'NUM_SPATIAL_CROPS': 1,
          'NUM_TEMPORAL_CLIPS': [],
          'OPENSET': False,
          'PATCHING_MODEL': False,
          'PATCHING_RATIO': 0.5,
          'SAVE_RESULTS_PATH': '',
          'UPDATE_STATE': False},
 'TEST_FILE': 'test.csv',
 'TRAIN': {'ADAPT_ZS_CONS_RATIO': False,
           'AUTO_RESUME': True,
           'BATCH_SIZE': 32,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_IN_INIT': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'pytorch',
           'CLIP_ORI_PATH': '/mnt/SSD8T/home/huangwei/.cache/clip/ViT-B-16.pt',
           'CUSTOM_LOAD': False,
           'CUSTOM_LOAD_FILE': None,
           'DATASET': 'kinetics',
           'ENABLE': True,
           'EVAL_PERIOD': 1,
           'EWC_CONSTRAIN_RATIO': 1.0,
           'EWC_IDENTITY_FISHER': False,
           'EWC_IGNORE_LOGIT_SCALE': False,
           'EWC_LOAD_FILE': None,
           'EWC_SET': False,
           'KILL_LOSS_EXPLOSION_FACTOR': 0.0,
           'LINEAR_CONNECT_CLIMB': False,
           'LINEAR_CONNECT_LOSS_RATIO': 0.0,
           'LINEAR_CONNECT_SAMPLE': True,
           'LINEAR_CONNECT_SAMPLE_L': 0.4,
           'LINEAR_CONNECT_SAMPLE_R': 0.6,
           'MIXED_PRECISION': True,
           'ZS_CONS': False,
           'ZS_CONS_RATIO': 0.8,
           'ZS_INIT_CONS': False,
           'ZS_RESTART_CONS': False,
           'ZS_RESTART_EPOCH': -1},
 'TRAIN_FILE': 'train.csv',
 'TUNE_HEAD': False,
 'VAL_FILE': 'test.csv',
 'VAL_MODE': False,
 'VIS_MASK': CfgNode({'ENABLE': False}),
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/16 23:53:43][INFO] temporalclip_video_model.py:  657: load pretrained CLIP:<All keys matched successfully>
[12/16 23:53:51][INFO] temporalclip_video_model.py:  657: load pretrained CLIP:<All keys matched successfully>
[12/16 23:53:53][INFO] train_net.py:  951: total trainable parameters:
[12/16 23:53:53][INFO] train_net.py:  952: ['module.model.positional_embedding',
 'module.model.text_projection',
 'module.model.logit_scale',
 'module.model.visual.class_embedding',
 'module.model.visual.positional_embedding',
 'module.model.visual.proj',
 'module.model.visual.conv1.weight',
 'module.model.visual.ln_pre.weight',
 'module.model.visual.ln_pre.bias',
 'module.model.visual.transformer.resblocks.0.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.0.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.0.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.0.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.0.ln_1.weight',
 'module.model.visual.transformer.resblocks.0.ln_1.bias',
 'module.model.visual.transformer.resblocks.0.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.0.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.0.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.0.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.0.ln_2.weight',
 'module.model.visual.transformer.resblocks.0.ln_2.bias',
 'module.model.visual.transformer.resblocks.1.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.1.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.1.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.1.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.1.ln_1.weight',
 'module.model.visual.transformer.resblocks.1.ln_1.bias',
 'module.model.visual.transformer.resblocks.1.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.1.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.1.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.1.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.1.ln_2.weight',
 'module.model.visual.transformer.resblocks.1.ln_2.bias',
 'module.model.visual.transformer.resblocks.2.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.2.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.2.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.2.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.2.ln_1.weight',
 'module.model.visual.transformer.resblocks.2.ln_1.bias',
 'module.model.visual.transformer.resblocks.2.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.2.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.2.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.2.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.2.ln_2.weight',
 'module.model.visual.transformer.resblocks.2.ln_2.bias',
 'module.model.visual.transformer.resblocks.3.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.3.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.3.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.3.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.3.ln_1.weight',
 'module.model.visual.transformer.resblocks.3.ln_1.bias',
 'module.model.visual.transformer.resblocks.3.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.3.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.3.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.3.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.3.ln_2.weight',
 'module.model.visual.transformer.resblocks.3.ln_2.bias',
 'module.model.visual.transformer.resblocks.4.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.4.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.4.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.4.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.4.ln_1.weight',
 'module.model.visual.transformer.resblocks.4.ln_1.bias',
 'module.model.visual.transformer.resblocks.4.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.4.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.4.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.4.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.4.ln_2.weight',
 'module.model.visual.transformer.resblocks.4.ln_2.bias',
 'module.model.visual.transformer.resblocks.5.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.5.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.5.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.5.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.5.ln_1.weight',
 'module.model.visual.transformer.resblocks.5.ln_1.bias',
 'module.model.visual.transformer.resblocks.5.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.5.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.5.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.5.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.5.ln_2.weight',
 'module.model.visual.transformer.resblocks.5.ln_2.bias',
 'module.model.visual.transformer.resblocks.6.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.6.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.6.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.6.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.6.ln_1.weight',
 'module.model.visual.transformer.resblocks.6.ln_1.bias',
 'module.model.visual.transformer.resblocks.6.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.6.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.6.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.6.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.6.ln_2.weight',
 'module.model.visual.transformer.resblocks.6.ln_2.bias',
 'module.model.visual.transformer.resblocks.7.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.7.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.7.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.7.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.7.ln_1.weight',
 'module.model.visual.transformer.resblocks.7.ln_1.bias',
 'module.model.visual.transformer.resblocks.7.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.7.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.7.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.7.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.7.ln_2.weight',
 'module.model.visual.transformer.resblocks.7.ln_2.bias',
 'module.model.visual.transformer.resblocks.8.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.8.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.8.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.8.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.8.ln_1.weight',
 'module.model.visual.transformer.resblocks.8.ln_1.bias',
 'module.model.visual.transformer.resblocks.8.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.8.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.8.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.8.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.8.ln_2.weight',
 'module.model.visual.transformer.resblocks.8.ln_2.bias',
 'module.model.visual.transformer.resblocks.9.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.9.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.9.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.9.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.9.ln_1.weight',
 'module.model.visual.transformer.resblocks.9.ln_1.bias',
 'module.model.visual.transformer.resblocks.9.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.9.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.9.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.9.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.9.ln_2.weight',
 'module.model.visual.transformer.resblocks.9.ln_2.bias',
 'module.model.visual.transformer.resblocks.10.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.10.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.10.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.10.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.10.ln_1.weight',
 'module.model.visual.transformer.resblocks.10.ln_1.bias',
 'module.model.visual.transformer.resblocks.10.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.10.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.10.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.10.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.10.ln_2.weight',
 'module.model.visual.transformer.resblocks.10.ln_2.bias',
 'module.model.visual.transformer.resblocks.11.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.11.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.11.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.11.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.11.ln_1.weight',
 'module.model.visual.transformer.resblocks.11.ln_1.bias',
 'module.model.visual.transformer.resblocks.11.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.11.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.11.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.11.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.11.ln_2.weight',
 'module.model.visual.transformer.resblocks.11.ln_2.bias',
 'module.model.visual.ln_post.weight',
 'module.model.visual.ln_post.bias',
 'module.model.transformer.resblocks.0.attn.in_proj_weight',
 'module.model.transformer.resblocks.0.attn.in_proj_bias',
 'module.model.transformer.resblocks.0.attn.out_proj.weight',
 'module.model.transformer.resblocks.0.attn.out_proj.bias',
 'module.model.transformer.resblocks.0.ln_1.weight',
 'module.model.transformer.resblocks.0.ln_1.bias',
 'module.model.transformer.resblocks.0.mlp.c_fc.weight',
 'module.model.transformer.resblocks.0.mlp.c_fc.bias',
 'module.model.transformer.resblocks.0.mlp.c_proj.weight',
 'module.model.transformer.resblocks.0.mlp.c_proj.bias',
 'module.model.transformer.resblocks.0.ln_2.weight',
 'module.model.transformer.resblocks.0.ln_2.bias',
 'module.model.transformer.resblocks.1.attn.in_proj_weight',
 'module.model.transformer.resblocks.1.attn.in_proj_bias',
 'module.model.transformer.resblocks.1.attn.out_proj.weight',
 'module.model.transformer.resblocks.1.attn.out_proj.bias',
 'module.model.transformer.resblocks.1.ln_1.weight',
 'module.model.transformer.resblocks.1.ln_1.bias',
 'module.model.transformer.resblocks.1.mlp.c_fc.weight',
 'module.model.transformer.resblocks.1.mlp.c_fc.bias',
 'module.model.transformer.resblocks.1.mlp.c_proj.weight',
 'module.model.transformer.resblocks.1.mlp.c_proj.bias',
 'module.model.transformer.resblocks.1.ln_2.weight',
 'module.model.transformer.resblocks.1.ln_2.bias',
 'module.model.transformer.resblocks.2.attn.in_proj_weight',
 'module.model.transformer.resblocks.2.attn.in_proj_bias',
 'module.model.transformer.resblocks.2.attn.out_proj.weight',
 'module.model.transformer.resblocks.2.attn.out_proj.bias',
 'module.model.transformer.resblocks.2.ln_1.weight',
 'module.model.transformer.resblocks.2.ln_1.bias',
 'module.model.transformer.resblocks.2.mlp.c_fc.weight',
 'module.model.transformer.resblocks.2.mlp.c_fc.bias',
 'module.model.transformer.resblocks.2.mlp.c_proj.weight',
 'module.model.transformer.resblocks.2.mlp.c_proj.bias',
 'module.model.transformer.resblocks.2.ln_2.weight',
 'module.model.transformer.resblocks.2.ln_2.bias',
 'module.model.transformer.resblocks.3.attn.in_proj_weight',
 'module.model.transformer.resblocks.3.attn.in_proj_bias',
 'module.model.transformer.resblocks.3.attn.out_proj.weight',
 'module.model.transformer.resblocks.3.attn.out_proj.bias',
 'module.model.transformer.resblocks.3.ln_1.weight',
 'module.model.transformer.resblocks.3.ln_1.bias',
 'module.model.transformer.resblocks.3.mlp.c_fc.weight',
 'module.model.transformer.resblocks.3.mlp.c_fc.bias',
 'module.model.transformer.resblocks.3.mlp.c_proj.weight',
 'module.model.transformer.resblocks.3.mlp.c_proj.bias',
 'module.model.transformer.resblocks.3.ln_2.weight',
 'module.model.transformer.resblocks.3.ln_2.bias',
 'module.model.transformer.resblocks.4.attn.in_proj_weight',
 'module.model.transformer.resblocks.4.attn.in_proj_bias',
 'module.model.transformer.resblocks.4.attn.out_proj.weight',
 'module.model.transformer.resblocks.4.attn.out_proj.bias',
 'module.model.transformer.resblocks.4.ln_1.weight',
 'module.model.transformer.resblocks.4.ln_1.bias',
 'module.model.transformer.resblocks.4.mlp.c_fc.weight',
 'module.model.transformer.resblocks.4.mlp.c_fc.bias',
 'module.model.transformer.resblocks.4.mlp.c_proj.weight',
 'module.model.transformer.resblocks.4.mlp.c_proj.bias',
 'module.model.transformer.resblocks.4.ln_2.weight',
 'module.model.transformer.resblocks.4.ln_2.bias',
 'module.model.transformer.resblocks.5.attn.in_proj_weight',
 'module.model.transformer.resblocks.5.attn.in_proj_bias',
 'module.model.transformer.resblocks.5.attn.out_proj.weight',
 'module.model.transformer.resblocks.5.attn.out_proj.bias',
 'module.model.transformer.resblocks.5.ln_1.weight',
 'module.model.transformer.resblocks.5.ln_1.bias',
 'module.model.transformer.resblocks.5.mlp.c_fc.weight',
 'module.model.transformer.resblocks.5.mlp.c_fc.bias',
 'module.model.transformer.resblocks.5.mlp.c_proj.weight',
 'module.model.transformer.resblocks.5.mlp.c_proj.bias',
 'module.model.transformer.resblocks.5.ln_2.weight',
 'module.model.transformer.resblocks.5.ln_2.bias',
 'module.model.transformer.resblocks.6.attn.in_proj_weight',
 'module.model.transformer.resblocks.6.attn.in_proj_bias',
 'module.model.transformer.resblocks.6.attn.out_proj.weight',
 'module.model.transformer.resblocks.6.attn.out_proj.bias',
 'module.model.transformer.resblocks.6.ln_1.weight',
 'module.model.transformer.resblocks.6.ln_1.bias',
 'module.model.transformer.resblocks.6.mlp.c_fc.weight',
 'module.model.transformer.resblocks.6.mlp.c_fc.bias',
 'module.model.transformer.resblocks.6.mlp.c_proj.weight',
 'module.model.transformer.resblocks.6.mlp.c_proj.bias',
 'module.model.transformer.resblocks.6.ln_2.weight',
 'module.model.transformer.resblocks.6.ln_2.bias',
 'module.model.transformer.resblocks.7.attn.in_proj_weight',
 'module.model.transformer.resblocks.7.attn.in_proj_bias',
 'module.model.transformer.resblocks.7.attn.out_proj.weight',
 'module.model.transformer.resblocks.7.attn.out_proj.bias',
 'module.model.transformer.resblocks.7.ln_1.weight',
 'module.model.transformer.resblocks.7.ln_1.bias',
 'module.model.transformer.resblocks.7.mlp.c_fc.weight',
 'module.model.transformer.resblocks.7.mlp.c_fc.bias',
 'module.model.transformer.resblocks.7.mlp.c_proj.weight',
 'module.model.transformer.resblocks.7.mlp.c_proj.bias',
 'module.model.transformer.resblocks.7.ln_2.weight',
 'module.model.transformer.resblocks.7.ln_2.bias',
 'module.model.transformer.resblocks.8.attn.in_proj_weight',
 'module.model.transformer.resblocks.8.attn.in_proj_bias',
 'module.model.transformer.resblocks.8.attn.out_proj.weight',
 'module.model.transformer.resblocks.8.attn.out_proj.bias',
 'module.model.transformer.resblocks.8.ln_1.weight',
 'module.model.transformer.resblocks.8.ln_1.bias',
 'module.model.transformer.resblocks.8.mlp.c_fc.weight',
 'module.model.transformer.resblocks.8.mlp.c_fc.bias',
 'module.model.transformer.resblocks.8.mlp.c_proj.weight',
 'module.model.transformer.resblocks.8.mlp.c_proj.bias',
 'module.model.transformer.resblocks.8.ln_2.weight',
 'module.model.transformer.resblocks.8.ln_2.bias',
 'module.model.transformer.resblocks.9.attn.in_proj_weight',
 'module.model.transformer.resblocks.9.attn.in_proj_bias',
 'module.model.transformer.resblocks.9.attn.out_proj.weight',
 'module.model.transformer.resblocks.9.attn.out_proj.bias',
 'module.model.transformer.resblocks.9.ln_1.weight',
 'module.model.transformer.resblocks.9.ln_1.bias',
 'module.model.transformer.resblocks.9.mlp.c_fc.weight',
 'module.model.transformer.resblocks.9.mlp.c_fc.bias',
 'module.model.transformer.resblocks.9.mlp.c_proj.weight',
 'module.model.transformer.resblocks.9.mlp.c_proj.bias',
 'module.model.transformer.resblocks.9.ln_2.weight',
 'module.model.transformer.resblocks.9.ln_2.bias',
 'module.model.transformer.resblocks.10.attn.in_proj_weight',
 'module.model.transformer.resblocks.10.attn.in_proj_bias',
 'module.model.transformer.resblocks.10.attn.out_proj.weight',
 'module.model.transformer.resblocks.10.attn.out_proj.bias',
 'module.model.transformer.resblocks.10.ln_1.weight',
 'module.model.transformer.resblocks.10.ln_1.bias',
 'module.model.transformer.resblocks.10.mlp.c_fc.weight',
 'module.model.transformer.resblocks.10.mlp.c_fc.bias',
 'module.model.transformer.resblocks.10.mlp.c_proj.weight',
 'module.model.transformer.resblocks.10.mlp.c_proj.bias',
 'module.model.transformer.resblocks.10.ln_2.weight',
 'module.model.transformer.resblocks.10.ln_2.bias',
 'module.model.transformer.resblocks.11.attn.in_proj_weight',
 'module.model.transformer.resblocks.11.attn.in_proj_bias',
 'module.model.transformer.resblocks.11.attn.out_proj.weight',
 'module.model.transformer.resblocks.11.attn.out_proj.bias',
 'module.model.transformer.resblocks.11.ln_1.weight',
 'module.model.transformer.resblocks.11.ln_1.bias',
 'module.model.transformer.resblocks.11.mlp.c_fc.weight',
 'module.model.transformer.resblocks.11.mlp.c_fc.bias',
 'module.model.transformer.resblocks.11.mlp.c_proj.weight',
 'module.model.transformer.resblocks.11.mlp.c_proj.bias',
 'module.model.transformer.resblocks.11.ln_2.weight',
 'module.model.transformer.resblocks.11.ln_2.bias',
 'module.model.token_embedding.weight',
 'module.model.ln_final.weight',
 'module.model.ln_final.bias',
 'module.projector_v.0.weight',
 'module.projector_v.2.weight',
 'module.projector_t.0.weight',
 'module.projector_t.2.weight']
[12/16 23:53:53][INFO] misc.py:  185: Model:
DistributedDataParallel(
  (module): TemporalClipVideo(
    (model): WCLIP(
      (visual): TemporalVisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): TSTransformer(
          (resblocks): Sequential(
            (0): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (raw_model): WCLIP(
      (visual): TemporalVisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): TSTransformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (projector_v): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): GELU()
      (2): Linear(in_features=512, out_features=512, bias=False)
    )
    (projector_t): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): GELU()
      (2): Linear(in_features=512, out_features=512, bias=False)
    )
  )
)
[12/16 23:53:53][INFO] misc.py:  187: Params: 300,290,050
[12/16 23:53:53][INFO] misc.py:  188: Mem: 1.6981406211853027 MB
[12/16 23:53:53][INFO] misc.py:  197: nvidia-smi
Mon Dec 16 23:53:53 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  Off |
| 42%   24C    P2    66W / 450W |   5130MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:23:00.0 Off |                  Off |
| 41%   25C    P2    63W / 450W |   5130MiB / 24564MiB |     34%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:41:00.0 Off |                  Off |
| 41%   26C    P2    68W / 450W |   5130MiB / 24564MiB |      6%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:61:00.0 Off |                  Off |
| 40%   25C    P2    55W / 450W |   5130MiB / 24564MiB |     28%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   4  NVIDIA GeForce ...  Off  | 00000000:81:00.0 Off |                  Off |
| 42%   25C    P2    70W / 450W |   5130MiB / 24564MiB |     27%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   5  NVIDIA GeForce ...  Off  | 00000000:A1:00.0 Off |                  Off |
| 41%   25C    P2    69W / 450W |   5130MiB / 24564MiB |     52%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   6  NVIDIA GeForce ...  Off  | 00000000:C1:00.0 Off |                  Off |
| 42%   25C    P2    59W / 450W |   5130MiB / 24564MiB |     49%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   7  NVIDIA GeForce ...  Off  | 00000000:E1:00.0 Off |                  Off |
| 40%   25C    P2    67W / 450W |   5130MiB / 24564MiB |     14%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    0   N/A  N/A   3749450      C   .../envs/slowfast/bin/python     5122MiB |
|    1   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    1   N/A  N/A   3749451      C   .../envs/slowfast/bin/python     5122MiB |
|    2   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    2   N/A  N/A   3749452      C   .../envs/slowfast/bin/python     5122MiB |
|    3   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    3   N/A  N/A   3749453      C   .../envs/slowfast/bin/python     5122MiB |
|    4   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    4   N/A  N/A   3749454      C   .../envs/slowfast/bin/python     5122MiB |
|    5   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    5   N/A  N/A   3749460      C   .../envs/slowfast/bin/python     5122MiB |
|    6   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    6   N/A  N/A   3749461      C   .../envs/slowfast/bin/python     5122MiB |
|    7   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    7   N/A  N/A   3749462      C   .../envs/slowfast/bin/python     5122MiB |
+-----------------------------------------------------------------------------+
bn 0, non bn 107, zero 199, no grad 302
[12/16 23:53:54][INFO] kinetics.py:   94: Constructing Kinetics train...
path: ---------------------------- /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_ssv2/train.csv
[12/16 23:53:54][INFO] kinetics.py:  172: Constructing kinetics dataloader (size: 1392 skip_rows 0) from /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_ssv2/train.csv 
[12/16 23:53:54][INFO] kinetics.py:   94: Constructing Kinetics val...
path: ---------------------------- /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_ssv2/test.csv
[12/16 23:53:54][INFO] kinetics.py:  172: Constructing kinetics dataloader (size: 7215 skip_rows 0) from /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_ssv2/test.csv 
[12/16 23:53:54][INFO] kinetics.py:   94: Constructing Kinetics train...
path: ---------------------------- /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_ssv2/train.csv
[12/16 23:53:54][INFO] kinetics.py:  172: Constructing kinetics dataloader (size: 1392 skip_rows 0) from /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_ssv2/train.csv 
[12/16 23:53:54][INFO] train_net.py: 1134: Start epoch: 1
[12/16 23:53:54][INFO] train_net.py:  304: total trainable params:
[12/16 23:53:54][INFO] train_net.py:  307: module.model.positional_embedding
[12/16 23:53:54][INFO] train_net.py:  307: module.model.text_projection
[12/16 23:53:54][INFO] train_net.py:  307: module.model.logit_scale
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.proj
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.ln_final.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.model.ln_final.bias
[12/16 23:53:54][INFO] train_net.py:  307: module.projector_v.0.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.projector_v.2.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.projector_t.0.weight
[12/16 23:53:54][INFO] train_net.py:  307: module.projector_t.2.weight
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
exponential temporal pooling in train
alpha:0.2
[12/16 23:54:14][INFO] train_net.py:  491: Distillation Loss: 0.07358217
[12/16 23:54:14][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 23:54:21][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.65791841, "dt_data": 0.00040911, "dt_net": 0.65750777, "epoch": "1/12", "eta": "0:05:32", "gpu_mem": "13.72G", "grad_norm": 115.61530304, "iter": "10/43", "loss": 5.35076165, "lr": 3.8E-7, "top1_err": 98.43750000, "top5_err": 87.50000000}
exponential temporal pooling in train
alpha:0.2
[12/16 23:54:21][INFO] train_net.py:  491: Distillation Loss: 0.07116610
[12/16 23:54:21][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 23:54:27][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.63925405, "dt_data": 0.00037083, "dt_net": 0.63888162, "epoch": "1/12", "eta": "0:05:17", "gpu_mem": "13.72G", "grad_norm": 102.47490692, "iter": "20/43", "loss": 4.87714505, "lr": 7.6E-7, "top1_err": 96.87500000, "top5_err": 84.37500000}
exponential temporal pooling in train
alpha:0.2
[12/16 23:54:27][INFO] train_net.py:  491: Distillation Loss: 0.06069726
[12/16 23:54:27][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 23:54:33][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.64082236, "dt_data": 0.00019110, "dt_net": 0.64063041, "epoch": "1/12", "eta": "0:05:11", "gpu_mem": "13.72G", "grad_norm": 68.24732208, "iter": "30/43", "loss": 4.55520511, "lr": 0.00000114, "top1_err": 96.87500000, "top5_err": 81.25000000}
exponential temporal pooling in train
alpha:0.2
[12/16 23:54:34][INFO] train_net.py:  491: Distillation Loss: 0.08563775
[12/16 23:54:34][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 23:54:40][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.65442897, "dt_data": 0.00017461, "dt_net": 0.65425342, "epoch": "1/12", "eta": "0:05:11", "gpu_mem": "13.72G", "grad_norm": 70.29114532, "iter": "40/43", "loss": 4.52968144, "lr": 0.00000153, "top1_err": 93.75000000, "top5_err": 84.37500000}
exponential temporal pooling in train
alpha:0.2
[12/16 23:54:40][INFO] train_net.py:  491: Distillation Loss: 0.07880193
[12/16 23:54:40][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 23:54:44][INFO] logging.py:   99: json_stats: {"RAM": "49.58/251.74G", "_type": "train_epoch", "dt": 2.38412264, "dt_data": 2.38412204, "dt_net": 0.63799767, "epoch": "1/12", "eta": "0:18:47", "gpu_mem": "13.72G", "grad_norm": 57.19869995, "loss": 4.77348292, "lr": 0.00000164, "top1_err": 95.56686047, "top5_err": 84.01162791}
[12/16 23:54:44][INFO] train_net.py: 1338: Epoch 0 takes 50.44s. Epochs from 0 to 0 take 50.44s in average and 50.44s in median.
[12/16 23:54:44][INFO] train_net.py: 1344: For epoch 0, each iteraction takes 1.17s in average. From epoch 0 to 0, each iteraction takes 1.17s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:55:17][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:03:25", "gpu_mem": "13.72G", "iter": "10/226", "time_diff": 0.95151930, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:55:26][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:03:15", "gpu_mem": "13.72G", "iter": "20/226", "time_diff": 0.95111232, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:55:36][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:03:04", "gpu_mem": "13.72G", "iter": "30/226", "time_diff": 0.94212095, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:55:46][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:02:54", "gpu_mem": "13.72G", "iter": "40/226", "time_diff": 0.93856924, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:55:55][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:02:45", "gpu_mem": "13.72G", "iter": "50/226", "time_diff": 0.93872262, "top1_err": 100.00000000, "top5_err": 90.62500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:56:05][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:02:35", "gpu_mem": "13.72G", "iter": "60/226", "time_diff": 0.93630367, "top1_err": 100.00000000, "top5_err": 90.62500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:56:14][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:02:26", "gpu_mem": "13.72G", "iter": "70/226", "time_diff": 0.93778980, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:56:24][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:02:19", "gpu_mem": "13.72G", "iter": "80/226", "time_diff": 0.95247914, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:56:33][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:02:11", "gpu_mem": "13.72G", "iter": "90/226", "time_diff": 0.96839411, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:56:43][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:02:00", "gpu_mem": "13.72G", "iter": "100/226", "time_diff": 0.95823109, "top1_err": 96.87500000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:56:52][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:01:53", "gpu_mem": "13.72G", "iter": "110/226", "time_diff": 0.97461816, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:57:02][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:01:40", "gpu_mem": "13.72G", "iter": "120/226", "time_diff": 0.94569145, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:57:11][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:01:30", "gpu_mem": "13.72G", "iter": "130/226", "time_diff": 0.93952959, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:57:21][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:01:22", "gpu_mem": "13.72G", "iter": "140/226", "time_diff": 0.95478857, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:57:30][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:01:11", "gpu_mem": "13.72G", "iter": "150/226", "time_diff": 0.94713276, "top1_err": 100.00000000, "top5_err": 92.18750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:57:40][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:01:01", "gpu_mem": "13.72G", "iter": "160/226", "time_diff": 0.93194482, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:57:49][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:00:53", "gpu_mem": "13.72G", "iter": "170/226", "time_diff": 0.95115636, "top1_err": 98.43750000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:57:59][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:00:43", "gpu_mem": "13.72G", "iter": "180/226", "time_diff": 0.94337803, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:58:08][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:00:33", "gpu_mem": "13.72G", "iter": "190/226", "time_diff": 0.94054618, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:58:18][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:00:24", "gpu_mem": "13.72G", "iter": "200/226", "time_diff": 0.96040540, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:58:27][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:00:14", "gpu_mem": "13.72G", "iter": "210/226", "time_diff": 0.91812723, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:58:36][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:00:05", "gpu_mem": "13.72G", "iter": "220/226", "time_diff": 0.90858336, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/16 23:58:44][INFO] logging.py:   99: json_stats: {"RAM": "50.46/251.74G", "_type": "val_epoch", "epoch": "1/12", "gpu_mem": "13.72G", "min_top1_err": 98.98835920, "min_top5_err": 93.76385809, "time_diff": 2.08725634, "top1_err": 98.98835920, "top5_err": 93.76385809}
[12/16 23:58:44][INFO] train_net.py:  304: total trainable params:
[12/16 23:58:44][INFO] train_net.py:  307: module.model.positional_embedding
[12/16 23:58:44][INFO] train_net.py:  307: module.model.text_projection
[12/16 23:58:44][INFO] train_net.py:  307: module.model.logit_scale
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.proj
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.ln_final.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.model.ln_final.bias
[12/16 23:58:44][INFO] train_net.py:  307: module.projector_v.0.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.projector_v.2.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.projector_t.0.weight
[12/16 23:58:44][INFO] train_net.py:  307: module.projector_t.2.weight
exponential temporal pooling in train
alpha:0.2
[12/16 23:59:03][INFO] train_net.py:  491: Distillation Loss: 0.08385408
[12/16 23:59:03][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 23:59:11][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.65230748, "dt_data": 0.00049562, "dt_net": 0.65180973, "epoch": "2/12", "eta": "0:05:02", "gpu_mem": "13.77G", "grad_norm": 64.34636688, "iter": "10/43", "loss": 4.15592575, "lr": 0.00000203, "top1_err": 92.18750000, "top5_err": 75.00000000}
exponential temporal pooling in train
alpha:0.2
[12/16 23:59:11][INFO] train_net.py:  491: Distillation Loss: 0.07545131
[12/16 23:59:11][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 23:59:17][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.64419753, "dt_data": 0.00044572, "dt_net": 0.64375047, "epoch": "2/12", "eta": "0:04:51", "gpu_mem": "13.77G", "grad_norm": 67.68451691, "iter": "20/43", "loss": 4.13085461, "lr": 0.00000241, "top1_err": 92.18750000, "top5_err": 75.00000000}
exponential temporal pooling in train
alpha:0.2
[12/16 23:59:18][INFO] train_net.py:  491: Distillation Loss: 0.08840418
[12/16 23:59:18][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 23:59:24][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.64143282, "dt_data": 0.00018413, "dt_net": 0.64124754, "epoch": "2/12", "eta": "0:04:44", "gpu_mem": "13.77G", "grad_norm": 72.33232880, "iter": "30/43", "loss": 4.06984115, "lr": 0.00000279, "top1_err": 87.50000000, "top5_err": 73.43750000}
exponential temporal pooling in train
alpha:0.2
[12/16 23:59:24][INFO] train_net.py:  491: Distillation Loss: 0.07908440
[12/16 23:59:24][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 23:59:30][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.64003561, "dt_data": 0.00018651, "dt_net": 0.63984889, "epoch": "2/12", "eta": "0:04:37", "gpu_mem": "13.77G", "grad_norm": 67.20252228, "iter": "40/43", "loss": 4.08873272, "lr": 0.00000318, "top1_err": 87.50000000, "top5_err": 68.75000000}
exponential temporal pooling in train
alpha:0.2
[12/16 23:59:30][INFO] train_net.py:  491: Distillation Loss: 0.09440273
[12/16 23:59:30][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/16 23:59:35][INFO] logging.py:   99: json_stats: {"RAM": "49.61/251.74G", "_type": "train_epoch", "dt": 2.36155980, "dt_data": 2.36155869, "dt_net": 0.63393616, "epoch": "2/12", "eta": "0:16:55", "gpu_mem": "13.77G", "grad_norm": 70.32186127, "loss": 4.10768702, "lr": 0.00000329, "top1_err": 89.46220930, "top5_err": 72.38372093}
[12/16 23:59:35][INFO] train_net.py: 1338: Epoch 1 takes 50.72s. Epochs from 0 to 1 take 50.58s in average and 50.58s in median.
[12/16 23:59:35][INFO] train_net.py: 1344: For epoch 1, each iteraction takes 1.18s in average. From epoch 0 to 1, each iteraction takes 1.18s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:00:07][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:03:25", "gpu_mem": "13.77G", "iter": "10/226", "time_diff": 0.94941334, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:00:17][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:03:12", "gpu_mem": "13.77G", "iter": "20/226", "time_diff": 0.93381066, "top1_err": 100.00000000, "top5_err": 92.18750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:00:26][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:03:09", "gpu_mem": "13.77G", "iter": "30/226", "time_diff": 0.96598116, "top1_err": 100.00000000, "top5_err": 92.18750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:00:36][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:02:55", "gpu_mem": "13.77G", "iter": "40/226", "time_diff": 0.94147697, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:00:45][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:02:46", "gpu_mem": "13.77G", "iter": "50/226", "time_diff": 0.94379951, "top1_err": 96.87500000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:00:55][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:02:38", "gpu_mem": "13.77G", "iter": "60/226", "time_diff": 0.95492108, "top1_err": 100.00000000, "top5_err": 92.18750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:01:04][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:02:28", "gpu_mem": "13.77G", "iter": "70/226", "time_diff": 0.95504745, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:01:14][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:02:18", "gpu_mem": "13.77G", "iter": "80/226", "time_diff": 0.94591009, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:01:23][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:02:09", "gpu_mem": "13.77G", "iter": "90/226", "time_diff": 0.94920035, "top1_err": 96.87500000, "top5_err": 92.18750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:01:32][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:01:57", "gpu_mem": "13.77G", "iter": "100/226", "time_diff": 0.93481936, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:01:42][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:01:50", "gpu_mem": "13.77G", "iter": "110/226", "time_diff": 0.95297994, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:01:51][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:01:40", "gpu_mem": "13.77G", "iter": "120/226", "time_diff": 0.94463260, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:02:01][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:01:31", "gpu_mem": "13.77G", "iter": "130/226", "time_diff": 0.95619567, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:02:10][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:01:20", "gpu_mem": "13.77G", "iter": "140/226", "time_diff": 0.93961904, "top1_err": 100.00000000, "top5_err": 90.62500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:02:20][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:01:13", "gpu_mem": "13.77G", "iter": "150/226", "time_diff": 0.96966272, "top1_err": 98.43750000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:02:29][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:01:03", "gpu_mem": "13.77G", "iter": "160/226", "time_diff": 0.96260762, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:02:39][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:00:52", "gpu_mem": "13.77G", "iter": "170/226", "time_diff": 0.93731169, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:02:48][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:00:42", "gpu_mem": "13.77G", "iter": "180/226", "time_diff": 0.93090009, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:02:58][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:00:34", "gpu_mem": "13.77G", "iter": "190/226", "time_diff": 0.96250382, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:03:07][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:00:24", "gpu_mem": "13.77G", "iter": "200/226", "time_diff": 0.95640768, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:03:17][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:00:14", "gpu_mem": "13.77G", "iter": "210/226", "time_diff": 0.93210740, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:03:26][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:00:05", "gpu_mem": "13.77G", "iter": "220/226", "time_diff": 0.91086096, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:03:33][INFO] logging.py:   99: json_stats: {"RAM": "49.13/251.74G", "_type": "val_epoch", "epoch": "2/12", "gpu_mem": "13.77G", "min_top1_err": 98.98835920, "min_top5_err": 93.76385809, "time_diff": 1.84490511, "top1_err": 99.04379157, "top5_err": 93.80543237}
[12/17 00:03:33][INFO] train_net.py:  304: total trainable params:
[12/17 00:03:33][INFO] train_net.py:  307: module.model.positional_embedding
[12/17 00:03:33][INFO] train_net.py:  307: module.model.text_projection
[12/17 00:03:33][INFO] train_net.py:  307: module.model.logit_scale
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.proj
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.ln_final.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.model.ln_final.bias
[12/17 00:03:33][INFO] train_net.py:  307: module.projector_v.0.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.projector_v.2.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.projector_t.0.weight
[12/17 00:03:33][INFO] train_net.py:  307: module.projector_t.2.weight
exponential temporal pooling in train
alpha:0.2
[12/17 00:03:54][INFO] train_net.py:  491: Distillation Loss: 0.09200370
[12/17 00:03:54][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:04:00][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.64894009, "dt_data": 0.00032255, "dt_net": 0.64861611, "epoch": "3/12", "eta": "0:04:32", "gpu_mem": "13.77G", "grad_norm": 79.41589355, "iter": "10/43", "loss": 3.48598969, "lr": 0.00000333, "top1_err": 81.25000000, "top5_err": 51.56250000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:04:00][INFO] train_net.py:  491: Distillation Loss: 0.10415959
[12/17 00:04:00][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:04:07][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.63756414, "dt_data": 0.00067160, "dt_net": 0.63689017, "epoch": "3/12", "eta": "0:04:21", "gpu_mem": "13.77G", "grad_norm": 82.39488983, "iter": "20/43", "loss": 3.37331855, "lr": 0.00000331, "top1_err": 76.56250000, "top5_err": 51.56250000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:04:07][INFO] train_net.py:  491: Distillation Loss: 0.10395378
[12/17 00:04:07][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:04:13][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.64033857, "dt_data": 0.00018962, "dt_net": 0.64014837, "epoch": "3/12", "eta": "0:04:16", "gpu_mem": "13.77G", "grad_norm": 83.83657837, "iter": "30/43", "loss": 3.51049209, "lr": 0.00000329, "top1_err": 82.81250000, "top5_err": 59.37500000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:04:13][INFO] train_net.py:  491: Distillation Loss: 0.11374986
[12/17 00:04:13][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:04:20][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.64816239, "dt_data": 0.00022101, "dt_net": 0.64794052, "epoch": "3/12", "eta": "0:04:12", "gpu_mem": "13.77G", "grad_norm": 72.26644897, "iter": "40/43", "loss": 3.37710118, "lr": 0.00000326, "top1_err": 76.56250000, "top5_err": 53.12500000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:04:20][INFO] train_net.py:  491: Distillation Loss: 0.11893743
[12/17 00:04:20][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:04:24][INFO] logging.py:   99: json_stats: {"RAM": "49.22/251.74G", "_type": "train_epoch", "dt": 2.06440342, "dt_data": 2.06440254, "dt_net": 0.64367813, "epoch": "3/12", "eta": "0:13:18", "gpu_mem": "13.77G", "grad_norm": 93.38404083, "loss": 3.44116877, "lr": 0.00000325, "top1_err": 78.77906977, "top5_err": 53.34302326}
[12/17 00:04:24][INFO] train_net.py: 1338: Epoch 2 takes 50.49s. Epochs from 0 to 2 take 50.55s in average and 50.49s in median.
[12/17 00:04:24][INFO] train_net.py: 1344: For epoch 2, each iteraction takes 1.17s in average. From epoch 0 to 2, each iteraction takes 1.18s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:04:56][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:03:25", "gpu_mem": "13.77G", "iter": "10/226", "time_diff": 0.95306536, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:05:06][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:03:15", "gpu_mem": "13.77G", "iter": "20/226", "time_diff": 0.94679087, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:05:15][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:03:05", "gpu_mem": "13.77G", "iter": "30/226", "time_diff": 0.94614316, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:05:25][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:02:52", "gpu_mem": "13.77G", "iter": "40/226", "time_diff": 0.92891976, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:05:34][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:02:49", "gpu_mem": "13.77G", "iter": "50/226", "time_diff": 0.96508235, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:05:44][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:02:36", "gpu_mem": "13.77G", "iter": "60/226", "time_diff": 0.94173269, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:05:53][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:02:25", "gpu_mem": "13.77G", "iter": "70/226", "time_diff": 0.93053190, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:06:03][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:02:16", "gpu_mem": "13.77G", "iter": "80/226", "time_diff": 0.93693336, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:06:12][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:02:13", "gpu_mem": "13.77G", "iter": "90/226", "time_diff": 0.98335769, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:06:21][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:01:58", "gpu_mem": "13.77G", "iter": "100/226", "time_diff": 0.93743680, "top1_err": 98.43750000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:06:31][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:01:48", "gpu_mem": "13.77G", "iter": "110/226", "time_diff": 0.93603009, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:06:40][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:01:39", "gpu_mem": "13.77G", "iter": "120/226", "time_diff": 0.93777489, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:06:50][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:01:31", "gpu_mem": "13.77G", "iter": "130/226", "time_diff": 0.94845078, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:06:59][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:01:25", "gpu_mem": "13.77G", "iter": "140/226", "time_diff": 0.99060807, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:07:09][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:01:12", "gpu_mem": "13.77G", "iter": "150/226", "time_diff": 0.94990045, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:07:18][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:01:01", "gpu_mem": "13.77G", "iter": "160/226", "time_diff": 0.92984826, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:07:28][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:00:52", "gpu_mem": "13.77G", "iter": "170/226", "time_diff": 0.94412617, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:07:37][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:00:43", "gpu_mem": "13.77G", "iter": "180/226", "time_diff": 0.94863890, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:07:47][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:00:34", "gpu_mem": "13.77G", "iter": "190/226", "time_diff": 0.94541460, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:07:56][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:00:24", "gpu_mem": "13.77G", "iter": "200/226", "time_diff": 0.94835949, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:08:06][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:00:15", "gpu_mem": "13.77G", "iter": "210/226", "time_diff": 0.93799189, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:08:15][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:00:05", "gpu_mem": "13.77G", "iter": "220/226", "time_diff": 0.90865094, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:08:22][INFO] logging.py:   99: json_stats: {"RAM": "49.80/251.74G", "_type": "val_epoch", "epoch": "3/12", "gpu_mem": "13.77G", "min_top1_err": 98.98835920, "min_top5_err": 93.76385809, "time_diff": 1.91189463, "top1_err": 99.22394678, "top5_err": 94.99722838}
[12/17 00:08:22][INFO] train_net.py:  304: total trainable params:
[12/17 00:08:22][INFO] train_net.py:  307: module.model.positional_embedding
[12/17 00:08:22][INFO] train_net.py:  307: module.model.text_projection
[12/17 00:08:22][INFO] train_net.py:  307: module.model.logit_scale
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.proj
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.ln_final.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.model.ln_final.bias
[12/17 00:08:22][INFO] train_net.py:  307: module.projector_v.0.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.projector_v.2.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.projector_t.0.weight
[12/17 00:08:22][INFO] train_net.py:  307: module.projector_t.2.weight
exponential temporal pooling in train
alpha:0.2
[12/17 00:08:43][INFO] train_net.py:  491: Distillation Loss: 0.12178302
[12/17 00:08:43][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:08:49][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.65424736, "dt_data": 0.00030696, "dt_net": 0.65393883, "epoch": "4/12", "eta": "0:04:06", "gpu_mem": "13.77G", "grad_norm": 83.85010529, "iter": "10/43", "loss": 2.89395976, "lr": 0.00000321, "top1_err": 68.75000000, "top5_err": 31.25000000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:08:49][INFO] train_net.py:  491: Distillation Loss: 0.13137966
[12/17 00:08:49][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:08:56][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.63527142, "dt_data": 0.00038983, "dt_net": 0.63488020, "epoch": "4/12", "eta": "0:03:53", "gpu_mem": "13.77G", "grad_norm": 90.38003540, "iter": "20/43", "loss": 2.70051003, "lr": 0.00000316, "top1_err": 64.06250000, "top5_err": 32.81250000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:08:56][INFO] train_net.py:  491: Distillation Loss: 0.13689560
[12/17 00:08:56][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:09:02][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.63940263, "dt_data": 0.00018880, "dt_net": 0.63921278, "epoch": "4/12", "eta": "0:03:48", "gpu_mem": "13.77G", "grad_norm": 88.50355530, "iter": "30/43", "loss": 2.82010829, "lr": 0.00000311, "top1_err": 67.18750000, "top5_err": 32.81250000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:09:02][INFO] train_net.py:  491: Distillation Loss: 0.12350762
[12/17 00:09:02][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:09:08][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.64012126, "dt_data": 0.00020501, "dt_net": 0.63991493, "epoch": "4/12", "eta": "0:03:42", "gpu_mem": "13.77G", "grad_norm": 88.54777527, "iter": "40/43", "loss": 2.75718641, "lr": 0.00000304, "top1_err": 68.75000000, "top5_err": 34.37500000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:09:09][INFO] train_net.py:  491: Distillation Loss: 0.14136130
[12/17 00:09:09][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:09:13][INFO] logging.py:   99: json_stats: {"RAM": "49.64/251.74G", "_type": "train_epoch", "dt": 2.27881140, "dt_data": 2.27881060, "dt_net": 0.63455725, "epoch": "4/12", "eta": "0:13:03", "gpu_mem": "13.77G", "grad_norm": 107.99736786, "loss": 2.81478455, "lr": 0.00000302, "top1_err": 67.22383721, "top5_err": 32.77616279}
[12/17 00:09:13][INFO] train_net.py: 1338: Epoch 3 takes 50.55s. Epochs from 0 to 3 take 50.55s in average and 50.52s in median.
[12/17 00:09:13][INFO] train_net.py: 1344: For epoch 3, each iteraction takes 1.18s in average. From epoch 0 to 3, each iteraction takes 1.18s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:09:45][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:03:28", "gpu_mem": "13.77G", "iter": "10/226", "time_diff": 0.96666417, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:09:55][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:03:16", "gpu_mem": "13.77G", "iter": "20/226", "time_diff": 0.95202501, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:10:05][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:03:03", "gpu_mem": "13.77G", "iter": "30/226", "time_diff": 0.93849354, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:10:14][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:02:57", "gpu_mem": "13.77G", "iter": "40/226", "time_diff": 0.95173853, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:10:24][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:02:50", "gpu_mem": "13.77G", "iter": "50/226", "time_diff": 0.97138035, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:10:33][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:02:38", "gpu_mem": "13.77G", "iter": "60/226", "time_diff": 0.95403606, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:10:43][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:02:30", "gpu_mem": "13.77G", "iter": "70/226", "time_diff": 0.96630432, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:10:53][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:02:21", "gpu_mem": "13.77G", "iter": "80/226", "time_diff": 0.96882470, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:11:02][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:02:10", "gpu_mem": "13.77G", "iter": "90/226", "time_diff": 0.95727353, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:11:12][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:02:00", "gpu_mem": "13.77G", "iter": "100/226", "time_diff": 0.95550286, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:11:21][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:01:48", "gpu_mem": "13.77G", "iter": "110/226", "time_diff": 0.93902692, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:11:31][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:01:40", "gpu_mem": "13.77G", "iter": "120/226", "time_diff": 0.94495356, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:11:40][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:01:29", "gpu_mem": "13.77G", "iter": "130/226", "time_diff": 0.93729060, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:11:50][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:01:21", "gpu_mem": "13.77G", "iter": "140/226", "time_diff": 0.94322004, "top1_err": 100.00000000, "top5_err": 90.62500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:11:59][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:01:11", "gpu_mem": "13.77G", "iter": "150/226", "time_diff": 0.93783122, "top1_err": 98.43750000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:12:09][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:01:01", "gpu_mem": "13.77G", "iter": "160/226", "time_diff": 0.92867603, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:12:18][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:00:52", "gpu_mem": "13.77G", "iter": "170/226", "time_diff": 0.94403850, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:12:28][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:00:43", "gpu_mem": "13.77G", "iter": "180/226", "time_diff": 0.94907956, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:12:37][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:00:34", "gpu_mem": "13.77G", "iter": "190/226", "time_diff": 0.94785661, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:12:47][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:00:24", "gpu_mem": "13.77G", "iter": "200/226", "time_diff": 0.94206253, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:12:56][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:00:15", "gpu_mem": "13.77G", "iter": "210/226", "time_diff": 0.96812864, "top1_err": 100.00000000, "top5_err": 92.18750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:13:05][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:00:05", "gpu_mem": "13.77G", "iter": "220/226", "time_diff": 0.90747720, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:13:13][INFO] logging.py:   99: json_stats: {"RAM": "49.64/251.74G", "_type": "val_epoch", "epoch": "4/12", "gpu_mem": "13.77G", "min_top1_err": 98.98835920, "min_top5_err": 93.76385809, "time_diff": 2.06508045, "top1_err": 99.22394678, "top5_err": 94.80321508}
[12/17 00:13:13][INFO] train_net.py:  304: total trainable params:
[12/17 00:13:13][INFO] train_net.py:  307: module.model.positional_embedding
[12/17 00:13:13][INFO] train_net.py:  307: module.model.text_projection
[12/17 00:13:13][INFO] train_net.py:  307: module.model.logit_scale
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.proj
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.ln_final.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.model.ln_final.bias
[12/17 00:13:13][INFO] train_net.py:  307: module.projector_v.0.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.projector_v.2.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.projector_t.0.weight
[12/17 00:13:13][INFO] train_net.py:  307: module.projector_t.2.weight
exponential temporal pooling in train
alpha:0.2
[12/17 00:13:33][INFO] train_net.py:  491: Distillation Loss: 0.10247910
[12/17 00:13:33][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:13:40][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.64520412, "dt_data": 0.00038799, "dt_net": 0.64481402, "epoch": "5/12", "eta": "0:03:35", "gpu_mem": "13.77G", "grad_norm": 97.69306183, "iter": "10/43", "loss": 2.36595643, "lr": 0.00000295, "top1_err": 56.25000000, "top5_err": 18.75000000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:13:40][INFO] train_net.py:  491: Distillation Loss: 0.15437603
[12/17 00:13:40][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:13:46][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.63239581, "dt_data": 0.00092249, "dt_net": 0.63147030, "epoch": "5/12", "eta": "0:03:24", "gpu_mem": "13.77G", "grad_norm": 106.80799866, "iter": "20/43", "loss": 2.27586150, "lr": 0.00000287, "top1_err": 51.56250000, "top5_err": 23.43750000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:13:46][INFO] train_net.py:  491: Distillation Loss: 0.17620748
[12/17 00:13:46][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:13:53][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.63656747, "dt_data": 0.00017967, "dt_net": 0.63638675, "epoch": "5/12", "eta": "0:03:19", "gpu_mem": "13.77G", "grad_norm": 118.84167480, "iter": "30/43", "loss": 2.37057590, "lr": 0.00000278, "top1_err": 56.25000000, "top5_err": 21.87500000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:13:53][INFO] train_net.py:  491: Distillation Loss: 0.15166360
[12/17 00:13:53][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:13:59][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.64255555, "dt_data": 0.00021459, "dt_net": 0.64233945, "epoch": "5/12", "eta": "0:03:15", "gpu_mem": "13.77G", "grad_norm": 90.65116882, "iter": "40/43", "loss": 2.24823093, "lr": 0.00000269, "top1_err": 53.12500000, "top5_err": 20.31250000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:13:59][INFO] train_net.py:  491: Distillation Loss: 0.14994287
[12/17 00:13:59][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:14:03][INFO] logging.py:   99: json_stats: {"RAM": "49.63/251.74G", "_type": "train_epoch", "dt": 2.10390986, "dt_data": 2.10390929, "dt_net": 0.64017610, "epoch": "5/12", "eta": "0:10:33", "gpu_mem": "13.77G", "grad_norm": 98.79879761, "loss": 2.29110118, "lr": 0.00000266, "top1_err": 53.19767442, "top5_err": 21.43895349}
[12/17 00:14:03][INFO] train_net.py: 1338: Epoch 4 takes 50.34s. Epochs from 0 to 4 take 50.51s in average and 50.49s in median.
[12/17 00:14:03][INFO] train_net.py: 1344: For epoch 4, each iteraction takes 1.17s in average. From epoch 0 to 4, each iteraction takes 1.17s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:14:36][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:03:25", "gpu_mem": "13.77G", "iter": "10/226", "time_diff": 0.95067072, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:14:45][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:03:13", "gpu_mem": "13.77G", "iter": "20/226", "time_diff": 0.94144056, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:14:55][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:03:07", "gpu_mem": "13.77G", "iter": "30/226", "time_diff": 0.95581126, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:15:04][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:02:56", "gpu_mem": "13.77G", "iter": "40/226", "time_diff": 0.94762857, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:15:14][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:02:46", "gpu_mem": "13.77G", "iter": "50/226", "time_diff": 0.94493723, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:15:23][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:02:41", "gpu_mem": "13.77G", "iter": "60/226", "time_diff": 0.97313253, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:15:33][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:02:24", "gpu_mem": "13.77G", "iter": "70/226", "time_diff": 0.92563135, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:15:42][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:02:17", "gpu_mem": "13.77G", "iter": "80/226", "time_diff": 0.94406534, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:15:52][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:02:06", "gpu_mem": "13.77G", "iter": "90/226", "time_diff": 0.93130196, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:16:01][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:02:00", "gpu_mem": "13.77G", "iter": "100/226", "time_diff": 0.95389199, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:16:11][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:01:48", "gpu_mem": "13.77G", "iter": "110/226", "time_diff": 0.93386528, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:16:20][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:01:40", "gpu_mem": "13.77G", "iter": "120/226", "time_diff": 0.95242825, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:16:30][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:01:30", "gpu_mem": "13.77G", "iter": "130/226", "time_diff": 0.94370101, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:16:39][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:01:20", "gpu_mem": "13.77G", "iter": "140/226", "time_diff": 0.93453734, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:16:49][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:01:12", "gpu_mem": "13.77G", "iter": "150/226", "time_diff": 0.95014331, "top1_err": 98.43750000, "top5_err": 92.18750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:16:58][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:01:02", "gpu_mem": "13.77G", "iter": "160/226", "time_diff": 0.94624638, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:17:08][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:00:53", "gpu_mem": "13.77G", "iter": "170/226", "time_diff": 0.96140424, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:17:17][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:00:43", "gpu_mem": "13.77G", "iter": "180/226", "time_diff": 0.94956748, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:17:27][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:00:33", "gpu_mem": "13.77G", "iter": "190/226", "time_diff": 0.93624107, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:17:36][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:00:24", "gpu_mem": "13.77G", "iter": "200/226", "time_diff": 0.95327058, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:17:46][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:00:15", "gpu_mem": "13.77G", "iter": "210/226", "time_diff": 0.93803497, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:17:55][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:00:05", "gpu_mem": "13.77G", "iter": "220/226", "time_diff": 0.90860407, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:18:02][INFO] logging.py:   99: json_stats: {"RAM": "49.64/251.74G", "_type": "val_epoch", "epoch": "5/12", "gpu_mem": "13.77G", "min_top1_err": 98.98835920, "min_top5_err": 93.76385809, "time_diff": 2.12704442, "top1_err": 99.23780488, "top5_err": 94.60920177}
[12/17 00:18:02][INFO] train_net.py:  304: total trainable params:
[12/17 00:18:02][INFO] train_net.py:  307: module.model.positional_embedding
[12/17 00:18:02][INFO] train_net.py:  307: module.model.text_projection
[12/17 00:18:02][INFO] train_net.py:  307: module.model.logit_scale
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.proj
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.ln_final.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.model.ln_final.bias
[12/17 00:18:02][INFO] train_net.py:  307: module.projector_v.0.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.projector_v.2.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.projector_t.0.weight
[12/17 00:18:02][INFO] train_net.py:  307: module.projector_t.2.weight
exponential temporal pooling in train
alpha:0.2
[12/17 00:18:23][INFO] train_net.py:  491: Distillation Loss: 0.17510140
[12/17 00:18:23][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:18:29][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.63699676, "dt_data": 0.00055093, "dt_net": 0.63644420, "epoch": "6/12", "eta": "0:03:05", "gpu_mem": "13.77G", "grad_norm": 98.44237518, "iter": "10/43", "loss": 1.78080630, "lr": 0.00000256, "top1_err": 35.93750000, "top5_err": 9.37500000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:18:30][INFO] train_net.py:  491: Distillation Loss: 0.16517615
[12/17 00:18:30][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:18:36][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.64667139, "dt_data": 0.00041859, "dt_net": 0.64625195, "epoch": "6/12", "eta": "0:03:01", "gpu_mem": "13.77G", "grad_norm": 77.84683228, "iter": "20/43", "loss": 1.76064372, "lr": 0.00000246, "top1_err": 37.50000000, "top5_err": 9.37500000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:18:36][INFO] train_net.py:  491: Distillation Loss: 0.19281703
[12/17 00:18:36][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:18:42][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.64677283, "dt_data": 0.00017995, "dt_net": 0.64659188, "epoch": "6/12", "eta": "0:02:55", "gpu_mem": "13.77G", "grad_norm": 95.27488708, "iter": "30/43", "loss": 1.91828901, "lr": 0.00000235, "top1_err": 39.06250000, "top5_err": 14.06250000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:18:42][INFO] train_net.py:  491: Distillation Loss: 0.18562216
[12/17 00:18:42][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:18:49][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.63820095, "dt_data": 0.00018761, "dt_net": 0.63801199, "epoch": "6/12", "eta": "0:02:46", "gpu_mem": "13.77G", "grad_norm": 135.54956055, "iter": "40/43", "loss": 1.82292002, "lr": 0.00000224, "top1_err": 42.18750000, "top5_err": 10.93750000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:18:49][INFO] train_net.py:  491: Distillation Loss: 0.18516654
[12/17 00:18:49][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:18:53][INFO] logging.py:   99: json_stats: {"RAM": "49.61/251.74G", "_type": "train_epoch", "dt": 2.05550305, "dt_data": 2.05550261, "dt_net": 0.63556761, "epoch": "6/12", "eta": "0:08:50", "gpu_mem": "13.77G", "grad_norm": 110.08104706, "loss": 1.82771961, "lr": 0.00000220, "top1_err": 37.86337209, "top5_err": 11.40988372}
[12/17 00:18:53][INFO] train_net.py: 1338: Epoch 5 takes 50.38s. Epochs from 0 to 5 take 50.49s in average and 50.47s in median.
[12/17 00:18:53][INFO] train_net.py: 1344: For epoch 5, each iteraction takes 1.17s in average. From epoch 0 to 5, each iteraction takes 1.17s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:19:25][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:03:28", "gpu_mem": "13.77G", "iter": "10/226", "time_diff": 0.96386017, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:19:35][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:03:15", "gpu_mem": "13.77G", "iter": "20/226", "time_diff": 0.94663848, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:19:45][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:03:02", "gpu_mem": "13.77G", "iter": "30/226", "time_diff": 0.93254388, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:19:54][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:02:56", "gpu_mem": "13.77G", "iter": "40/226", "time_diff": 0.95151807, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:20:04][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:02:44", "gpu_mem": "13.77G", "iter": "50/226", "time_diff": 0.93654311, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:20:13][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:02:38", "gpu_mem": "13.77G", "iter": "60/226", "time_diff": 0.95354055, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:20:23][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:02:29", "gpu_mem": "13.77G", "iter": "70/226", "time_diff": 0.96053361, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:20:32][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:02:18", "gpu_mem": "13.77G", "iter": "80/226", "time_diff": 0.95116120, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:20:41][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:02:07", "gpu_mem": "13.77G", "iter": "90/226", "time_diff": 0.93521336, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:20:51][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:02:00", "gpu_mem": "13.77G", "iter": "100/226", "time_diff": 0.95964728, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:21:00][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:01:57", "gpu_mem": "13.77G", "iter": "110/226", "time_diff": 1.01078511, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:21:10][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:01:40", "gpu_mem": "13.77G", "iter": "120/226", "time_diff": 0.95216398, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:21:19][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:01:33", "gpu_mem": "13.77G", "iter": "130/226", "time_diff": 0.97143540, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:21:29][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:01:22", "gpu_mem": "13.77G", "iter": "140/226", "time_diff": 0.96015001, "top1_err": 100.00000000, "top5_err": 92.18750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:21:39][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:01:12", "gpu_mem": "13.77G", "iter": "150/226", "time_diff": 0.95787105, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:21:48][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:01:01", "gpu_mem": "13.77G", "iter": "160/226", "time_diff": 0.93750201, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:21:58][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:00:52", "gpu_mem": "13.77G", "iter": "170/226", "time_diff": 0.93497286, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:22:07][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:00:43", "gpu_mem": "13.77G", "iter": "180/226", "time_diff": 0.93980093, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:22:16][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:00:33", "gpu_mem": "13.77G", "iter": "190/226", "time_diff": 0.94309413, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:22:26][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:00:24", "gpu_mem": "13.77G", "iter": "200/226", "time_diff": 0.94207602, "top1_err": 100.00000000, "top5_err": 98.43750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:22:35][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:00:14", "gpu_mem": "13.77G", "iter": "210/226", "time_diff": 0.93011373, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:22:45][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:00:05", "gpu_mem": "13.77G", "iter": "220/226", "time_diff": 0.90917552, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:22:52][INFO] logging.py:   99: json_stats: {"RAM": "50.11/251.74G", "_type": "val_epoch", "epoch": "6/12", "gpu_mem": "13.77G", "min_top1_err": 98.98835920, "min_top5_err": 93.76385809, "time_diff": 1.96041228, "top1_err": 99.22394678, "top5_err": 95.57926829}
[12/17 00:22:52][INFO] train_net.py:  304: total trainable params:
[12/17 00:22:52][INFO] train_net.py:  307: module.model.positional_embedding
[12/17 00:22:52][INFO] train_net.py:  307: module.model.text_projection
[12/17 00:22:52][INFO] train_net.py:  307: module.model.logit_scale
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.proj
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.ln_final.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.model.ln_final.bias
[12/17 00:22:52][INFO] train_net.py:  307: module.projector_v.0.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.projector_v.2.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.projector_t.0.weight
[12/17 00:22:52][INFO] train_net.py:  307: module.projector_t.2.weight
exponential temporal pooling in train
alpha:0.2
[12/17 00:23:13][INFO] train_net.py:  491: Distillation Loss: 0.18996733
[12/17 00:23:13][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:23:19][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.63931204, "dt_data": 0.00046246, "dt_net": 0.63884799, "epoch": "7/12", "eta": "0:02:38", "gpu_mem": "13.77G", "grad_norm": 80.59973907, "iter": "10/43", "loss": 1.47126615, "lr": 0.00000209, "top1_err": 26.56250000, "top5_err": 6.25000000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:23:19][INFO] train_net.py:  491: Distillation Loss: 0.19298935
[12/17 00:23:19][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:23:26][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.64784296, "dt_data": 0.00035964, "dt_net": 0.64748233, "epoch": "7/12", "eta": "0:02:34", "gpu_mem": "13.77G", "grad_norm": 86.20122528, "iter": "20/43", "loss": 1.44594681, "lr": 0.00000197, "top1_err": 29.68750000, "top5_err": 6.25000000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:23:26][INFO] train_net.py:  491: Distillation Loss: 0.19597596
[12/17 00:23:26][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:23:32][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.64012716, "dt_data": 0.00017953, "dt_net": 0.63994655, "epoch": "7/12", "eta": "0:02:25", "gpu_mem": "13.77G", "grad_norm": 88.40998077, "iter": "30/43", "loss": 1.55460465, "lr": 0.00000185, "top1_err": 31.25000000, "top5_err": 6.25000000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:23:32][INFO] train_net.py:  491: Distillation Loss: 0.19262093
[12/17 00:23:32][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:23:38][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.63306142, "dt_data": 0.00023701, "dt_net": 0.63282226, "epoch": "7/12", "eta": "0:02:18", "gpu_mem": "13.77G", "grad_norm": 84.11048126, "iter": "40/43", "loss": 1.48381764, "lr": 0.00000173, "top1_err": 26.56250000, "top5_err": 6.25000000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:23:38][INFO] train_net.py:  491: Distillation Loss: 0.19896740
[12/17 00:23:38][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:23:42][INFO] logging.py:   99: json_stats: {"RAM": "50.19/251.74G", "_type": "train_epoch", "dt": 1.86165176, "dt_data": 1.86165142, "dt_net": 0.63085853, "epoch": "7/12", "eta": "0:06:40", "gpu_mem": "13.77G", "grad_norm": 80.63690186, "loss": 1.51664421, "lr": 0.00000169, "top1_err": 28.27034884, "top5_err": 6.90406977}
[12/17 00:23:42][INFO] train_net.py: 1338: Epoch 6 takes 50.14s. Epochs from 0 to 6 take 50.44s in average and 50.44s in median.
[12/17 00:23:42][INFO] train_net.py: 1344: For epoch 6, each iteraction takes 1.17s in average. From epoch 0 to 6, each iteraction takes 1.17s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:24:15][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:03:25", "gpu_mem": "13.77G", "iter": "10/226", "time_diff": 0.94912389, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:24:24][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:03:13", "gpu_mem": "13.77G", "iter": "20/226", "time_diff": 0.93850816, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:24:34][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:03:02", "gpu_mem": "13.77G", "iter": "30/226", "time_diff": 0.93351306, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:24:43][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:02:54", "gpu_mem": "13.77G", "iter": "40/226", "time_diff": 0.93985419, "top1_err": 98.43750000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:24:53][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:02:43", "gpu_mem": "13.77G", "iter": "50/226", "time_diff": 0.93025683, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:25:02][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:02:37", "gpu_mem": "13.77G", "iter": "60/226", "time_diff": 0.94841328, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:25:12][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:02:27", "gpu_mem": "13.77G", "iter": "70/226", "time_diff": 0.94362394, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:25:21][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:02:22", "gpu_mem": "13.77G", "iter": "80/226", "time_diff": 0.97460286, "top1_err": 100.00000000, "top5_err": 98.43750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:25:31][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:02:09", "gpu_mem": "13.77G", "iter": "90/226", "time_diff": 0.95151526, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:25:40][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:01:58", "gpu_mem": "13.77G", "iter": "100/226", "time_diff": 0.94317534, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:25:50][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:01:48", "gpu_mem": "13.77G", "iter": "110/226", "time_diff": 0.93130849, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:25:59][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:01:40", "gpu_mem": "13.77G", "iter": "120/226", "time_diff": 0.94697454, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:26:09][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:01:31", "gpu_mem": "13.77G", "iter": "130/226", "time_diff": 0.95379029, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:26:18][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:01:21", "gpu_mem": "13.77G", "iter": "140/226", "time_diff": 0.94692021, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:26:28][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:01:10", "gpu_mem": "13.77G", "iter": "150/226", "time_diff": 0.93006665, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:26:37][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:01:02", "gpu_mem": "13.77G", "iter": "160/226", "time_diff": 0.94479709, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:26:47][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:00:52", "gpu_mem": "13.77G", "iter": "170/226", "time_diff": 0.94295794, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:26:56][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:00:44", "gpu_mem": "13.77G", "iter": "180/226", "time_diff": 0.97046929, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:27:06][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:00:34", "gpu_mem": "13.77G", "iter": "190/226", "time_diff": 0.95207044, "top1_err": 98.43750000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:27:15][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:00:24", "gpu_mem": "13.77G", "iter": "200/226", "time_diff": 0.93351662, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:27:25][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:00:14", "gpu_mem": "13.77G", "iter": "210/226", "time_diff": 0.92192457, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:27:34][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:00:05", "gpu_mem": "13.77G", "iter": "220/226", "time_diff": 0.90757828, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:27:41][INFO] logging.py:   99: json_stats: {"RAM": "49.65/251.74G", "_type": "val_epoch", "epoch": "7/12", "gpu_mem": "13.77G", "min_top1_err": 98.98835920, "min_top5_err": 93.76385809, "time_diff": 1.87627497, "top1_err": 99.23780488, "top5_err": 95.13580931}
[12/17 00:27:41][INFO] train_net.py:  304: total trainable params:
[12/17 00:27:41][INFO] train_net.py:  307: module.model.positional_embedding
[12/17 00:27:41][INFO] train_net.py:  307: module.model.text_projection
[12/17 00:27:41][INFO] train_net.py:  307: module.model.logit_scale
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.proj
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.ln_final.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.model.ln_final.bias
[12/17 00:27:41][INFO] train_net.py:  307: module.projector_v.0.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.projector_v.2.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.projector_t.0.weight
[12/17 00:27:41][INFO] train_net.py:  307: module.projector_t.2.weight
exponential temporal pooling in train
alpha:0.2
[12/17 00:28:02][INFO] train_net.py:  491: Distillation Loss: 0.18765092
[12/17 00:28:02][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:28:08][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.64619057, "dt_data": 0.00048592, "dt_net": 0.64570344, "epoch": "8/12", "eta": "0:02:12", "gpu_mem": "13.77G", "grad_norm": 92.84192657, "iter": "10/43", "loss": 1.23166287, "lr": 0.00000157, "top1_err": 20.31250000, "top5_err": 6.25000000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:28:08][INFO] train_net.py:  491: Distillation Loss: 0.20145941
[12/17 00:28:08][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:28:15][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.65318540, "dt_data": 0.00045724, "dt_net": 0.65272678, "epoch": "8/12", "eta": "0:02:07", "gpu_mem": "13.77G", "grad_norm": 89.76709747, "iter": "20/43", "loss": 1.23967993, "lr": 0.00000145, "top1_err": 17.18750000, "top5_err": 6.25000000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:28:15][INFO] train_net.py:  491: Distillation Loss: 0.19887543
[12/17 00:28:15][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:28:21][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.63654583, "dt_data": 0.00017167, "dt_net": 0.63637284, "epoch": "8/12", "eta": "0:01:57", "gpu_mem": "13.77G", "grad_norm": 82.88692474, "iter": "30/43", "loss": 1.29047942, "lr": 0.00000134, "top1_err": 25.00000000, "top5_err": 4.68750000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:28:21][INFO] train_net.py:  491: Distillation Loss: 0.19401419
[12/17 00:28:21][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:28:27][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.64000500, "dt_data": 0.00027195, "dt_net": 0.63973085, "epoch": "8/12", "eta": "0:01:52", "gpu_mem": "13.77G", "grad_norm": 77.86450195, "iter": "40/43", "loss": 1.32784039, "lr": 0.00000122, "top1_err": 26.56250000, "top5_err": 3.12500000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:28:28][INFO] train_net.py:  491: Distillation Loss: 0.20167518
[12/17 00:28:28][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:28:31][INFO] logging.py:   99: json_stats: {"RAM": "54.50/251.74G", "_type": "train_epoch", "dt": 1.55916885, "dt_data": 1.55916829, "dt_net": 0.63561495, "epoch": "8/12", "eta": "0:04:28", "gpu_mem": "13.77G", "grad_norm": 83.67328644, "loss": 1.28632275, "lr": 0.00000118, "top1_err": 20.13081395, "top5_err": 4.72383721}
[12/17 00:28:31][INFO] train_net.py: 1338: Epoch 7 takes 49.82s. Epochs from 0 to 7 take 50.36s in average and 50.41s in median.
[12/17 00:28:31][INFO] train_net.py: 1344: For epoch 7, each iteraction takes 1.16s in average. From epoch 0 to 7, each iteraction takes 1.17s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:29:04][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:03:23", "gpu_mem": "13.77G", "iter": "10/226", "time_diff": 0.94111225, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:29:13][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:03:13", "gpu_mem": "13.77G", "iter": "20/226", "time_diff": 0.93752250, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:29:23][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:03:07", "gpu_mem": "13.77G", "iter": "30/226", "time_diff": 0.95471130, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:29:32][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:02:52", "gpu_mem": "13.77G", "iter": "40/226", "time_diff": 0.92903704, "top1_err": 100.00000000, "top5_err": 92.18750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:29:42][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:02:45", "gpu_mem": "13.77G", "iter": "50/226", "time_diff": 0.94241686, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:29:51][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:02:38", "gpu_mem": "13.77G", "iter": "60/226", "time_diff": 0.95739036, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:30:01][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:02:25", "gpu_mem": "13.77G", "iter": "70/226", "time_diff": 0.93531597, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:30:10][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:02:18", "gpu_mem": "13.77G", "iter": "80/226", "time_diff": 0.94644570, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:30:20][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:02:10", "gpu_mem": "13.77G", "iter": "90/226", "time_diff": 0.95990623, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:30:29][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:02:03", "gpu_mem": "13.77G", "iter": "100/226", "time_diff": 0.97949281, "top1_err": 98.43750000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:30:39][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:01:48", "gpu_mem": "13.77G", "iter": "110/226", "time_diff": 0.93824256, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:30:48][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:01:40", "gpu_mem": "13.77G", "iter": "120/226", "time_diff": 0.94747979, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:30:58][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:01:31", "gpu_mem": "13.77G", "iter": "130/226", "time_diff": 0.94834390, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:31:07][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:01:20", "gpu_mem": "13.77G", "iter": "140/226", "time_diff": 0.93552053, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:31:17][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:01:12", "gpu_mem": "13.77G", "iter": "150/226", "time_diff": 0.95069420, "top1_err": 98.43750000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:31:26][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:01:03", "gpu_mem": "13.77G", "iter": "160/226", "time_diff": 0.95522720, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:31:36][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:00:52", "gpu_mem": "13.77G", "iter": "170/226", "time_diff": 0.94603825, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:31:45][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:00:43", "gpu_mem": "13.77G", "iter": "180/226", "time_diff": 0.94234800, "top1_err": 100.00000000, "top5_err": 98.43750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:31:55][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:00:34", "gpu_mem": "13.77G", "iter": "190/226", "time_diff": 0.94555722, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:32:04][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:00:24", "gpu_mem": "13.77G", "iter": "200/226", "time_diff": 0.94023851, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:32:14][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:00:14", "gpu_mem": "13.77G", "iter": "210/226", "time_diff": 0.93030761, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:32:23][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:00:05", "gpu_mem": "13.77G", "iter": "220/226", "time_diff": 0.91096334, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:32:30][INFO] logging.py:   99: json_stats: {"RAM": "57.46/251.74G", "_type": "val_epoch", "epoch": "8/12", "gpu_mem": "13.77G", "min_top1_err": 98.98835920, "min_top5_err": 93.76385809, "time_diff": 1.67668730, "top1_err": 99.21008869, "top5_err": 95.34368071}
[12/17 00:32:30][INFO] train_net.py:  304: total trainable params:
[12/17 00:32:30][INFO] train_net.py:  307: module.model.positional_embedding
[12/17 00:32:30][INFO] train_net.py:  307: module.model.text_projection
[12/17 00:32:30][INFO] train_net.py:  307: module.model.logit_scale
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.proj
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.ln_final.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.model.ln_final.bias
[12/17 00:32:30][INFO] train_net.py:  307: module.projector_v.0.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.projector_v.2.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.projector_t.0.weight
[12/17 00:32:30][INFO] train_net.py:  307: module.projector_t.2.weight
exponential temporal pooling in train
alpha:0.2
[12/17 00:32:50][INFO] train_net.py:  491: Distillation Loss: 0.20484400
[12/17 00:32:50][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:32:58][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.63954514, "dt_data": 0.00039465, "dt_net": 0.63914971, "epoch": "9/12", "eta": "0:01:43", "gpu_mem": "13.77G", "grad_norm": 69.23491669, "iter": "10/43", "loss": 1.11568010, "lr": 0.00000107, "top1_err": 14.06250000, "top5_err": 3.12500000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:32:58][INFO] train_net.py:  491: Distillation Loss: 0.23366225
[12/17 00:32:58][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:33:04][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.64367266, "dt_data": 0.00043569, "dt_net": 0.64323507, "epoch": "9/12", "eta": "0:01:37", "gpu_mem": "13.77G", "grad_norm": 51.08370590, "iter": "20/43", "loss": 1.03646749, "lr": 9.6E-7, "top1_err": 10.93750000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/17 00:33:04][INFO] train_net.py:  491: Distillation Loss: 0.24019176
[12/17 00:33:04][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:33:11][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.64197588, "dt_data": 0.00020131, "dt_net": 0.64177392, "epoch": "9/12", "eta": "0:01:31", "gpu_mem": "13.77G", "grad_norm": 64.99303436, "iter": "30/43", "loss": 1.00241303, "lr": 8.5E-7, "top1_err": 10.93750000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/17 00:33:11][INFO] train_net.py:  491: Distillation Loss: 0.20868075
[12/17 00:33:11][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:33:17][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.63778455, "dt_data": 0.00018473, "dt_net": 0.63759862, "epoch": "9/12", "eta": "0:01:24", "gpu_mem": "13.77G", "grad_norm": 79.24566650, "iter": "40/43", "loss": 1.08310163, "lr": 7.5E-7, "top1_err": 14.06250000, "top5_err": 3.12500000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:33:17][INFO] train_net.py:  491: Distillation Loss: 0.22945464
[12/17 00:33:17][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:33:21][INFO] logging.py:   99: json_stats: {"RAM": "49.66/251.74G", "_type": "train_epoch", "dt": 2.48653229, "dt_data": 2.48653217, "dt_net": 0.63844237, "epoch": "9/12", "eta": "0:05:20", "gpu_mem": "13.77G", "grad_norm": 78.98168182, "loss": 1.08737005, "lr": 7.2E-7, "top1_err": 13.80813953, "top5_err": 2.18023256}
[12/17 00:33:21][INFO] train_net.py: 1338: Epoch 8 takes 51.29s. Epochs from 0 to 8 take 50.46s in average and 50.44s in median.
[12/17 00:33:21][INFO] train_net.py: 1344: For epoch 8, each iteraction takes 1.19s in average. From epoch 0 to 8, each iteraction takes 1.17s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:33:54][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:03:27", "gpu_mem": "13.77G", "iter": "10/226", "time_diff": 0.96038954, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:34:03][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:03:17", "gpu_mem": "13.77G", "iter": "20/226", "time_diff": 0.95707157, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:34:13][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:03:06", "gpu_mem": "13.77G", "iter": "30/226", "time_diff": 0.95015300, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:34:22][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:03:01", "gpu_mem": "13.77G", "iter": "40/226", "time_diff": 0.97323468, "top1_err": 100.00000000, "top5_err": 92.18750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:34:32][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:02:47", "gpu_mem": "13.77G", "iter": "50/226", "time_diff": 0.94938743, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:34:41][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:02:42", "gpu_mem": "13.77G", "iter": "60/226", "time_diff": 0.97919939, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:34:51][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:02:27", "gpu_mem": "13.77G", "iter": "70/226", "time_diff": 0.94526230, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:35:00][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:02:16", "gpu_mem": "13.77G", "iter": "80/226", "time_diff": 0.93663360, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:35:10][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:02:09", "gpu_mem": "13.77G", "iter": "90/226", "time_diff": 0.95135289, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:35:19][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:02:03", "gpu_mem": "13.77G", "iter": "100/226", "time_diff": 0.97852289, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:35:29][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:01:50", "gpu_mem": "13.77G", "iter": "110/226", "time_diff": 0.95125095, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:35:38][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:01:41", "gpu_mem": "13.77G", "iter": "120/226", "time_diff": 0.95650143, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:35:48][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:01:30", "gpu_mem": "13.77G", "iter": "130/226", "time_diff": 0.94589193, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:35:57][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:01:21", "gpu_mem": "13.77G", "iter": "140/226", "time_diff": 0.94193391, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:36:07][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:01:11", "gpu_mem": "13.77G", "iter": "150/226", "time_diff": 0.94655763, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:36:16][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:01:02", "gpu_mem": "13.77G", "iter": "160/226", "time_diff": 0.94344173, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:36:26][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:00:53", "gpu_mem": "13.77G", "iter": "170/226", "time_diff": 0.94881278, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:36:35][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:00:43", "gpu_mem": "13.77G", "iter": "180/226", "time_diff": 0.94920665, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:36:45][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:00:34", "gpu_mem": "13.77G", "iter": "190/226", "time_diff": 0.94567470, "top1_err": 100.00000000, "top5_err": 92.18750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:36:55][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:00:24", "gpu_mem": "13.77G", "iter": "200/226", "time_diff": 0.95386949, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:37:04][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:00:15", "gpu_mem": "13.77G", "iter": "210/226", "time_diff": 0.94725249, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:37:13][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:00:05", "gpu_mem": "13.77G", "iter": "220/226", "time_diff": 0.90975157, "top1_err": 98.43750000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:37:20][INFO] logging.py:   99: json_stats: {"RAM": "49.77/251.74G", "_type": "val_epoch", "epoch": "9/12", "gpu_mem": "13.77G", "min_top1_err": 98.98835920, "min_top5_err": 93.76385809, "time_diff": 1.76676670, "top1_err": 99.05764967, "top5_err": 94.67849224}
[12/17 00:37:20][INFO] train_net.py:  304: total trainable params:
[12/17 00:37:20][INFO] train_net.py:  307: module.model.positional_embedding
[12/17 00:37:20][INFO] train_net.py:  307: module.model.text_projection
[12/17 00:37:20][INFO] train_net.py:  307: module.model.logit_scale
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.proj
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.ln_final.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.model.ln_final.bias
[12/17 00:37:20][INFO] train_net.py:  307: module.projector_v.0.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.projector_v.2.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.projector_t.0.weight
[12/17 00:37:20][INFO] train_net.py:  307: module.projector_t.2.weight
exponential temporal pooling in train
alpha:0.2
[12/17 00:37:41][INFO] train_net.py:  491: Distillation Loss: 0.22085899
[12/17 00:37:41][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:37:48][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.64336754, "dt_data": 0.00032663, "dt_net": 0.64303971, "epoch": "10/12", "eta": "0:01:16", "gpu_mem": "13.77G", "grad_norm": 85.39252472, "iter": "10/43", "loss": 0.89810872, "lr": 6.3E-7, "top1_err": 6.25000000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/17 00:37:48][INFO] train_net.py:  491: Distillation Loss: 0.19270468
[12/17 00:37:48][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:37:54][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.63457073, "dt_data": 0.00049077, "dt_net": 0.63407835, "epoch": "10/12", "eta": "0:01:09", "gpu_mem": "13.77G", "grad_norm": 60.68257904, "iter": "20/43", "loss": 0.88968310, "lr": 5.4E-7, "top1_err": 6.25000000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/17 00:37:54][INFO] train_net.py:  491: Distillation Loss: 0.17561847
[12/17 00:37:54][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:38:00][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.63938682, "dt_data": 0.00024297, "dt_net": 0.63914265, "epoch": "10/12", "eta": "0:01:03", "gpu_mem": "13.77G", "grad_norm": 85.85450745, "iter": "30/43", "loss": 0.91859329, "lr": 4.5E-7, "top1_err": 7.81250000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/17 00:38:00][INFO] train_net.py:  491: Distillation Loss: 0.21195805
[12/17 00:38:00][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:38:07][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.63313236, "dt_data": 0.00017544, "dt_net": 0.63295552, "epoch": "10/12", "eta": "0:00:56", "gpu_mem": "13.77G", "grad_norm": 65.95362091, "iter": "40/43", "loss": 0.95727617, "lr": 3.8E-7, "top1_err": 7.81250000, "top5_err": 1.56250000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:38:07][INFO] train_net.py:  491: Distillation Loss: 0.22131115
[12/17 00:38:07][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:38:11][INFO] logging.py:   99: json_stats: {"RAM": "49.65/251.74G", "_type": "train_epoch", "dt": 2.38181037, "dt_data": 2.38180976, "dt_net": 0.64091811, "epoch": "10/12", "eta": "0:03:24", "gpu_mem": "13.77G", "grad_norm": 73.34207916, "loss": 0.95980654, "lr": 3.6E-7, "top1_err": 8.43023256, "top5_err": 1.52616279}
[12/17 00:38:11][INFO] train_net.py: 1338: Epoch 9 takes 50.67s. Epochs from 0 to 9 take 50.48s in average and 50.47s in median.
[12/17 00:38:11][INFO] train_net.py: 1344: For epoch 9, each iteraction takes 1.18s in average. From epoch 0 to 9, each iteraction takes 1.17s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:38:43][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:03:24", "gpu_mem": "13.77G", "iter": "10/226", "time_diff": 0.94474350, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:38:53][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:03:14", "gpu_mem": "13.77G", "iter": "20/226", "time_diff": 0.94319526, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:39:02][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:03:10", "gpu_mem": "13.77G", "iter": "30/226", "time_diff": 0.97023109, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:39:12][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:02:54", "gpu_mem": "13.77G", "iter": "40/226", "time_diff": 0.93876892, "top1_err": 98.43750000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:39:21][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:02:47", "gpu_mem": "13.77G", "iter": "50/226", "time_diff": 0.95444226, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:39:31][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:02:37", "gpu_mem": "13.77G", "iter": "60/226", "time_diff": 0.95132875, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:39:41][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:02:30", "gpu_mem": "13.77G", "iter": "70/226", "time_diff": 0.96550886, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:39:50][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:02:22", "gpu_mem": "13.77G", "iter": "80/226", "time_diff": 0.97686474, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:40:00][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:02:09", "gpu_mem": "13.77G", "iter": "90/226", "time_diff": 0.95169622, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:40:09][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:02:00", "gpu_mem": "13.77G", "iter": "100/226", "time_diff": 0.95605185, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:40:19][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:01:48", "gpu_mem": "13.77G", "iter": "110/226", "time_diff": 0.93945517, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:40:28][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:01:40", "gpu_mem": "13.77G", "iter": "120/226", "time_diff": 0.94796022, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:40:38][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:01:30", "gpu_mem": "13.77G", "iter": "130/226", "time_diff": 0.94581279, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:40:47][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:01:20", "gpu_mem": "13.77G", "iter": "140/226", "time_diff": 0.93899483, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:40:57][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:01:13", "gpu_mem": "13.77G", "iter": "150/226", "time_diff": 0.96845517, "top1_err": 98.43750000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:41:06][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:01:03", "gpu_mem": "13.77G", "iter": "160/226", "time_diff": 0.96335155, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:41:16][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:00:53", "gpu_mem": "13.77G", "iter": "170/226", "time_diff": 0.95957932, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:41:25][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:00:43", "gpu_mem": "13.77G", "iter": "180/226", "time_diff": 0.94445146, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:41:35][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:00:34", "gpu_mem": "13.77G", "iter": "190/226", "time_diff": 0.95782440, "top1_err": 98.43750000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:41:44][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:00:24", "gpu_mem": "13.77G", "iter": "200/226", "time_diff": 0.95312477, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:41:54][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:00:14", "gpu_mem": "13.77G", "iter": "210/226", "time_diff": 0.92929693, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:42:03][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:00:05", "gpu_mem": "13.77G", "iter": "220/226", "time_diff": 0.90530602, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:42:10][INFO] logging.py:   99: json_stats: {"RAM": "49.68/251.74G", "_type": "val_epoch", "epoch": "10/12", "gpu_mem": "13.77G", "min_top1_err": 98.98835920, "min_top5_err": 93.76385809, "time_diff": 1.98590737, "top1_err": 99.19623060, "top5_err": 94.55376940}
[12/17 00:42:10][INFO] train_net.py:  304: total trainable params:
[12/17 00:42:10][INFO] train_net.py:  307: module.model.positional_embedding
[12/17 00:42:10][INFO] train_net.py:  307: module.model.text_projection
[12/17 00:42:10][INFO] train_net.py:  307: module.model.logit_scale
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.proj
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.ln_final.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.model.ln_final.bias
[12/17 00:42:10][INFO] train_net.py:  307: module.projector_v.0.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.projector_v.2.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.projector_t.0.weight
[12/17 00:42:10][INFO] train_net.py:  307: module.projector_t.2.weight
exponential temporal pooling in train
alpha:0.2
[12/17 00:42:31][INFO] train_net.py:  491: Distillation Loss: 0.21189642
[12/17 00:42:31][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:42:38][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.64550875, "dt_data": 0.00040387, "dt_net": 0.64510327, "epoch": "11/12", "eta": "0:00:49", "gpu_mem": "13.77G", "grad_norm": 63.18157959, "iter": "10/43", "loss": 0.91701877, "lr": 2.9E-7, "top1_err": 6.25000000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/17 00:42:38][INFO] train_net.py:  491: Distillation Loss: 0.23063147
[12/17 00:42:38][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:42:44][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.64836062, "dt_data": 0.00055790, "dt_net": 0.64780063, "epoch": "11/12", "eta": "0:00:42", "gpu_mem": "13.77G", "grad_norm": 75.62014771, "iter": "20/43", "loss": 0.90031189, "lr": 2.3E-7, "top1_err": 9.37500000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/17 00:42:44][INFO] train_net.py:  491: Distillation Loss: 0.20018888
[12/17 00:42:44][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:42:50][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.63463614, "dt_data": 0.00028835, "dt_net": 0.63434546, "epoch": "11/12", "eta": "0:00:35", "gpu_mem": "13.77G", "grad_norm": 55.72624969, "iter": "30/43", "loss": 0.92649809, "lr": 1.7E-7, "top1_err": 7.81250000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/17 00:42:51][INFO] train_net.py:  491: Distillation Loss: 0.21865708
[12/17 00:42:51][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:42:57][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.63695094, "dt_data": 0.00016821, "dt_net": 0.63678169, "epoch": "11/12", "eta": "0:00:29", "gpu_mem": "13.77G", "grad_norm": 75.60575104, "iter": "40/43", "loss": 0.95567471, "lr": 1.3E-7, "top1_err": 6.25000000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/17 00:42:57][INFO] train_net.py:  491: Distillation Loss: 0.19818956
[12/17 00:42:57][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:43:01][INFO] logging.py:   99: json_stats: {"RAM": "49.61/251.74G", "_type": "train_epoch", "dt": 1.91963058, "dt_data": 1.91962983, "dt_net": 0.63782153, "epoch": "11/12", "eta": "0:01:22", "gpu_mem": "13.77G", "grad_norm": 66.00301361, "loss": 0.93118549, "lr": 1.2E-7, "top1_err": 7.92151163, "top5_err": 1.09011628}
[12/17 00:43:01][INFO] train_net.py: 1338: Epoch 10 takes 50.30s. Epochs from 0 to 10 take 50.47s in average and 50.44s in median.
[12/17 00:43:01][INFO] train_net.py: 1344: For epoch 10, each iteraction takes 1.17s in average. From epoch 0 to 10, each iteraction takes 1.17s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:43:33][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:03:25", "gpu_mem": "13.77G", "iter": "10/226", "time_diff": 0.95214768, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:43:43][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:03:16", "gpu_mem": "13.77G", "iter": "20/226", "time_diff": 0.95153202, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:43:52][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:03:05", "gpu_mem": "13.77G", "iter": "30/226", "time_diff": 0.94787422, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:44:02][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:02:58", "gpu_mem": "13.77G", "iter": "40/226", "time_diff": 0.95951752, "top1_err": 98.43750000, "top5_err": 90.62500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:44:11][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:02:44", "gpu_mem": "13.77G", "iter": "50/226", "time_diff": 0.93413478, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:44:21][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:02:38", "gpu_mem": "13.77G", "iter": "60/226", "time_diff": 0.95327219, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:44:30][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:02:30", "gpu_mem": "13.77G", "iter": "70/226", "time_diff": 0.96755061, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:44:40][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:02:17", "gpu_mem": "13.77G", "iter": "80/226", "time_diff": 0.94035413, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:44:49][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:02:10", "gpu_mem": "13.77G", "iter": "90/226", "time_diff": 0.95607110, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:44:59][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:02:00", "gpu_mem": "13.77G", "iter": "100/226", "time_diff": 0.95700339, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:45:08][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:01:50", "gpu_mem": "13.77G", "iter": "110/226", "time_diff": 0.95323587, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:45:18][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:01:39", "gpu_mem": "13.77G", "iter": "120/226", "time_diff": 0.93930714, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:45:27][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:01:31", "gpu_mem": "13.77G", "iter": "130/226", "time_diff": 0.95552992, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:45:36][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:01:22", "gpu_mem": "13.77G", "iter": "140/226", "time_diff": 0.95978678, "top1_err": 100.00000000, "top5_err": 92.18750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:45:46][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:01:16", "gpu_mem": "13.77G", "iter": "150/226", "time_diff": 1.00400529, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:45:55][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:01:02", "gpu_mem": "13.77G", "iter": "160/226", "time_diff": 0.94621349, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:46:05][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:00:52", "gpu_mem": "13.77G", "iter": "170/226", "time_diff": 0.94137349, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:46:14][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:00:43", "gpu_mem": "13.77G", "iter": "180/226", "time_diff": 0.94485494, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:46:24][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:00:33", "gpu_mem": "13.77G", "iter": "190/226", "time_diff": 0.93926822, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:46:33][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:00:24", "gpu_mem": "13.77G", "iter": "200/226", "time_diff": 0.94384427, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:46:43][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:00:14", "gpu_mem": "13.77G", "iter": "210/226", "time_diff": 0.93131188, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:46:52][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:00:05", "gpu_mem": "13.77G", "iter": "220/226", "time_diff": 0.91023337, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:46:59][INFO] logging.py:   99: json_stats: {"RAM": "60.14/251.74G", "_type": "val_epoch", "epoch": "11/12", "gpu_mem": "13.77G", "min_top1_err": 98.98835920, "min_top5_err": 93.76385809, "time_diff": 1.39730502, "top1_err": 99.02993348, "top5_err": 94.69235033}
[12/17 00:46:59][INFO] train_net.py:  304: total trainable params:
[12/17 00:46:59][INFO] train_net.py:  307: module.model.positional_embedding
[12/17 00:46:59][INFO] train_net.py:  307: module.model.text_projection
[12/17 00:46:59][INFO] train_net.py:  307: module.model.logit_scale
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.proj
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.ln_final.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.model.ln_final.bias
[12/17 00:46:59][INFO] train_net.py:  307: module.projector_v.0.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.projector_v.2.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.projector_t.0.weight
[12/17 00:46:59][INFO] train_net.py:  307: module.projector_t.2.weight
exponential temporal pooling in train
alpha:0.2
[12/17 00:47:19][INFO] train_net.py:  491: Distillation Loss: 0.19677627
[12/17 00:47:19][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:47:26][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.63286864, "dt_data": 0.00029358, "dt_net": 0.63257353, "epoch": "12/12", "eta": "0:00:20", "gpu_mem": "13.77G", "grad_norm": 52.34716797, "iter": "10/43", "loss": 0.90592289, "lr": 8E-8, "top1_err": 6.25000000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/17 00:47:27][INFO] train_net.py:  491: Distillation Loss: 0.21991444
[12/17 00:47:27][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:47:33][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.64320052, "dt_data": 0.00067391, "dt_net": 0.64252387, "epoch": "12/12", "eta": "0:00:14", "gpu_mem": "13.77G", "grad_norm": 65.04744720, "iter": "20/43", "loss": 0.89128959, "lr": 6E-8, "top1_err": 6.25000000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/17 00:47:33][INFO] train_net.py:  491: Distillation Loss: 0.19962877
[12/17 00:47:33][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:47:39][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.63605637, "dt_data": 0.00028845, "dt_net": 0.63576560, "epoch": "12/12", "eta": "0:00:08", "gpu_mem": "13.77G", "grad_norm": 50.22714615, "iter": "30/43", "loss": 0.94562861, "lr": 4E-8, "top1_err": 6.25000000, "top5_err": 3.12500000}
exponential temporal pooling in train
alpha:0.2
[12/17 00:47:39][INFO] train_net.py:  491: Distillation Loss: 0.24462736
[12/17 00:47:39][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:47:46][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.63986923, "dt_data": 0.00018854, "dt_net": 0.63968008, "epoch": "12/12", "eta": "0:00:01", "gpu_mem": "13.77G", "grad_norm": 73.71112823, "iter": "40/43", "loss": 0.95379263, "lr": 3E-8, "top1_err": 7.81250000, "top5_err": 0E-8}
exponential temporal pooling in train
alpha:0.2
[12/17 00:47:46][INFO] train_net.py:  491: Distillation Loss: 0.23369813
[12/17 00:47:46][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
exponential temporal pooling in train
alpha:0.2
exponential temporal pooling in train
alpha:0.2
[12/17 00:47:50][INFO] logging.py:   99: json_stats: {"RAM": "49.73/251.74G", "_type": "train_epoch", "dt": 2.44230589, "dt_data": 2.44230411, "dt_net": 0.64143380, "epoch": "12/12", "eta": "0:00:00", "gpu_mem": "13.77G", "grad_norm": 59.12789536, "loss": 0.90314150, "lr": 3E-8, "top1_err": 7.41279070, "top5_err": 1.38081395}
[12/17 00:47:50][INFO] train_net.py: 1338: Epoch 11 takes 51.28s. Epochs from 0 to 11 take 50.53s in average and 50.47s in median.
[12/17 00:47:50][INFO] train_net.py: 1344: For epoch 11, each iteraction takes 1.19s in average. From epoch 0 to 11, each iteraction takes 1.18s in average.
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:48:23][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:03:29", "gpu_mem": "13.77G", "iter": "10/226", "time_diff": 0.97168281, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:48:32][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:03:18", "gpu_mem": "13.77G", "iter": "20/226", "time_diff": 0.96339693, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:48:42][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:03:10", "gpu_mem": "13.77G", "iter": "30/226", "time_diff": 0.97344022, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:48:51][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:02:59", "gpu_mem": "13.77G", "iter": "40/226", "time_diff": 0.96771068, "top1_err": 98.43750000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:49:01][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:02:49", "gpu_mem": "13.77G", "iter": "50/226", "time_diff": 0.96092042, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:49:10][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:02:35", "gpu_mem": "13.77G", "iter": "60/226", "time_diff": 0.93729224, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:49:20][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:02:30", "gpu_mem": "13.77G", "iter": "70/226", "time_diff": 0.96232665, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:49:29][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:02:21", "gpu_mem": "13.77G", "iter": "80/226", "time_diff": 0.97188624, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:49:39][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:02:10", "gpu_mem": "13.77G", "iter": "90/226", "time_diff": 0.96158730, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:49:48][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:01:57", "gpu_mem": "13.77G", "iter": "100/226", "time_diff": 0.93612741, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:49:58][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:01:50", "gpu_mem": "13.77G", "iter": "110/226", "time_diff": 0.95504514, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:50:07][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:01:42", "gpu_mem": "13.77G", "iter": "120/226", "time_diff": 0.96590534, "top1_err": 98.43750000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:50:17][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:01:31", "gpu_mem": "13.77G", "iter": "130/226", "time_diff": 0.95089779, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:50:27][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:01:20", "gpu_mem": "13.77G", "iter": "140/226", "time_diff": 0.94117699, "top1_err": 100.00000000, "top5_err": 92.18750000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:50:36][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:01:13", "gpu_mem": "13.77G", "iter": "150/226", "time_diff": 0.97054524, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:50:45][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:01:02", "gpu_mem": "13.77G", "iter": "160/226", "time_diff": 0.94978754, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:50:55][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:00:54", "gpu_mem": "13.77G", "iter": "170/226", "time_diff": 0.97133387, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:51:05][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:00:43", "gpu_mem": "13.77G", "iter": "180/226", "time_diff": 0.93755816, "top1_err": 100.00000000, "top5_err": 96.87500000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:51:14][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:00:34", "gpu_mem": "13.77G", "iter": "190/226", "time_diff": 0.95344095, "top1_err": 96.87500000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:51:24][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:00:24", "gpu_mem": "13.77G", "iter": "200/226", "time_diff": 0.94676867, "top1_err": 100.00000000, "top5_err": 95.31250000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:51:33][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:00:15", "gpu_mem": "13.77G", "iter": "210/226", "time_diff": 0.95854926, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:51:42][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:00:05", "gpu_mem": "13.77G", "iter": "220/226", "time_diff": 0.90862344, "top1_err": 100.00000000, "top5_err": 93.75000000}
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
exponential temporal pooling in test
alpha:0.2
[12/17 00:51:49][INFO] logging.py:   99: json_stats: {"RAM": "52.30/251.74G", "_type": "val_epoch", "epoch": "12/12", "gpu_mem": "13.77G", "min_top1_err": 98.98835920, "min_top5_err": 93.76385809, "time_diff": 1.78281014, "top1_err": 99.16851441, "top5_err": 94.63691796}
[12/17 00:51:49][INFO] train_net.py: 1443: training done: _p300.29_f10.00 _t0.84_m13.77 _a1.01 Top5 Acc: 6.24 MEM: 13.77 f: 10.0000
[12/17 00:51:55][INFO] test_net.py:  319: Test with config:
[12/17 00:51:55][INFO] test_net.py:  320: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: False
  GEN_MASK_LOADER: False
  INTERPOLATION: bicubic
  MASK_FRAMES: False
  MASK_RATIO: 0.0
  MASK_TUBE: False
  MASK_WINDOW_SIZE: [8, 7, 7]
  MAX_MASK_PATCHES_PER_BLOCK: None
  NUM_SAMPLE: 1
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  BGR: False
  DETECTION_SCORE_THRESH: 0.9
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: /mnt/fair-flash3-east/ava_trainval_frames.img/
  FRAME_LIST_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  FULL_TEST_ON_VAL: False
  GROUNDTRUTH_FILE: ava_val_v2.2.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: ava_action_list_v2.2_for_activitynet_2019.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_val_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train_v2.2.csv']
  TRAIN_LISTS: ['train_all.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  GLOBAL_SYNC: False
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
CONTRASTIVE:
  BN_MLP: False
  BN_SYNC_MLP: False
  DELTA_CLIPS_MAX: inf
  DELTA_CLIPS_MIN: -inf
  DIM: 128
  INTERP_MEMORY: False
  KNN_ON: True
  LENGTH: 239975
  LOCAL_SHUFFLE_BN: True
  MEM_TYPE: 1d
  MLP_DIM: 2048
  MOCO_MULTI_VIEW_QUEUE: False
  MOMENTUM: 0.5
  MOMENTUM_ANNEALING: False
  NUM_CLASSES_DOWNSTREAM: 400
  NUM_MLP_LAYERS: 1
  PREDICTOR_DEPTHS: []
  QUEUE_LEN: 65536
  SEQUENTIAL: False
  SIMCLR_DIST_ON: True
  SWAV_QEUE_LEN: 0
  T: 0.07
  TYPE: mem
DATA:
  COLOR_RND_GRAYSCALE: 0.0
  DECODING_BACKEND: pyav
  DECODING_SHORT_SIZE: 256
  DUMMY_LOAD: False
  ENSEMBLE_METHOD: sum
  IN22K_TRAINVAL: False
  IN22k_VAL_IN1K: 
  INDEX_LABEL_MAPPING_FILE: /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_ssv2/train_rephrased.json
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  IN_VAL_CROP_RATIO: 0.875
  LOADER_CHUNK_OVERALL_SIZE: 0
  LOADER_CHUNK_SIZE: 0
  MEAN: [0.48145466, 0.4578275, 0.40821073]
  MULTI_LABEL: False
  NUM_FRAMES: 8
  PATH_LABEL_SEPARATOR: ,
  PATH_PREFIX: /mnt/SSD8T/home/huangwei/projects/FROSTER/data/ssv2/videos
  PATH_TO_DATA_DIR: /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_ssv2
  PATH_TO_PRELOAD_IMDB: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 16
  SKIP_ROWS: 0
  SSL_BLUR_SIGMA_MAX: [0.0, 2.0]
  SSL_BLUR_SIGMA_MIN: [0.0, 0.1]
  SSL_COLOR_BRI_CON_SAT: [0.4, 0.4, 0.4]
  SSL_COLOR_HUE: 0.1
  SSL_COLOR_JITTER: False
  SSL_MOCOV2_AUG: False
  STD: [0.26862954, 0.26130258, 0.27577711]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TIME_DIFF_PROB: 0.0
  TRAIN_CROP_NUM_SPATIAL: 1
  TRAIN_CROP_NUM_TEMPORAL: 1
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: []
  TRAIN_JITTER_FPS: 0.0
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [224, 256]
  TRAIN_JITTER_SCALES_RELATIVE: []
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: False
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
IMAGENET_SIMPLELABEL_PATH: None
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MASK:
  DECODER_DEPTH: 0
  DECODER_EMBED_DIM: 512
  DECODER_SEP_POS_EMBED: False
  DEC_KV_KERNEL: []
  DEC_KV_STRIDE: []
  ENABLE: False
  HEAD_TYPE: separate
  MAE_ON: False
  MAE_RND_MASK: False
  NORM_PRED_PIXEL: True
  PER_FRAME_MASKING: False
  PRED_HOG: False
  PRETRAIN_DEPTH: [15]
  SCALE_INIT_BY_DEPTH: False
  TIME_STRIDE_LOSS: True
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: False
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ADAPT_FINETUNE_FACTOR: 1.0
  ARCH: vitb16
  CLS_LOSS_RATIO: 1.0
  CONTEXT_LENGTH: 77
  DEFAULT_FINETUNE_FACTOR: 1.0
  DETACH_FINAL_FC: False
  DISTILLATION_RATIO: 2.0
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  ENSEMBLE_PRED: False
  ENSEMBLE_RAWMODEL_RATIO: 0.0
  EXPERT_FINETUNE_FACTOR: 1.0
  EXPERT_INSERT_LAYERS: [10, 11]
  FC_INIT_STD: 0.01
  FINETUNE_FACTOR: 1.0
  FP16_ALLREDUCE: False
  FROZEN_BN: False
  HEAD_ACT: softmax
  KEEP_RAW_MODEL: True
  LOSS_FREQ_TYPE: mse
  LOSS_FUNC: soft_cross_entropy
  MLP_FINETUNE_FACTOR: 1.0
  MODEL_NAME: TemporalClipVideo
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 87
  NUM_EXPERTS: 0
  PROMPT_NUM: 1
  RAW_MODEL_DISTILLATION: True
  RECORD_ROUTING: False
  ROUTING_FINETUNE_FACTOR: 1.0
  ROUTING_FREQUENCE_CONSTRAIN: 0.5
  ROUTING_FREQ_CONS_FACTOR: 1.0
  ROUTING_TYPE: patch-level
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'maskmvit', 'vitb32', 'vitb16', 'vitl14']
  STATIC_GRAPH: False
  TEMPORAL_MODELING_TYPE: expand_temporal_view
  TEXT_PROMPT: False
  USE_CHECKPOINT: False
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 16
  DIM_MUL: []
  DIM_MUL_IN_ATT: False
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.1
  EMBED_DIM: 96
  HEAD_INIT_SCALE: 1.0
  HEAD_MUL: []
  LAYER_SCALE_INIT_VALUE: 0.0
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [2, 4, 4]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: None
  POOL_KV_STRIDE: []
  POOL_KV_STRIDE_ADAPTIVE: None
  POOL_Q_STRIDE: []
  QKV_BIAS: True
  REL_POS_SPATIAL: False
  REL_POS_TEMPORAL: False
  REL_POS_ZERO_INIT: False
  RESIDUAL_POOLING: False
  REV:
    BUFFER_LAYERS: []
    ENABLE: False
    PRE_Q_FUSION: avg
    RESPATH_FUSE: concat
    RES_PATH: conv
  SEPARATE_QKV: False
  SEP_POS_EMBED: False
  USE_ABS_POS: True
  USE_FIXED_SINCOS_POS: False
  USE_MEAN_POOLING: False
  ZERO_DECAY_POS_CLS: True
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 8
NUM_SHARDS: 1
OUTPUT_DIR: /mnt/SSD8T/home/huangwei/projects/FROSTER/checkpoints/basetraining/B2N_ssv2_froster_exp02
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
  ZERO_INIT_FINAL_CONV: False
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 3.33e-06
  BASE_LR_SCALE_NUM_SHARDS: True
  BETAS: (0.9, 0.999)
  CLIP_GRAD_L2NORM: 1.0
  CLIP_GRAD_VAL: None
  COSINE_AFTER_WARMUP: True
  COSINE_END_LR: 3.33e-08
  COSINE_RESTART_EPOCH: 0
  DAMPENING: 0.0
  GAMMA: 0.1
  LARS_ON: False
  LAYER_DECAY: 1.0
  LRS: []
  LR_POLICY: cosine
  MAX_EPOCH: 12
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: []
  STEP_SIZE: 1
  WARMUP_EPOCHS: 2.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 3.33e-08
  WEIGHT_DECAY: 0.01
  ZERO_WD_1D_PARAM: True
TASK: 
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 240
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_TYPE: pytorch
  CLIP_ORI_PATH: None
  CUSTOM_LOAD: False
  CUSTOM_LOAD_FILE: None
  DATASET: kinetics
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 3
  NUM_SPATIAL_CROPS: 1
  NUM_TEMPORAL_CLIPS: [3]
  OPENSET: False
  PATCHING_MODEL: False
  PATCHING_RATIO: 0.5
  SAVE_RESULTS_PATH: 
  UPDATE_STATE: False
TEST_FILE: test.csv
TRAIN:
  ADAPT_ZS_CONS_RATIO: False
  AUTO_RESUME: True
  BATCH_SIZE: 32
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_INFLATE: False
  CHECKPOINT_IN_INIT: False
  CHECKPOINT_PERIOD: 1
  CHECKPOINT_TYPE: pytorch
  CLIP_ORI_PATH: /mnt/SSD8T/home/huangwei/.cache/clip/ViT-B-16.pt
  CUSTOM_LOAD: False
  CUSTOM_LOAD_FILE: None
  DATASET: kinetics
  ENABLE: True
  EVAL_PERIOD: 1
  EWC_CONSTRAIN_RATIO: 1.0
  EWC_IDENTITY_FISHER: False
  EWC_IGNORE_LOGIT_SCALE: False
  EWC_LOAD_FILE: None
  EWC_SET: False
  KILL_LOSS_EXPLOSION_FACTOR: 0.0
  LINEAR_CONNECT_CLIMB: False
  LINEAR_CONNECT_LOSS_RATIO: 0.0
  LINEAR_CONNECT_SAMPLE: True
  LINEAR_CONNECT_SAMPLE_L: 0.4
  LINEAR_CONNECT_SAMPLE_R: 0.6
  MIXED_PRECISION: True
  ZS_CONS: False
  ZS_CONS_RATIO: 0.8
  ZS_INIT_CONS: False
  ZS_RESTART_CONS: False
  ZS_RESTART_EPOCH: -1
TRAIN_FILE: train.csv
TUNE_HEAD: False
VAL_FILE: test.csv
VAL_MODE: False
VIS_MASK:
  ENABLE: False
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[12/17 00:51:59][INFO] temporalclip_video_model.py:  657: load pretrained CLIP:<All keys matched successfully>
[12/17 00:52:07][INFO] temporalclip_video_model.py:  657: load pretrained CLIP:<All keys matched successfully>
[12/17 00:52:08][INFO] checkpoint.py:  222: Loading network weights from /mnt/SSD8T/home/huangwei/projects/FROSTER/checkpoints/basetraining/B2N_ssv2_froster_exp02/checkpoints/checkpoint_epoch_00012.pyth.
missing keys: []
unexpected keys: []
[12/17 00:52:10][INFO] misc.py:  185: Model:
DistributedDataParallel(
  (module): TemporalClipVideo(
    (model): WCLIP(
      (visual): TemporalVisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): TSTransformer(
          (resblocks): Sequential(
            (0): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (raw_model): WCLIP(
      (visual): TemporalVisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): TSTransformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (projector_v): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): GELU()
      (2): Linear(in_features=512, out_features=512, bias=False)
    )
    (projector_t): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): GELU()
      (2): Linear(in_features=512, out_features=512, bias=False)
    )
  )
)
[12/17 00:52:10][INFO] misc.py:  187: Params: 300,290,050
[12/17 00:52:10][INFO] misc.py:  188: Mem: 1.6981406211853027 MB
[12/17 00:52:10][INFO] misc.py:  197: nvidia-smi
Tue Dec 17 00:52:10 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  Off |
| 42%   38C    P2    75W / 450W |   5130MiB / 24564MiB |     30%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:23:00.0 Off |                  Off |
| 42%   38C    P2    70W / 450W |   5130MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:41:00.0 Off |                  Off |
| 41%   40C    P2    78W / 450W |   5130MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:61:00.0 Off |                  Off |
| 40%   40C    P2    76W / 450W |   5130MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   4  NVIDIA GeForce ...  Off  | 00000000:81:00.0 Off |                  Off |
| 42%   39C    P2    73W / 450W |   5130MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   5  NVIDIA GeForce ...  Off  | 00000000:A1:00.0 Off |                  Off |
| 41%   38C    P2    73W / 450W |   5130MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   6  NVIDIA GeForce ...  Off  | 00000000:C1:00.0 Off |                  Off |
| 42%   38C    P2    68W / 450W |   5130MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   7  NVIDIA GeForce ...  Off  | 00000000:E1:00.0 Off |                  Off |
| 40%   37C    P2    73W / 450W |   5130MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    0   N/A  N/A   1340300      C   .../envs/slowfast/bin/python     5122MiB |
|    1   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    1   N/A  N/A   1340301      C   .../envs/slowfast/bin/python     5122MiB |
|    2   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    2   N/A  N/A   1340302      C   .../envs/slowfast/bin/python     5122MiB |
|    3   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    3   N/A  N/A   1340303      C   .../envs/slowfast/bin/python     5122MiB |
|    4   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    4   N/A  N/A   1340304      C   .../envs/slowfast/bin/python     5122MiB |
|    5   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    5   N/A  N/A   1340306      C   .../envs/slowfast/bin/python     5122MiB |
|    6   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    6   N/A  N/A   1340308      C   .../envs/slowfast/bin/python     5122MiB |
|    7   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    7   N/A  N/A   1340310      C   .../envs/slowfast/bin/python     5122MiB |
+-----------------------------------------------------------------------------+
[12/17 00:52:10][INFO] misc.py:  185: Model:
DistributedDataParallel(
  (module): TemporalClipVideo(
    (model): WCLIP(
      (visual): TemporalVisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): TSTransformer(
          (resblocks): Sequential(
            (0): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (raw_model): WCLIP(
      (visual): TemporalVisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): TSTransformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (projector_v): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): GELU()
      (2): Linear(in_features=512, out_features=512, bias=False)
    )
    (projector_t): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): GELU()
      (2): Linear(in_features=512, out_features=512, bias=False)
    )
  )
)
[12/17 00:52:10][INFO] misc.py:  187: Params: 300,290,050
[12/17 00:52:10][INFO] misc.py:  188: Mem: 1.6981406211853027 MB
[12/17 00:52:10][INFO] misc.py:  197: nvidia-smi
Tue Dec 17 00:52:11 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  Off |
| 42%   38C    P2    71W / 450W |   5130MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:23:00.0 Off |                  Off |
| 42%   38C    P2    66W / 450W |   5130MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:41:00.0 Off |                  Off |
| 41%   39C    P2    74W / 450W |   5130MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:61:00.0 Off |                  Off |
| 40%   39C    P2    73W / 450W |   5130MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   4  NVIDIA GeForce ...  Off  | 00000000:81:00.0 Off |                  Off |
| 42%   39C    P2    69W / 450W |   5130MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   5  NVIDIA GeForce ...  Off  | 00000000:A1:00.0 Off |                  Off |
| 41%   38C    P2    70W / 450W |   5130MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   6  NVIDIA GeForce ...  Off  | 00000000:C1:00.0 Off |                  Off |
| 42%   38C    P2    65W / 450W |   5130MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   7  NVIDIA GeForce ...  Off  | 00000000:E1:00.0 Off |                  Off |
| 40%   36C    P2    70W / 450W |   5130MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    0   N/A  N/A   1340300      C   .../envs/slowfast/bin/python     5122MiB |
|    1   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    1   N/A  N/A   1340301      C   .../envs/slowfast/bin/python     5122MiB |
|    2   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    2   N/A  N/A   1340302      C   .../envs/slowfast/bin/python     5122MiB |
|    3   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    3   N/A  N/A   1340303      C   .../envs/slowfast/bin/python     5122MiB |
|    4   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    4   N/A  N/A   1340304      C   .../envs/slowfast/bin/python     5122MiB |
|    5   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    5   N/A  N/A   1340306      C   .../envs/slowfast/bin/python     5122MiB |
|    6   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    6   N/A  N/A   1340308      C   .../envs/slowfast/bin/python     5122MiB |
|    7   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    7   N/A  N/A   1340310      C   .../envs/slowfast/bin/python     5122MiB |
+-----------------------------------------------------------------------------+
[12/17 00:52:13][INFO] kinetics.py:   94: Constructing Kinetics test...
path: ---------------------------- /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_ssv2/test.csv
[12/17 00:52:13][INFO] kinetics.py:  172: Constructing kinetics dataloader (size: 21645 skip_rows 0) from /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_ssv2/test.csv 
[12/17 00:52:13][INFO] test_net.py:  434: Testing model for 91 iterations
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/mnt/SSD8T/home/huangwei/anaconda3/envs/slowfast/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/mnt/SSD8T/home/huangwei/anaconda3/envs/slowfast/lib/python3.8/multiprocessing/spawn.py", line 126, in _main
    self = reduction.pickle.load(from_parent)
_pickle.UnpicklingError: pickle data was truncated
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/mnt/SSD8T/home/huangwei/anaconda3/envs/slowfast/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/mnt/SSD8T/home/huangwei/anaconda3/envs/slowfast/lib/python3.8/multiprocessing/spawn.py", line 126, in _main
    self = reduction.pickle.load(from_parent)
_pickle.UnpicklingError: pickle data was truncated
Traceback (most recent call last):
  File "tools/run_net.py", line 56, in <module>
    main()
  File "tools/run_net.py", line 41, in main
    launch_job(cfg=cfg, init_method=args.init_method, func=test)
  File "/mnt/SSD8T/home/huangwei/projects/FROSTER/slowfast/utils/misc.py", line 416, in launch_job
    torch.multiprocessing.spawn(
  File "/mnt/SSD8T/home/huangwei/anaconda3/envs/slowfast/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 240, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/SSD8T/home/huangwei/anaconda3/envs/slowfast/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 198, in start_processes
    while not context.join():
  File "/mnt/SSD8T/home/huangwei/anaconda3/envs/slowfast/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 6 terminated with signal SIGKILL
