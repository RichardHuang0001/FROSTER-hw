config files: ['configs/Kinetics/TemporalCLIP_vitb16_8x16_STAdapter_HMDB51.yaml']
[12/17 16:29:19][INFO] train_net.py:  948: --Train with config:
[12/17 16:29:19][INFO] train_net.py:  949: {'AUG': {'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': False,
         'GEN_MASK_LOADER': False,
         'INTERPOLATION': 'bicubic',
         'MASK_FRAMES': False,
         'MASK_RATIO': 0.0,
         'MASK_TUBE': False,
         'MASK_WINDOW_SIZE': [8, 7, 7],
         'MAX_MASK_PATCHES_PER_BLOCK': None,
         'NUM_SAMPLE': 1,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train_all.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'GLOBAL_SYNC': False,
        'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'CONTRASTIVE': {'BN_MLP': False,
                 'BN_SYNC_MLP': False,
                 'DELTA_CLIPS_MAX': inf,
                 'DELTA_CLIPS_MIN': -inf,
                 'DIM': 128,
                 'INTERP_MEMORY': False,
                 'KNN_ON': True,
                 'LENGTH': 239975,
                 'LOCAL_SHUFFLE_BN': True,
                 'MEM_TYPE': '1d',
                 'MLP_DIM': 2048,
                 'MOCO_MULTI_VIEW_QUEUE': False,
                 'MOMENTUM': 0.5,
                 'MOMENTUM_ANNEALING': False,
                 'NUM_CLASSES_DOWNSTREAM': 400,
                 'NUM_MLP_LAYERS': 1,
                 'PREDICTOR_DEPTHS': [],
                 'QUEUE_LEN': 65536,
                 'SEQUENTIAL': False,
                 'SIMCLR_DIST_ON': True,
                 'SWAV_QEUE_LEN': 0,
                 'T': 0.07,
                 'TYPE': 'mem'},
 'DATA': {'COLOR_RND_GRAYSCALE': 0.0,
          'DECODING_BACKEND': 'pyav',
          'DECODING_SHORT_SIZE': 256,
          'DUMMY_LOAD': False,
          'ENSEMBLE_METHOD': 'sum',
          'IN22K_TRAINVAL': False,
          'IN22k_VAL_IN1K': '',
          'INDEX_LABEL_MAPPING_FILE': '/mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/train_rephrased.json',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'IN_VAL_CROP_RATIO': 0.875,
          'LOADER_CHUNK_OVERALL_SIZE': 0,
          'LOADER_CHUNK_SIZE': 0,
          'MEAN': [0.48145466, 0.4578275, 0.40821073],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 8,
          'PATH_LABEL_SEPARATOR': ',',
          'PATH_PREFIX': '/mnt/SSD8T/home/huangwei/projects/FROSTER/data/hmdb51',
          'PATH_TO_DATA_DIR': '/mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb',
          'PATH_TO_PRELOAD_IMDB': '',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 16,
          'SKIP_ROWS': 0,
          'SSL_BLUR_SIGMA_MAX': [0.0, 2.0],
          'SSL_BLUR_SIGMA_MIN': [0.0, 0.1],
          'SSL_COLOR_BRI_CON_SAT': [0.4, 0.4, 0.4],
          'SSL_COLOR_HUE': 0.1,
          'SSL_COLOR_JITTER': False,
          'SSL_MOCOV2_AUG': False,
          'STD': [0.26862954, 0.26130258, 0.27577711],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TIME_DIFF_PROB': 0.0,
          'TRAIN_CROP_NUM_SPATIAL': 1,
          'TRAIN_CROP_NUM_TEMPORAL': 1,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [],
          'TRAIN_JITTER_FPS': 0.0,
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [224, 256],
          'TRAIN_JITTER_SCALES_RELATIVE': [],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': True},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'IMAGENET_SIMPLELABEL_PATH': None,
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MASK': {'DECODER_DEPTH': 0,
          'DECODER_EMBED_DIM': 512,
          'DECODER_SEP_POS_EMBED': False,
          'DEC_KV_KERNEL': [],
          'DEC_KV_STRIDE': [],
          'ENABLE': False,
          'HEAD_TYPE': 'separate',
          'MAE_ON': False,
          'MAE_RND_MASK': False,
          'NORM_PRED_PIXEL': True,
          'PER_FRAME_MASKING': False,
          'PRED_HOG': False,
          'PRETRAIN_DEPTH': [15],
          'SCALE_INIT_BY_DEPTH': False,
          'TIME_STRIDE_LOSS': True},
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': False,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ADAPT_FINETUNE_FACTOR': 1.0,
           'ARCH': 'vitb16',
           'CLS_LOSS_RATIO': 1.0,
           'CONTEXT_LENGTH': 77,
           'DEFAULT_FINETUNE_FACTOR': 1.0,
           'DETACH_FINAL_FC': False,
           'DISTILLATION_RATIO': 2.0,
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'ENSEMBLE_PRED': False,
           'ENSEMBLE_RAWMODEL_RATIO': 0.0,
           'EXPERT_FINETUNE_FACTOR': 1.0,
           'EXPERT_INSERT_LAYERS': [10, 11],
           'FC_INIT_STD': 0.01,
           'FINETUNE_FACTOR': 1.0,
           'FP16_ALLREDUCE': False,
           'FROZEN_BN': False,
           'HEAD_ACT': 'softmax',
           'KEEP_RAW_MODEL': True,
           'LOSS_FREQ_TYPE': 'mse',
           'LOSS_FUNC': 'soft_cross_entropy',
           'MLP_FINETUNE_FACTOR': 1.0,
           'MODEL_NAME': 'TemporalClipVideo',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 26,
           'NUM_EXPERTS': 0,
           'PROMPT_NUM': 1,
           'RAW_MODEL_DISTILLATION': True,
           'RECORD_ROUTING': False,
           'ROUTING_FINETUNE_FACTOR': 1.0,
           'ROUTING_FREQUENCE_CONSTRAIN': 0.5,
           'ROUTING_FREQ_CONS_FACTOR': 1.0,
           'ROUTING_TYPE': 'patch-level',
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'maskmvit',
                                   'vitb32',
                                   'vitb16',
                                   'vitl14'],
           'STATIC_GRAPH': False,
           'TEMPORAL_MODELING_TYPE': 'expand_temporal_view',
           'TEXT_PROMPT': False,
           'USE_CHECKPOINT': False},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 16,
          'DIM_MUL': [],
          'DIM_MUL_IN_ATT': False,
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.1,
          'EMBED_DIM': 96,
          'HEAD_INIT_SCALE': 1.0,
          'HEAD_MUL': [],
          'LAYER_SCALE_INIT_VALUE': 0.0,
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [2, 4, 4],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': None,
          'POOL_KV_STRIDE': [],
          'POOL_KV_STRIDE_ADAPTIVE': None,
          'POOL_Q_STRIDE': [],
          'QKV_BIAS': True,
          'REL_POS_SPATIAL': False,
          'REL_POS_TEMPORAL': False,
          'REL_POS_ZERO_INIT': False,
          'RESIDUAL_POOLING': False,
          'REV': {'BUFFER_LAYERS': [],
                  'ENABLE': False,
                  'PRE_Q_FUSION': 'avg',
                  'RESPATH_FUSE': 'concat',
                  'RES_PATH': 'conv'},
          'SEPARATE_QKV': False,
          'SEP_POS_EMBED': False,
          'USE_ABS_POS': True,
          'USE_FIXED_SINCOS_POS': False,
          'USE_MEAN_POOLING': False,
          'ZERO_DECAY_POS_CLS': True},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 4,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '/mnt/SSD8T/home/huangwei/projects/FROSTER/checkpoints/basetraining/B2N_hmdb51_froster_premean',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False,
            'ZERO_INIT_FINAL_CONV': False},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 3.33e-06,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'BETAS': (0.9, 0.999),
            'CLIP_GRAD_L2NORM': 1.0,
            'CLIP_GRAD_VAL': None,
            'COSINE_AFTER_WARMUP': True,
            'COSINE_END_LR': 3.33e-08,
            'COSINE_RESTART_EPOCH': 0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LARS_ON': False,
            'LAYER_DECAY': 1.0,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 12,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 2.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 3.33e-08,
            'WEIGHT_DECAY': 0.01,
            'ZERO_WD_1D_PARAM': True},
 'TASK': '',
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 240,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'CLIP_ORI_PATH': None,
          'CUSTOM_LOAD': False,
          'CUSTOM_LOAD_FILE': None,
          'DATASET': 'kinetics',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 3,
          'NUM_SPATIAL_CROPS': 1,
          'NUM_TEMPORAL_CLIPS': [],
          'OPENSET': False,
          'PATCHING_MODEL': False,
          'PATCHING_RATIO': 0.5,
          'SAVE_RESULTS_PATH': '',
          'UPDATE_STATE': False},
 'TEST_FILE': 'test.csv',
 'TRAIN': {'ADAPT_ZS_CONS_RATIO': False,
           'AUTO_RESUME': True,
           'BATCH_SIZE': 32,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_IN_INIT': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'pytorch',
           'CLIP_ORI_PATH': '/mnt/SSD8T/home/huangwei/.cache/clip/ViT-B-16.pt',
           'CUSTOM_LOAD': False,
           'CUSTOM_LOAD_FILE': None,
           'DATASET': 'kinetics',
           'ENABLE': True,
           'EVAL_PERIOD': 1,
           'EWC_CONSTRAIN_RATIO': 1.0,
           'EWC_IDENTITY_FISHER': False,
           'EWC_IGNORE_LOGIT_SCALE': False,
           'EWC_LOAD_FILE': None,
           'EWC_SET': False,
           'KILL_LOSS_EXPLOSION_FACTOR': 0.0,
           'LINEAR_CONNECT_CLIMB': False,
           'LINEAR_CONNECT_LOSS_RATIO': 0.0,
           'LINEAR_CONNECT_SAMPLE': True,
           'LINEAR_CONNECT_SAMPLE_L': 0.4,
           'LINEAR_CONNECT_SAMPLE_R': 0.6,
           'MIXED_PRECISION': True,
           'ZS_CONS': False,
           'ZS_CONS_RATIO': 0.8,
           'ZS_INIT_CONS': False,
           'ZS_RESTART_CONS': False,
           'ZS_RESTART_EPOCH': -1},
 'TRAIN_FILE': 'train_all.csv',
 'TUNE_HEAD': False,
 'VAL_FILE': 'val.csv',
 'VAL_MODE': False,
 'VIS_MASK': CfgNode({'ENABLE': False}),
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/17 16:29:23][INFO] temporalclip_video_model.py:  636: load pretrained CLIP:<All keys matched successfully>
[12/17 16:29:29][INFO] temporalclip_video_model.py:  636: load pretrained CLIP:<All keys matched successfully>
[12/17 16:29:31][INFO] train_net.py:  957: total trainable parameters:
[12/17 16:29:31][INFO] train_net.py:  958: ['module.model.positional_embedding',
 'module.model.text_projection',
 'module.model.logit_scale',
 'module.model.visual.class_embedding',
 'module.model.visual.positional_embedding',
 'module.model.visual.proj',
 'module.model.visual.conv1.weight',
 'module.model.visual.ln_pre.weight',
 'module.model.visual.ln_pre.bias',
 'module.model.visual.transformer.resblocks.0.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.0.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.0.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.0.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.0.ln_1.weight',
 'module.model.visual.transformer.resblocks.0.ln_1.bias',
 'module.model.visual.transformer.resblocks.0.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.0.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.0.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.0.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.0.ln_2.weight',
 'module.model.visual.transformer.resblocks.0.ln_2.bias',
 'module.model.visual.transformer.resblocks.1.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.1.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.1.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.1.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.1.ln_1.weight',
 'module.model.visual.transformer.resblocks.1.ln_1.bias',
 'module.model.visual.transformer.resblocks.1.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.1.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.1.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.1.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.1.ln_2.weight',
 'module.model.visual.transformer.resblocks.1.ln_2.bias',
 'module.model.visual.transformer.resblocks.2.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.2.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.2.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.2.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.2.ln_1.weight',
 'module.model.visual.transformer.resblocks.2.ln_1.bias',
 'module.model.visual.transformer.resblocks.2.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.2.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.2.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.2.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.2.ln_2.weight',
 'module.model.visual.transformer.resblocks.2.ln_2.bias',
 'module.model.visual.transformer.resblocks.3.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.3.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.3.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.3.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.3.ln_1.weight',
 'module.model.visual.transformer.resblocks.3.ln_1.bias',
 'module.model.visual.transformer.resblocks.3.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.3.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.3.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.3.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.3.ln_2.weight',
 'module.model.visual.transformer.resblocks.3.ln_2.bias',
 'module.model.visual.transformer.resblocks.4.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.4.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.4.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.4.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.4.ln_1.weight',
 'module.model.visual.transformer.resblocks.4.ln_1.bias',
 'module.model.visual.transformer.resblocks.4.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.4.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.4.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.4.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.4.ln_2.weight',
 'module.model.visual.transformer.resblocks.4.ln_2.bias',
 'module.model.visual.transformer.resblocks.5.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.5.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.5.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.5.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.5.ln_1.weight',
 'module.model.visual.transformer.resblocks.5.ln_1.bias',
 'module.model.visual.transformer.resblocks.5.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.5.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.5.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.5.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.5.ln_2.weight',
 'module.model.visual.transformer.resblocks.5.ln_2.bias',
 'module.model.visual.transformer.resblocks.6.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.6.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.6.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.6.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.6.ln_1.weight',
 'module.model.visual.transformer.resblocks.6.ln_1.bias',
 'module.model.visual.transformer.resblocks.6.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.6.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.6.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.6.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.6.ln_2.weight',
 'module.model.visual.transformer.resblocks.6.ln_2.bias',
 'module.model.visual.transformer.resblocks.7.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.7.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.7.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.7.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.7.ln_1.weight',
 'module.model.visual.transformer.resblocks.7.ln_1.bias',
 'module.model.visual.transformer.resblocks.7.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.7.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.7.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.7.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.7.ln_2.weight',
 'module.model.visual.transformer.resblocks.7.ln_2.bias',
 'module.model.visual.transformer.resblocks.8.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.8.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.8.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.8.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.8.ln_1.weight',
 'module.model.visual.transformer.resblocks.8.ln_1.bias',
 'module.model.visual.transformer.resblocks.8.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.8.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.8.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.8.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.8.ln_2.weight',
 'module.model.visual.transformer.resblocks.8.ln_2.bias',
 'module.model.visual.transformer.resblocks.9.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.9.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.9.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.9.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.9.ln_1.weight',
 'module.model.visual.transformer.resblocks.9.ln_1.bias',
 'module.model.visual.transformer.resblocks.9.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.9.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.9.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.9.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.9.ln_2.weight',
 'module.model.visual.transformer.resblocks.9.ln_2.bias',
 'module.model.visual.transformer.resblocks.10.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.10.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.10.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.10.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.10.ln_1.weight',
 'module.model.visual.transformer.resblocks.10.ln_1.bias',
 'module.model.visual.transformer.resblocks.10.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.10.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.10.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.10.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.10.ln_2.weight',
 'module.model.visual.transformer.resblocks.10.ln_2.bias',
 'module.model.visual.transformer.resblocks.11.attn.in_proj_weight',
 'module.model.visual.transformer.resblocks.11.attn.in_proj_bias',
 'module.model.visual.transformer.resblocks.11.attn.out_proj.weight',
 'module.model.visual.transformer.resblocks.11.attn.out_proj.bias',
 'module.model.visual.transformer.resblocks.11.ln_1.weight',
 'module.model.visual.transformer.resblocks.11.ln_1.bias',
 'module.model.visual.transformer.resblocks.11.mlp.c_fc.weight',
 'module.model.visual.transformer.resblocks.11.mlp.c_fc.bias',
 'module.model.visual.transformer.resblocks.11.mlp.c_proj.weight',
 'module.model.visual.transformer.resblocks.11.mlp.c_proj.bias',
 'module.model.visual.transformer.resblocks.11.ln_2.weight',
 'module.model.visual.transformer.resblocks.11.ln_2.bias',
 'module.model.visual.ln_post.weight',
 'module.model.visual.ln_post.bias',
 'module.model.transformer.resblocks.0.attn.in_proj_weight',
 'module.model.transformer.resblocks.0.attn.in_proj_bias',
 'module.model.transformer.resblocks.0.attn.out_proj.weight',
 'module.model.transformer.resblocks.0.attn.out_proj.bias',
 'module.model.transformer.resblocks.0.ln_1.weight',
 'module.model.transformer.resblocks.0.ln_1.bias',
 'module.model.transformer.resblocks.0.mlp.c_fc.weight',
 'module.model.transformer.resblocks.0.mlp.c_fc.bias',
 'module.model.transformer.resblocks.0.mlp.c_proj.weight',
 'module.model.transformer.resblocks.0.mlp.c_proj.bias',
 'module.model.transformer.resblocks.0.ln_2.weight',
 'module.model.transformer.resblocks.0.ln_2.bias',
 'module.model.transformer.resblocks.1.attn.in_proj_weight',
 'module.model.transformer.resblocks.1.attn.in_proj_bias',
 'module.model.transformer.resblocks.1.attn.out_proj.weight',
 'module.model.transformer.resblocks.1.attn.out_proj.bias',
 'module.model.transformer.resblocks.1.ln_1.weight',
 'module.model.transformer.resblocks.1.ln_1.bias',
 'module.model.transformer.resblocks.1.mlp.c_fc.weight',
 'module.model.transformer.resblocks.1.mlp.c_fc.bias',
 'module.model.transformer.resblocks.1.mlp.c_proj.weight',
 'module.model.transformer.resblocks.1.mlp.c_proj.bias',
 'module.model.transformer.resblocks.1.ln_2.weight',
 'module.model.transformer.resblocks.1.ln_2.bias',
 'module.model.transformer.resblocks.2.attn.in_proj_weight',
 'module.model.transformer.resblocks.2.attn.in_proj_bias',
 'module.model.transformer.resblocks.2.attn.out_proj.weight',
 'module.model.transformer.resblocks.2.attn.out_proj.bias',
 'module.model.transformer.resblocks.2.ln_1.weight',
 'module.model.transformer.resblocks.2.ln_1.bias',
 'module.model.transformer.resblocks.2.mlp.c_fc.weight',
 'module.model.transformer.resblocks.2.mlp.c_fc.bias',
 'module.model.transformer.resblocks.2.mlp.c_proj.weight',
 'module.model.transformer.resblocks.2.mlp.c_proj.bias',
 'module.model.transformer.resblocks.2.ln_2.weight',
 'module.model.transformer.resblocks.2.ln_2.bias',
 'module.model.transformer.resblocks.3.attn.in_proj_weight',
 'module.model.transformer.resblocks.3.attn.in_proj_bias',
 'module.model.transformer.resblocks.3.attn.out_proj.weight',
 'module.model.transformer.resblocks.3.attn.out_proj.bias',
 'module.model.transformer.resblocks.3.ln_1.weight',
 'module.model.transformer.resblocks.3.ln_1.bias',
 'module.model.transformer.resblocks.3.mlp.c_fc.weight',
 'module.model.transformer.resblocks.3.mlp.c_fc.bias',
 'module.model.transformer.resblocks.3.mlp.c_proj.weight',
 'module.model.transformer.resblocks.3.mlp.c_proj.bias',
 'module.model.transformer.resblocks.3.ln_2.weight',
 'module.model.transformer.resblocks.3.ln_2.bias',
 'module.model.transformer.resblocks.4.attn.in_proj_weight',
 'module.model.transformer.resblocks.4.attn.in_proj_bias',
 'module.model.transformer.resblocks.4.attn.out_proj.weight',
 'module.model.transformer.resblocks.4.attn.out_proj.bias',
 'module.model.transformer.resblocks.4.ln_1.weight',
 'module.model.transformer.resblocks.4.ln_1.bias',
 'module.model.transformer.resblocks.4.mlp.c_fc.weight',
 'module.model.transformer.resblocks.4.mlp.c_fc.bias',
 'module.model.transformer.resblocks.4.mlp.c_proj.weight',
 'module.model.transformer.resblocks.4.mlp.c_proj.bias',
 'module.model.transformer.resblocks.4.ln_2.weight',
 'module.model.transformer.resblocks.4.ln_2.bias',
 'module.model.transformer.resblocks.5.attn.in_proj_weight',
 'module.model.transformer.resblocks.5.attn.in_proj_bias',
 'module.model.transformer.resblocks.5.attn.out_proj.weight',
 'module.model.transformer.resblocks.5.attn.out_proj.bias',
 'module.model.transformer.resblocks.5.ln_1.weight',
 'module.model.transformer.resblocks.5.ln_1.bias',
 'module.model.transformer.resblocks.5.mlp.c_fc.weight',
 'module.model.transformer.resblocks.5.mlp.c_fc.bias',
 'module.model.transformer.resblocks.5.mlp.c_proj.weight',
 'module.model.transformer.resblocks.5.mlp.c_proj.bias',
 'module.model.transformer.resblocks.5.ln_2.weight',
 'module.model.transformer.resblocks.5.ln_2.bias',
 'module.model.transformer.resblocks.6.attn.in_proj_weight',
 'module.model.transformer.resblocks.6.attn.in_proj_bias',
 'module.model.transformer.resblocks.6.attn.out_proj.weight',
 'module.model.transformer.resblocks.6.attn.out_proj.bias',
 'module.model.transformer.resblocks.6.ln_1.weight',
 'module.model.transformer.resblocks.6.ln_1.bias',
 'module.model.transformer.resblocks.6.mlp.c_fc.weight',
 'module.model.transformer.resblocks.6.mlp.c_fc.bias',
 'module.model.transformer.resblocks.6.mlp.c_proj.weight',
 'module.model.transformer.resblocks.6.mlp.c_proj.bias',
 'module.model.transformer.resblocks.6.ln_2.weight',
 'module.model.transformer.resblocks.6.ln_2.bias',
 'module.model.transformer.resblocks.7.attn.in_proj_weight',
 'module.model.transformer.resblocks.7.attn.in_proj_bias',
 'module.model.transformer.resblocks.7.attn.out_proj.weight',
 'module.model.transformer.resblocks.7.attn.out_proj.bias',
 'module.model.transformer.resblocks.7.ln_1.weight',
 'module.model.transformer.resblocks.7.ln_1.bias',
 'module.model.transformer.resblocks.7.mlp.c_fc.weight',
 'module.model.transformer.resblocks.7.mlp.c_fc.bias',
 'module.model.transformer.resblocks.7.mlp.c_proj.weight',
 'module.model.transformer.resblocks.7.mlp.c_proj.bias',
 'module.model.transformer.resblocks.7.ln_2.weight',
 'module.model.transformer.resblocks.7.ln_2.bias',
 'module.model.transformer.resblocks.8.attn.in_proj_weight',
 'module.model.transformer.resblocks.8.attn.in_proj_bias',
 'module.model.transformer.resblocks.8.attn.out_proj.weight',
 'module.model.transformer.resblocks.8.attn.out_proj.bias',
 'module.model.transformer.resblocks.8.ln_1.weight',
 'module.model.transformer.resblocks.8.ln_1.bias',
 'module.model.transformer.resblocks.8.mlp.c_fc.weight',
 'module.model.transformer.resblocks.8.mlp.c_fc.bias',
 'module.model.transformer.resblocks.8.mlp.c_proj.weight',
 'module.model.transformer.resblocks.8.mlp.c_proj.bias',
 'module.model.transformer.resblocks.8.ln_2.weight',
 'module.model.transformer.resblocks.8.ln_2.bias',
 'module.model.transformer.resblocks.9.attn.in_proj_weight',
 'module.model.transformer.resblocks.9.attn.in_proj_bias',
 'module.model.transformer.resblocks.9.attn.out_proj.weight',
 'module.model.transformer.resblocks.9.attn.out_proj.bias',
 'module.model.transformer.resblocks.9.ln_1.weight',
 'module.model.transformer.resblocks.9.ln_1.bias',
 'module.model.transformer.resblocks.9.mlp.c_fc.weight',
 'module.model.transformer.resblocks.9.mlp.c_fc.bias',
 'module.model.transformer.resblocks.9.mlp.c_proj.weight',
 'module.model.transformer.resblocks.9.mlp.c_proj.bias',
 'module.model.transformer.resblocks.9.ln_2.weight',
 'module.model.transformer.resblocks.9.ln_2.bias',
 'module.model.transformer.resblocks.10.attn.in_proj_weight',
 'module.model.transformer.resblocks.10.attn.in_proj_bias',
 'module.model.transformer.resblocks.10.attn.out_proj.weight',
 'module.model.transformer.resblocks.10.attn.out_proj.bias',
 'module.model.transformer.resblocks.10.ln_1.weight',
 'module.model.transformer.resblocks.10.ln_1.bias',
 'module.model.transformer.resblocks.10.mlp.c_fc.weight',
 'module.model.transformer.resblocks.10.mlp.c_fc.bias',
 'module.model.transformer.resblocks.10.mlp.c_proj.weight',
 'module.model.transformer.resblocks.10.mlp.c_proj.bias',
 'module.model.transformer.resblocks.10.ln_2.weight',
 'module.model.transformer.resblocks.10.ln_2.bias',
 'module.model.transformer.resblocks.11.attn.in_proj_weight',
 'module.model.transformer.resblocks.11.attn.in_proj_bias',
 'module.model.transformer.resblocks.11.attn.out_proj.weight',
 'module.model.transformer.resblocks.11.attn.out_proj.bias',
 'module.model.transformer.resblocks.11.ln_1.weight',
 'module.model.transformer.resblocks.11.ln_1.bias',
 'module.model.transformer.resblocks.11.mlp.c_fc.weight',
 'module.model.transformer.resblocks.11.mlp.c_fc.bias',
 'module.model.transformer.resblocks.11.mlp.c_proj.weight',
 'module.model.transformer.resblocks.11.mlp.c_proj.bias',
 'module.model.transformer.resblocks.11.ln_2.weight',
 'module.model.transformer.resblocks.11.ln_2.bias',
 'module.model.token_embedding.weight',
 'module.model.ln_final.weight',
 'module.model.ln_final.bias',
 'module.projector_v.0.weight',
 'module.projector_v.2.weight',
 'module.projector_t.0.weight',
 'module.projector_t.2.weight']
[12/17 16:29:31][INFO] misc.py:  185: Model:
DistributedDataParallel(
  (module): TemporalClipVideo(
    (model): WCLIP(
      (visual): TemporalVisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): TSTransformer(
          (resblocks): Sequential(
            (0): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (raw_model): WCLIP(
      (visual): TemporalVisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): TSTransformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (projector_v): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): GELU()
      (2): Linear(in_features=512, out_features=512, bias=False)
    )
    (projector_t): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): GELU()
      (2): Linear(in_features=512, out_features=512, bias=False)
    )
  )
)
[12/17 16:29:31][INFO] misc.py:  187: Params: 300,290,050
[12/17 16:29:31][INFO] misc.py:  188: Mem: 1.6999154090881348 MB
[12/17 16:29:31][INFO] misc.py:  197: nvidia-smi
Tue Dec 17 16:29:31 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  Off |
| 42%   32C    P2   101W / 450W |  13414MiB / 24564MiB |     64%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:23:00.0 Off |                  Off |
| 41%   33C    P2    97W / 450W |  13414MiB / 24564MiB |     62%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:41:00.0 Off |                  Off |
| 41%   35C    P2   102W / 450W |  13414MiB / 24564MiB |     47%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:61:00.0 Off |                  Off |
| 40%   34C    P2   102W / 450W |  13414MiB / 24564MiB |     59%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   4  NVIDIA GeForce ...  Off  | 00000000:81:00.0 Off |                  Off |
| 42%   25C    P2    63W / 450W |   5062MiB / 24564MiB |     50%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   5  NVIDIA GeForce ...  Off  | 00000000:A1:00.0 Off |                  Off |
| 41%   24C    P2    63W / 450W |   5062MiB / 24564MiB |     15%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   6  NVIDIA GeForce ...  Off  | 00000000:C1:00.0 Off |                  Off |
| 42%   25C    P2    52W / 450W |   5062MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   7  NVIDIA GeForce ...  Off  | 00000000:E1:00.0 Off |                  Off |
| 39%   24C    P2    60W / 450W |   5062MiB / 24564MiB |     44%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    0   N/A  N/A   1835998      C   ...3/envs/realnet/bin/python    13406MiB |
|    1   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    1   N/A  N/A   1835999      C   ...3/envs/realnet/bin/python    13406MiB |
|    2   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    2   N/A  N/A   1836000      C   ...3/envs/realnet/bin/python    13406MiB |
|    3   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    3   N/A  N/A   1836001      C   ...3/envs/realnet/bin/python    13406MiB |
|    4   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    4   N/A  N/A   2393256      C   .../envs/slowfast/bin/python     5054MiB |
|    5   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    5   N/A  N/A   2393257      C   .../envs/slowfast/bin/python     5054MiB |
|    6   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    6   N/A  N/A   2393258      C   .../envs/slowfast/bin/python     5054MiB |
|    7   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    7   N/A  N/A   2393259      C   .../envs/slowfast/bin/python     5054MiB |
+-----------------------------------------------------------------------------+
bn 0, non bn 107, zero 199, no grad 302
[12/17 16:29:32][INFO] kinetics.py:   94: Constructing Kinetics train...
path: ---------------------------- /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/train_all.csv
[12/17 16:29:32][INFO] kinetics.py:  172: Constructing kinetics dataloader (size: 1820 skip_rows 0) from /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/train_all.csv 
[12/17 16:29:32][INFO] kinetics.py:   94: Constructing Kinetics val...
path: ---------------------------- /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/val.csv
[12/17 16:29:32][INFO] kinetics.py:  172: Constructing kinetics dataloader (size: 774 skip_rows 0) from /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/val.csv 
[12/17 16:29:32][INFO] kinetics.py:   94: Constructing Kinetics train...
path: ---------------------------- /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/train_all.csv
[12/17 16:29:32][INFO] kinetics.py:  172: Constructing kinetics dataloader (size: 1820 skip_rows 0) from /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/train_all.csv 
[12/17 16:29:32][INFO] train_net.py: 1140: Start epoch: 1
[12/17 16:29:32][INFO] train_net.py:  304: total trainable params:
[12/17 16:29:32][INFO] train_net.py:  307: module.model.positional_embedding
[12/17 16:29:32][INFO] train_net.py:  307: module.model.text_projection
[12/17 16:29:32][INFO] train_net.py:  307: module.model.logit_scale
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.proj
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.ln_final.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.model.ln_final.bias
[12/17 16:29:32][INFO] train_net.py:  307: module.projector_v.0.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.projector_v.2.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.projector_t.0.weight
[12/17 16:29:32][INFO] train_net.py:  307: module.projector_t.2.weight
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1289] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:29:52][INFO] train_net.py:  491: Distillation Loss: 0.01602203
[12/17 16:29:52][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:29:57][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.46340967, "dt_data": 0.00033493, "dt_net": 0.46307423, "epoch": "1/12", "eta": "0:05:06", "gpu_mem": "16.92G", "grad_norm": 83.16586304, "iter": "10/56", "loss": 1.56842321, "lr": 3.0E-7, "top1_err": 45.31250000, "top5_err": 17.18750000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:29:57][INFO] train_net.py:  491: Distillation Loss: 0.01762551
[12/17 16:29:57][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:30:01][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.46894697, "dt_data": 0.00031295, "dt_net": 0.46863303, "epoch": "1/12", "eta": "0:05:05", "gpu_mem": "16.92G", "grad_norm": 74.78828430, "iter": "20/56", "loss": 1.29777128, "lr": 5.9E-7, "top1_err": 34.37500000, "top5_err": 14.06250000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:30:01][INFO] train_net.py:  491: Distillation Loss: 0.01325083
[12/17 16:30:01][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:30:06][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.46528774, "dt_data": 0.00043883, "dt_net": 0.46484640, "epoch": "1/12", "eta": "0:04:58", "gpu_mem": "16.92G", "grad_norm": 73.50196075, "iter": "30/56", "loss": 1.14484769, "lr": 8.9E-7, "top1_err": 31.25000000, "top5_err": 12.50000000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:30:06][INFO] train_net.py:  491: Distillation Loss: 0.01853371
[12/17 16:30:06][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:30:11][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45330819, "dt_data": 0.00041679, "dt_net": 0.45288975, "epoch": "1/12", "eta": "0:04:46", "gpu_mem": "16.92G", "grad_norm": 63.82003021, "iter": "40/56", "loss": 0.91567218, "lr": 0.00000118, "top1_err": 28.12500000, "top5_err": 6.25000000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:30:11][INFO] train_net.py:  491: Distillation Loss: 0.02451235
[12/17 16:30:11][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:30:15][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45006023, "dt_data": 0.00027701, "dt_net": 0.44978205, "epoch": "1/12", "eta": "0:04:39", "gpu_mem": "16.92G", "grad_norm": 58.24119949, "iter": "50/56", "loss": 0.93877825, "lr": 0.00000148, "top1_err": 29.68750000, "top5_err": 4.68750000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:30:15][INFO] train_net.py:  491: Distillation Loss: 0.02594632
[12/17 16:30:15][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:30:19][INFO] logging.py:   99: json_stats: {"RAM": "55.99/251.74G", "_type": "train_epoch", "dt": 1.24759965, "dt_data": 1.24759951, "dt_net": 0.45186001, "epoch": "1/12", "eta": "0:12:48", "gpu_mem": "16.92G", "grad_norm": 76.12269592, "loss": 1.15107520, "lr": 0.00000165, "top1_err": 33.48214286, "top5_err": 11.10491071}
[12/17 16:30:19][INFO] train_net.py: 1344: Epoch 0 takes 47.34s. Epochs from 0 to 0 take 47.34s in average and 47.34s in median.
[12/17 16:30:19][INFO] train_net.py: 1350: For epoch 0, each iteraction takes 0.85s in average. From epoch 0 to 0, each iteraction takes 0.85s in average.
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:30:45][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:00:04", "gpu_mem": "16.92G", "iter": "10/25", "time_diff": 0.29359904, "top1_err": 26.56250000, "top5_err": 6.25000000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:30:48][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "1/12", "eta": "0:00:01", "gpu_mem": "16.92G", "iter": "20/25", "time_diff": 0.28506831, "top1_err": 28.12500000, "top5_err": 3.12500000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([16, 512]),bz: 2,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([2, 512])
[12/17 16:30:51][INFO] logging.py:   99: json_stats: {"RAM": "55.07/251.74G", "_type": "val_epoch", "epoch": "1/12", "gpu_mem": "16.92G", "min_top1_err": 29.38144330, "min_top5_err": 5.92783505, "time_diff": 1.08441145, "top1_err": 29.38144330, "top5_err": 5.92783505}
[12/17 16:30:51][INFO] train_net.py:  304: total trainable params:
[12/17 16:30:51][INFO] train_net.py:  307: module.model.positional_embedding
[12/17 16:30:51][INFO] train_net.py:  307: module.model.text_projection
[12/17 16:30:51][INFO] train_net.py:  307: module.model.logit_scale
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.proj
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.ln_final.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.model.ln_final.bias
[12/17 16:30:51][INFO] train_net.py:  307: module.projector_v.0.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.projector_v.2.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.projector_t.0.weight
[12/17 16:30:51][INFO] train_net.py:  307: module.projector_t.2.weight
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:31:11][INFO] train_net.py:  491: Distillation Loss: 0.02564979
[12/17 16:31:11][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:31:16][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45987822, "dt_data": 0.00023199, "dt_net": 0.45964546, "epoch": "2/12", "eta": "0:04:38", "gpu_mem": "16.93G", "grad_norm": 55.23837280, "iter": "10/56", "loss": 0.62893915, "lr": 0.00000195, "top1_err": 21.87500000, "top5_err": 1.56250000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:31:16][INFO] train_net.py:  491: Distillation Loss: 0.02926171
[12/17 16:31:16][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:31:20][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45214958, "dt_data": 0.00032318, "dt_net": 0.45182554, "epoch": "2/12", "eta": "0:04:29", "gpu_mem": "16.93G", "grad_norm": 46.27845383, "iter": "20/56", "loss": 0.82122093, "lr": 0.00000224, "top1_err": 26.56250000, "top5_err": 3.12500000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:31:21][INFO] train_net.py:  491: Distillation Loss: 0.02857852
[12/17 16:31:21][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:31:25][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.44909099, "dt_data": 0.00029971, "dt_net": 0.44879027, "epoch": "2/12", "eta": "0:04:23", "gpu_mem": "16.93G", "grad_norm": 29.96985054, "iter": "30/56", "loss": 0.75780720, "lr": 0.00000254, "top1_err": 23.43750000, "top5_err": 4.68750000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:31:25][INFO] train_net.py:  491: Distillation Loss: 0.02951241
[12/17 16:31:25][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:31:30][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.46513536, "dt_data": 0.00029488, "dt_net": 0.46483920, "epoch": "2/12", "eta": "0:04:27", "gpu_mem": "16.93G", "grad_norm": 58.74223709, "iter": "40/56", "loss": 0.53429317, "lr": 0.00000283, "top1_err": 14.06250000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:31:30][INFO] train_net.py:  491: Distillation Loss: 0.03769821
[12/17 16:31:30][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:31:34][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.44436021, "dt_data": 0.00019220, "dt_net": 0.44416732, "epoch": "2/12", "eta": "0:04:11", "gpu_mem": "16.93G", "grad_norm": 60.37300873, "iter": "50/56", "loss": 0.62695602, "lr": 0.00000312, "top1_err": 17.18750000, "top5_err": 3.12500000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:31:34][INFO] train_net.py:  491: Distillation Loss: 0.03327310
[12/17 16:31:34][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:31:38][INFO] logging.py:   99: json_stats: {"RAM": "54.18/251.74G", "_type": "train_epoch", "dt": 1.35839749, "dt_data": 1.35839775, "dt_net": 0.44556860, "epoch": "2/12", "eta": "0:12:40", "gpu_mem": "16.93G", "grad_norm": 59.39796448, "loss": 0.69525218, "lr": 0.00000330, "top1_err": 20.31250000, "top5_err": 3.68303571}
[12/17 16:31:38][INFO] train_net.py: 1344: Epoch 1 takes 47.44s. Epochs from 0 to 1 take 47.39s in average and 47.39s in median.
[12/17 16:31:38][INFO] train_net.py: 1350: For epoch 1, each iteraction takes 0.85s in average. From epoch 0 to 1, each iteraction takes 0.85s in average.
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:32:04][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:00:04", "gpu_mem": "16.93G", "iter": "10/25", "time_diff": 0.29017828, "top1_err": 23.43750000, "top5_err": 3.12500000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:32:07][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "2/12", "eta": "0:00:01", "gpu_mem": "16.93G", "iter": "20/25", "time_diff": 0.29762669, "top1_err": 25.00000000, "top5_err": 3.12500000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([16, 512]),bz: 2,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([2, 512])
[12/17 16:32:10][INFO] logging.py:   99: json_stats: {"RAM": "54.02/251.74G", "_type": "val_epoch", "epoch": "2/12", "gpu_mem": "16.93G", "min_top1_err": 25.90206186, "min_top5_err": 3.47938144, "time_diff": 1.21717713, "top1_err": 25.90206186, "top5_err": 3.47938144}
[12/17 16:32:10][INFO] train_net.py:  304: total trainable params:
[12/17 16:32:10][INFO] train_net.py:  307: module.model.positional_embedding
[12/17 16:32:10][INFO] train_net.py:  307: module.model.text_projection
[12/17 16:32:10][INFO] train_net.py:  307: module.model.logit_scale
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.proj
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.ln_final.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.model.ln_final.bias
[12/17 16:32:10][INFO] train_net.py:  307: module.projector_v.0.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.projector_v.2.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.projector_t.0.weight
[12/17 16:32:10][INFO] train_net.py:  307: module.projector_t.2.weight
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:32:30][INFO] train_net.py:  491: Distillation Loss: 0.03297055
[12/17 16:32:30][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:32:35][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45264318, "dt_data": 0.00032736, "dt_net": 0.45231454, "epoch": "3/12", "eta": "0:04:08", "gpu_mem": "16.93G", "grad_norm": 51.53865051, "iter": "10/56", "loss": 0.54753935, "lr": 0.00000333, "top1_err": 15.62500000, "top5_err": 3.12500000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:32:35][INFO] train_net.py:  491: Distillation Loss: 0.04127455
[12/17 16:32:35][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:32:39][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45941429, "dt_data": 0.00044597, "dt_net": 0.45896734, "epoch": "3/12", "eta": "0:04:08", "gpu_mem": "16.93G", "grad_norm": 33.75663757, "iter": "20/56", "loss": 0.41886881, "lr": 0.00000332, "top1_err": 12.50000000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:32:40][INFO] train_net.py:  491: Distillation Loss: 0.03694284
[12/17 16:32:40][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:32:44][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45691700, "dt_data": 0.00027871, "dt_net": 0.45663719, "epoch": "3/12", "eta": "0:04:02", "gpu_mem": "16.93G", "grad_norm": 53.74894333, "iter": "30/56", "loss": 0.45006761, "lr": 0.00000331, "top1_err": 9.37500000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:32:44][INFO] train_net.py:  491: Distillation Loss: 0.04170173
[12/17 16:32:44][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:32:49][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.47485172, "dt_data": 0.00031501, "dt_net": 0.47453561, "epoch": "3/12", "eta": "0:04:06", "gpu_mem": "16.93G", "grad_norm": 41.55836868, "iter": "40/56", "loss": 0.39608572, "lr": 0.00000329, "top1_err": 9.37500000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:32:49][INFO] train_net.py:  491: Distillation Loss: 0.03641635
[12/17 16:32:49][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:32:53][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45314473, "dt_data": 0.00016817, "dt_net": 0.45297561, "epoch": "3/12", "eta": "0:03:51", "gpu_mem": "16.93G", "grad_norm": 49.85883331, "iter": "50/56", "loss": 0.50212313, "lr": 0.00000327, "top1_err": 15.62500000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:32:53][INFO] train_net.py:  491: Distillation Loss: 0.04280782
[12/17 16:32:53][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:32:57][INFO] logging.py:   99: json_stats: {"RAM": "60.52/251.74G", "_type": "train_epoch", "dt": 1.09550996, "dt_data": 1.09550931, "dt_net": 0.45049948, "epoch": "3/12", "eta": "0:09:12", "gpu_mem": "16.93G", "grad_norm": 61.68369293, "loss": 0.47830963, "lr": 0.00000325, "top1_err": 12.66741071, "top5_err": 1.39508929}
[12/17 16:32:57][INFO] train_net.py: 1344: Epoch 2 takes 47.19s. Epochs from 0 to 2 take 47.33s in average and 47.34s in median.
[12/17 16:32:57][INFO] train_net.py: 1350: For epoch 2, each iteraction takes 0.84s in average. From epoch 0 to 2, each iteraction takes 0.85s in average.
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:33:24][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:00:04", "gpu_mem": "16.93G", "iter": "10/25", "time_diff": 0.29235322, "top1_err": 21.87500000, "top5_err": 6.25000000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:33:27][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "3/12", "eta": "0:00:01", "gpu_mem": "16.93G", "iter": "20/25", "time_diff": 0.28675414, "top1_err": 21.87500000, "top5_err": 4.68750000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([16, 512]),bz: 2,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([2, 512])
[12/17 16:33:30][INFO] logging.py:   99: json_stats: {"RAM": "54.83/251.74G", "_type": "val_epoch", "epoch": "3/12", "gpu_mem": "16.93G", "min_top1_err": 25.64432990, "min_top5_err": 3.47938144, "time_diff": 1.02724346, "top1_err": 25.64432990, "top5_err": 4.76804124}
[12/17 16:33:30][INFO] train_net.py:  304: total trainable params:
[12/17 16:33:30][INFO] train_net.py:  307: module.model.positional_embedding
[12/17 16:33:30][INFO] train_net.py:  307: module.model.text_projection
[12/17 16:33:30][INFO] train_net.py:  307: module.model.logit_scale
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.proj
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.ln_final.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.model.ln_final.bias
[12/17 16:33:30][INFO] train_net.py:  307: module.projector_v.0.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.projector_v.2.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.projector_t.0.weight
[12/17 16:33:30][INFO] train_net.py:  307: module.projector_t.2.weight
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:33:49][INFO] train_net.py:  491: Distillation Loss: 0.03850496
[12/17 16:33:49][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:33:55][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.47363600, "dt_data": 0.00040418, "dt_net": 0.47323080, "epoch": "4/12", "eta": "0:03:53", "gpu_mem": "16.93G", "grad_norm": 61.98071671, "iter": "10/56", "loss": 0.40165780, "lr": 0.00000322, "top1_err": 9.37500000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:33:55][INFO] train_net.py:  491: Distillation Loss: 0.03977048
[12/17 16:33:55][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:34:00][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45216543, "dt_data": 0.00036288, "dt_net": 0.45180162, "epoch": "4/12", "eta": "0:03:38", "gpu_mem": "16.93G", "grad_norm": 33.23947906, "iter": "20/56", "loss": 0.38922928, "lr": 0.00000319, "top1_err": 10.93750000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:34:00][INFO] train_net.py:  491: Distillation Loss: 0.05259490
[12/17 16:34:00][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:34:04][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.47989884, "dt_data": 0.00033688, "dt_net": 0.47956101, "epoch": "4/12", "eta": "0:03:47", "gpu_mem": "16.93G", "grad_norm": 23.34895515, "iter": "30/56", "loss": 0.40454054, "lr": 0.00000315, "top1_err": 10.93750000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:34:05][INFO] train_net.py:  491: Distillation Loss: 0.03968483
[12/17 16:34:05][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:34:09][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.46479503, "dt_data": 0.00030237, "dt_net": 0.46449160, "epoch": "4/12", "eta": "0:03:35", "gpu_mem": "16.93G", "grad_norm": 36.33790207, "iter": "40/56", "loss": 0.33558452, "lr": 0.00000310, "top1_err": 6.25000000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:34:09][INFO] train_net.py:  491: Distillation Loss: 0.04417771
[12/17 16:34:09][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:34:13][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45231310, "dt_data": 0.00015605, "dt_net": 0.45215637, "epoch": "4/12", "eta": "0:03:25", "gpu_mem": "16.93G", "grad_norm": 33.41933441, "iter": "50/56", "loss": 0.30309561, "lr": 0.00000305, "top1_err": 6.25000000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:34:14][INFO] train_net.py:  491: Distillation Loss: 0.04841506
[12/17 16:34:14][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:34:18][INFO] logging.py:   99: json_stats: {"RAM": "53.98/251.74G", "_type": "train_epoch", "dt": 1.57489991, "dt_data": 1.57489998, "dt_net": 0.44975330, "epoch": "4/12", "eta": "0:11:45", "gpu_mem": "16.93G", "grad_norm": 18.65660667, "loss": 0.37265580, "lr": 0.00000302, "top1_err": 9.20758929, "top5_err": 0.55803571}
[12/17 16:34:18][INFO] train_net.py: 1344: Epoch 3 takes 48.27s. Epochs from 0 to 3 take 47.56s in average and 47.39s in median.
[12/17 16:34:18][INFO] train_net.py: 1350: For epoch 3, each iteraction takes 0.86s in average. From epoch 0 to 3, each iteraction takes 0.85s in average.
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:34:44][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:00:04", "gpu_mem": "16.93G", "iter": "10/25", "time_diff": 0.28713663, "top1_err": 20.31250000, "top5_err": 3.12500000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:34:46][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "4/12", "eta": "0:00:01", "gpu_mem": "16.93G", "iter": "20/25", "time_diff": 0.28417846, "top1_err": 21.87500000, "top5_err": 3.12500000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([16, 512]),bz: 2,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([2, 512])
[12/17 16:34:49][INFO] logging.py:   99: json_stats: {"RAM": "54.76/251.74G", "_type": "val_epoch", "epoch": "4/12", "gpu_mem": "16.93G", "min_top1_err": 23.32474227, "min_top5_err": 3.35051546, "time_diff": 1.31101754, "top1_err": 23.32474227, "top5_err": 3.35051546}
[12/17 16:34:49][INFO] train_net.py:  304: total trainable params:
[12/17 16:34:49][INFO] train_net.py:  307: module.model.positional_embedding
[12/17 16:34:49][INFO] train_net.py:  307: module.model.text_projection
[12/17 16:34:49][INFO] train_net.py:  307: module.model.logit_scale
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.proj
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.ln_final.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.model.ln_final.bias
[12/17 16:34:49][INFO] train_net.py:  307: module.projector_v.0.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.projector_v.2.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.projector_t.0.weight
[12/17 16:34:49][INFO] train_net.py:  307: module.projector_t.2.weight
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:35:09][INFO] train_net.py:  491: Distillation Loss: 0.04523885
[12/17 16:35:09][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:35:15][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.48185852, "dt_data": 0.00037682, "dt_net": 0.48148029, "epoch": "5/12", "eta": "0:03:31", "gpu_mem": "16.93G", "grad_norm": 53.66924667, "iter": "10/56", "loss": 0.28776062, "lr": 0.00000296, "top1_err": 6.25000000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:35:15][INFO] train_net.py:  491: Distillation Loss: 0.04282880
[12/17 16:35:15][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:35:19][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.46424839, "dt_data": 0.00030522, "dt_net": 0.46394219, "epoch": "5/12", "eta": "0:03:18", "gpu_mem": "16.93G", "grad_norm": 38.23580170, "iter": "20/56", "loss": 0.23139045, "lr": 0.00000290, "top1_err": 3.12500000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:35:20][INFO] train_net.py:  491: Distillation Loss: 0.05470276
[12/17 16:35:20][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:35:24][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.47135879, "dt_data": 0.00037776, "dt_net": 0.47098094, "epoch": "5/12", "eta": "0:03:17", "gpu_mem": "16.93G", "grad_norm": 37.50361633, "iter": "30/56", "loss": 0.27298969, "lr": 0.00000284, "top1_err": 6.25000000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:35:24][INFO] train_net.py:  491: Distillation Loss: 0.04114532
[12/17 16:35:24][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:35:29][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45880766, "dt_data": 0.00033295, "dt_net": 0.45847344, "epoch": "5/12", "eta": "0:03:07", "gpu_mem": "16.93G", "grad_norm": 17.44107246, "iter": "40/56", "loss": 0.24900065, "lr": 0.00000277, "top1_err": 4.68750000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:35:29][INFO] train_net.py:  491: Distillation Loss: 0.04176259
[12/17 16:35:29][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:35:33][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45177551, "dt_data": 0.00019049, "dt_net": 0.45158434, "epoch": "5/12", "eta": "0:02:59", "gpu_mem": "16.93G", "grad_norm": 36.20239639, "iter": "50/56", "loss": 0.26373503, "lr": 0.00000270, "top1_err": 4.68750000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:35:34][INFO] train_net.py:  491: Distillation Loss: 0.04285222
[12/17 16:35:34][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:35:37][INFO] logging.py:   99: json_stats: {"RAM": "53.93/251.74G", "_type": "train_epoch", "dt": 1.21723628, "dt_data": 1.21723635, "dt_net": 0.44995235, "epoch": "5/12", "eta": "0:07:57", "gpu_mem": "16.93G", "grad_norm": 37.31572723, "loss": 0.27334917, "lr": 0.00000266, "top1_err": 5.46875000, "top5_err": 0.33482143}
[12/17 16:35:37][INFO] train_net.py: 1344: Epoch 4 takes 48.16s. Epochs from 0 to 4 take 47.68s in average and 47.44s in median.
[12/17 16:35:37][INFO] train_net.py: 1350: For epoch 4, each iteraction takes 0.86s in average. From epoch 0 to 4, each iteraction takes 0.85s in average.
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:36:03][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:00:04", "gpu_mem": "16.93G", "iter": "10/25", "time_diff": 0.28644456, "top1_err": 28.12500000, "top5_err": 3.12500000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:36:06][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "5/12", "eta": "0:00:01", "gpu_mem": "16.93G", "iter": "20/25", "time_diff": 0.28534718, "top1_err": 25.00000000, "top5_err": 3.12500000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([16, 512]),bz: 2,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([2, 512])
[12/17 16:36:09][INFO] logging.py:   99: json_stats: {"RAM": "54.11/251.74G", "_type": "val_epoch", "epoch": "5/12", "gpu_mem": "16.93G", "min_top1_err": 23.32474227, "min_top5_err": 3.35051546, "time_diff": 1.22443516, "top1_err": 25.38659794, "top5_err": 3.99484536}
[12/17 16:36:09][INFO] train_net.py:  304: total trainable params:
[12/17 16:36:09][INFO] train_net.py:  307: module.model.positional_embedding
[12/17 16:36:09][INFO] train_net.py:  307: module.model.text_projection
[12/17 16:36:09][INFO] train_net.py:  307: module.model.logit_scale
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.proj
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.ln_final.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.model.ln_final.bias
[12/17 16:36:09][INFO] train_net.py:  307: module.projector_v.0.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.projector_v.2.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.projector_t.0.weight
[12/17 16:36:09][INFO] train_net.py:  307: module.projector_t.2.weight
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:36:29][INFO] train_net.py:  491: Distillation Loss: 0.04425848
[12/17 16:36:29][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:36:34][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.46582515, "dt_data": 0.00035572, "dt_net": 0.46546780, "epoch": "6/12", "eta": "0:02:57", "gpu_mem": "16.93G", "grad_norm": 53.25738907, "iter": "10/56", "loss": 0.18697418, "lr": 0.00000258, "top1_err": 1.56250000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:36:34][INFO] train_net.py:  491: Distillation Loss: 0.03808099
[12/17 16:36:34][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:36:38][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.46278469, "dt_data": 0.00031620, "dt_net": 0.46246725, "epoch": "6/12", "eta": "0:02:52", "gpu_mem": "16.93G", "grad_norm": 20.67743874, "iter": "20/56", "loss": 0.18223220, "lr": 0.00000250, "top1_err": 1.56250000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:36:38][INFO] train_net.py:  491: Distillation Loss: 0.04087675
[12/17 16:36:38][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:36:43][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45963509, "dt_data": 0.00035492, "dt_net": 0.45927904, "epoch": "6/12", "eta": "0:02:46", "gpu_mem": "16.93G", "grad_norm": 20.53704643, "iter": "30/56", "loss": 0.21568337, "lr": 0.00000242, "top1_err": 3.12500000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:36:43][INFO] train_net.py:  491: Distillation Loss: 0.03708220
[12/17 16:36:43][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:36:47][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45894272, "dt_data": 0.00031765, "dt_net": 0.45862405, "epoch": "6/12", "eta": "0:02:41", "gpu_mem": "16.93G", "grad_norm": 41.61029434, "iter": "40/56", "loss": 0.18414919, "lr": 0.00000234, "top1_err": 1.56250000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:36:48][INFO] train_net.py:  491: Distillation Loss: 0.04074174
[12/17 16:36:48][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:36:52][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.44812037, "dt_data": 0.00016496, "dt_net": 0.44795441, "epoch": "6/12", "eta": "0:02:33", "gpu_mem": "16.93G", "grad_norm": 15.79704094, "iter": "50/56", "loss": 0.18050881, "lr": 0.00000225, "top1_err": 3.12500000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:36:52][INFO] train_net.py:  491: Distillation Loss: 0.04688454
[12/17 16:36:52][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:36:56][INFO] logging.py:   99: json_stats: {"RAM": "53.91/251.74G", "_type": "train_epoch", "dt": 1.33097489, "dt_data": 1.33097462, "dt_net": 0.45579714, "epoch": "6/12", "eta": "0:07:27", "gpu_mem": "16.93G", "grad_norm": 28.80854988, "loss": 0.21675915, "lr": 0.00000220, "top1_err": 3.23660714, "top5_err": 0.16741071}
[12/17 16:36:56][INFO] train_net.py: 1344: Epoch 5 takes 47.35s. Epochs from 0 to 5 take 47.63s in average and 47.40s in median.
[12/17 16:36:56][INFO] train_net.py: 1350: For epoch 5, each iteraction takes 0.85s in average. From epoch 0 to 5, each iteraction takes 0.85s in average.
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:37:23][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:00:04", "gpu_mem": "16.93G", "iter": "10/25", "time_diff": 0.28660455, "top1_err": 25.00000000, "top5_err": 3.12500000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:37:26][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "6/12", "eta": "0:00:01", "gpu_mem": "16.93G", "iter": "20/25", "time_diff": 0.28939889, "top1_err": 23.43750000, "top5_err": 4.68750000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([16, 512]),bz: 2,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([2, 512])
[12/17 16:37:28][INFO] logging.py:   99: json_stats: {"RAM": "53.95/251.74G", "_type": "val_epoch", "epoch": "6/12", "gpu_mem": "16.93G", "min_top1_err": 23.32474227, "min_top5_err": 3.35051546, "time_diff": 1.22450282, "top1_err": 24.87113402, "top5_err": 3.99484536}
[12/17 16:37:28][INFO] train_net.py:  304: total trainable params:
[12/17 16:37:28][INFO] train_net.py:  307: module.model.positional_embedding
[12/17 16:37:28][INFO] train_net.py:  307: module.model.text_projection
[12/17 16:37:28][INFO] train_net.py:  307: module.model.logit_scale
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.proj
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.ln_final.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.model.ln_final.bias
[12/17 16:37:28][INFO] train_net.py:  307: module.projector_v.0.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.projector_v.2.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.projector_t.0.weight
[12/17 16:37:28][INFO] train_net.py:  307: module.projector_t.2.weight
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:37:48][INFO] train_net.py:  491: Distillation Loss: 0.04539311
[12/17 16:37:48][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:37:53][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45373590, "dt_data": 0.00042991, "dt_net": 0.45330563, "epoch": "7/12", "eta": "0:02:27", "gpu_mem": "16.93G", "grad_norm": 7.39955187, "iter": "10/56", "loss": 0.15224134, "lr": 0.00000211, "top1_err": 1.56250000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:37:53][INFO] train_net.py:  491: Distillation Loss: 0.03522575
[12/17 16:37:53][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:37:58][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.46347890, "dt_data": 0.00035859, "dt_net": 0.46312023, "epoch": "7/12", "eta": "0:02:26", "gpu_mem": "16.93G", "grad_norm": 26.90370560, "iter": "20/56", "loss": 0.13677434, "lr": 0.00000202, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:37:58][INFO] train_net.py:  491: Distillation Loss: 0.03449154
[12/17 16:37:58][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:38:02][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45825038, "dt_data": 0.00056093, "dt_net": 0.45768756, "epoch": "7/12", "eta": "0:02:20", "gpu_mem": "16.93G", "grad_norm": 14.38589382, "iter": "30/56", "loss": 0.22096664, "lr": 0.00000193, "top1_err": 3.12500000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:38:03][INFO] train_net.py:  491: Distillation Loss: 0.02898592
[12/17 16:38:03][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:38:07][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.46628712, "dt_data": 0.00039809, "dt_net": 0.46588616, "epoch": "7/12", "eta": "0:02:18", "gpu_mem": "16.93G", "grad_norm": 24.08431435, "iter": "40/56", "loss": 0.14288654, "lr": 0.00000184, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:38:07][INFO] train_net.py:  491: Distillation Loss: 0.03650427
[12/17 16:38:07][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:38:12][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45124864, "dt_data": 0.00017160, "dt_net": 0.45107634, "epoch": "7/12", "eta": "0:02:09", "gpu_mem": "16.93G", "grad_norm": 25.75357819, "iter": "50/56", "loss": 0.15401023, "lr": 0.00000175, "top1_err": 1.56250000, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:38:12][INFO] train_net.py:  491: Distillation Loss: 0.03097373
[12/17 16:38:12][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:38:16][INFO] logging.py:   99: json_stats: {"RAM": "53.98/251.74G", "_type": "train_epoch", "dt": 1.38246585, "dt_data": 1.38246618, "dt_net": 0.44920431, "epoch": "7/12", "eta": "0:06:27", "gpu_mem": "16.93G", "grad_norm": 12.57425117, "loss": 0.16145672, "lr": 0.00000169, "top1_err": 1.84151786, "top5_err": 0.05580357}
[12/17 16:38:16][INFO] train_net.py: 1344: Epoch 6 takes 47.41s. Epochs from 0 to 6 take 47.60s in average and 47.41s in median.
[12/17 16:38:16][INFO] train_net.py: 1350: For epoch 6, each iteraction takes 0.85s in average. From epoch 0 to 6, each iteraction takes 0.85s in average.
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:38:42][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:00:04", "gpu_mem": "16.93G", "iter": "10/25", "time_diff": 0.28495788, "top1_err": 25.00000000, "top5_err": 3.12500000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:38:45][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "7/12", "eta": "0:00:01", "gpu_mem": "16.93G", "iter": "20/25", "time_diff": 0.28610243, "top1_err": 25.00000000, "top5_err": 4.68750000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([16, 512]),bz: 2,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([2, 512])
[12/17 16:38:48][INFO] logging.py:   99: json_stats: {"RAM": "54.44/251.74G", "_type": "val_epoch", "epoch": "7/12", "gpu_mem": "16.93G", "min_top1_err": 23.32474227, "min_top5_err": 3.35051546, "time_diff": 1.13387633, "top1_err": 25.00000000, "top5_err": 4.38144330}
[12/17 16:38:48][INFO] train_net.py:  304: total trainable params:
[12/17 16:38:48][INFO] train_net.py:  307: module.model.positional_embedding
[12/17 16:38:48][INFO] train_net.py:  307: module.model.text_projection
[12/17 16:38:48][INFO] train_net.py:  307: module.model.logit_scale
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.proj
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.ln_final.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.model.ln_final.bias
[12/17 16:38:48][INFO] train_net.py:  307: module.projector_v.0.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.projector_v.2.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.projector_t.0.weight
[12/17 16:38:48][INFO] train_net.py:  307: module.projector_t.2.weight
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:39:08][INFO] train_net.py:  491: Distillation Loss: 0.03590029
[12/17 16:39:08][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:39:13][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.44728556, "dt_data": 0.00036709, "dt_net": 0.44691759, "epoch": "8/12", "eta": "0:02:00", "gpu_mem": "16.93G", "grad_norm": 18.17457199, "iter": "10/56", "loss": 0.13774318, "lr": 0.00000160, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:39:13][INFO] train_net.py:  491: Distillation Loss: 0.04066354
[12/17 16:39:13][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:39:17][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.46579728, "dt_data": 0.00031311, "dt_net": 0.46548277, "epoch": "8/12", "eta": "0:02:01", "gpu_mem": "16.93G", "grad_norm": 12.65666676, "iter": "20/56", "loss": 0.12036701, "lr": 0.00000151, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:39:18][INFO] train_net.py:  491: Distillation Loss: 0.03726256
[12/17 16:39:18][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:39:22][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.46022612, "dt_data": 0.00028908, "dt_net": 0.45993598, "epoch": "8/12", "eta": "0:01:55", "gpu_mem": "16.93G", "grad_norm": 22.67342377, "iter": "30/56", "loss": 0.11240794, "lr": 0.00000141, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:39:22][INFO] train_net.py:  491: Distillation Loss: 0.03345132
[12/17 16:39:22][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:39:27][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.46075837, "dt_data": 0.00031865, "dt_net": 0.46043845, "epoch": "8/12", "eta": "0:01:50", "gpu_mem": "16.93G", "grad_norm": 10.41013432, "iter": "40/56", "loss": 0.10590523, "lr": 0.00000132, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:39:27][INFO] train_net.py:  491: Distillation Loss: 0.03248847
[12/17 16:39:27][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:39:31][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45011396, "dt_data": 0.00018496, "dt_net": 0.44992831, "epoch": "8/12", "eta": "0:01:43", "gpu_mem": "16.93G", "grad_norm": 11.70791721, "iter": "50/56", "loss": 0.14584233, "lr": 0.00000123, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:39:31][INFO] train_net.py:  491: Distillation Loss: 0.02992964
[12/17 16:39:31][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:39:35][INFO] logging.py:   99: json_stats: {"RAM": "53.95/251.74G", "_type": "train_epoch", "dt": 1.26949546, "dt_data": 1.26949558, "dt_net": 0.44942622, "epoch": "8/12", "eta": "0:04:44", "gpu_mem": "16.93G", "grad_norm": 8.84401894, "loss": 0.13589111, "lr": 0.00000118, "top1_err": 1.17187500, "top5_err": 0.11160714}
[12/17 16:39:35][INFO] train_net.py: 1344: Epoch 7 takes 47.57s. Epochs from 0 to 7 take 47.59s in average and 47.42s in median.
[12/17 16:39:35][INFO] train_net.py: 1350: For epoch 7, each iteraction takes 0.85s in average. From epoch 0 to 7, each iteraction takes 0.85s in average.
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:40:01][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:00:04", "gpu_mem": "16.93G", "iter": "10/25", "time_diff": 0.29478996, "top1_err": 26.56250000, "top5_err": 3.12500000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:40:04][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "8/12", "eta": "0:00:01", "gpu_mem": "16.93G", "iter": "20/25", "time_diff": 0.29285972, "top1_err": 23.43750000, "top5_err": 4.68750000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([16, 512]),bz: 2,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([2, 512])
[12/17 16:40:07][INFO] logging.py:   99: json_stats: {"RAM": "55.80/251.74G", "_type": "val_epoch", "epoch": "8/12", "gpu_mem": "16.93G", "min_top1_err": 23.32474227, "min_top5_err": 3.35051546, "time_diff": 1.12902556, "top1_err": 24.35567010, "top5_err": 4.38144330}
[12/17 16:40:07][INFO] train_net.py:  304: total trainable params:
[12/17 16:40:07][INFO] train_net.py:  307: module.model.positional_embedding
[12/17 16:40:07][INFO] train_net.py:  307: module.model.text_projection
[12/17 16:40:07][INFO] train_net.py:  307: module.model.logit_scale
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.proj
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.ln_final.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.model.ln_final.bias
[12/17 16:40:07][INFO] train_net.py:  307: module.projector_v.0.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.projector_v.2.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.projector_t.0.weight
[12/17 16:40:07][INFO] train_net.py:  307: module.projector_t.2.weight
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:40:26][INFO] train_net.py:  491: Distillation Loss: 0.02921748
[12/17 16:40:26][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:40:32][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45747723, "dt_data": 0.00070156, "dt_net": 0.45677378, "epoch": "9/12", "eta": "0:01:37", "gpu_mem": "16.93G", "grad_norm": 27.46537399, "iter": "10/56", "loss": 0.08932713, "lr": 0.00000109, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:40:32][INFO] train_net.py:  491: Distillation Loss: 0.02722597
[12/17 16:40:32][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:40:36][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.47725078, "dt_data": 0.00033441, "dt_net": 0.47691517, "epoch": "9/12", "eta": "0:01:37", "gpu_mem": "16.93G", "grad_norm": 6.93210077, "iter": "20/56", "loss": 0.10476297, "lr": 0.00000101, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:40:36][INFO] train_net.py:  491: Distillation Loss: 0.03797752
[12/17 16:40:36][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:40:41][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45414561, "dt_data": 0.00032112, "dt_net": 0.45382358, "epoch": "9/12", "eta": "0:01:28", "gpu_mem": "16.93G", "grad_norm": 5.87527514, "iter": "30/56", "loss": 0.10669666, "lr": 9.3E-7, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:40:41][INFO] train_net.py:  491: Distillation Loss: 0.03180796
[12/17 16:40:41][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:40:46][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45767437, "dt_data": 0.00036153, "dt_net": 0.45731169, "epoch": "9/12", "eta": "0:01:24", "gpu_mem": "16.93G", "grad_norm": 4.51927423, "iter": "40/56", "loss": 0.10264777, "lr": 8.4E-7, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:40:46][INFO] train_net.py:  491: Distillation Loss: 0.02899742
[12/17 16:40:46][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:40:50][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45039242, "dt_data": 0.00018773, "dt_net": 0.45020405, "epoch": "9/12", "eta": "0:01:18", "gpu_mem": "16.93G", "grad_norm": 24.58937645, "iter": "50/56", "loss": 0.11008326, "lr": 7.7E-7, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:40:50][INFO] train_net.py:  491: Distillation Loss: 0.03146511
[12/17 16:40:50][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:40:54][INFO] logging.py:   99: json_stats: {"RAM": "53.99/251.74G", "_type": "train_epoch", "dt": 1.38545604, "dt_data": 1.38545570, "dt_net": 0.44708512, "epoch": "9/12", "eta": "0:03:52", "gpu_mem": "16.93G", "grad_norm": 85.20851898, "loss": 0.11324042, "lr": 7.2E-7, "top1_err": 0.55803571, "top5_err": 0.05580357}
[12/17 16:40:54][INFO] train_net.py: 1344: Epoch 8 takes 47.55s. Epochs from 0 to 8 take 47.59s in average and 47.44s in median.
[12/17 16:40:54][INFO] train_net.py: 1350: For epoch 8, each iteraction takes 0.85s in average. From epoch 0 to 8, each iteraction takes 0.85s in average.
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:41:21][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:00:04", "gpu_mem": "16.93G", "iter": "10/25", "time_diff": 0.28928084, "top1_err": 23.43750000, "top5_err": 3.12500000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:41:24][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "9/12", "eta": "0:00:01", "gpu_mem": "16.93G", "iter": "20/25", "time_diff": 0.29692799, "top1_err": 23.43750000, "top5_err": 3.12500000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([16, 512]),bz: 2,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([2, 512])
[12/17 16:41:27][INFO] logging.py:   99: json_stats: {"RAM": "53.94/251.74G", "_type": "val_epoch", "epoch": "9/12", "gpu_mem": "16.93G", "min_top1_err": 23.32474227, "min_top5_err": 3.35051546, "time_diff": 1.25006965, "top1_err": 25.77319588, "top5_err": 3.73711340}
[12/17 16:41:27][INFO] train_net.py:  304: total trainable params:
[12/17 16:41:27][INFO] train_net.py:  307: module.model.positional_embedding
[12/17 16:41:27][INFO] train_net.py:  307: module.model.text_projection
[12/17 16:41:27][INFO] train_net.py:  307: module.model.logit_scale
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.proj
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.ln_final.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.model.ln_final.bias
[12/17 16:41:27][INFO] train_net.py:  307: module.projector_v.0.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.projector_v.2.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.projector_t.0.weight
[12/17 16:41:27][INFO] train_net.py:  307: module.projector_t.2.weight
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:41:47][INFO] train_net.py:  491: Distillation Loss: 0.02709675
[12/17 16:41:47][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:41:52][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.46242071, "dt_data": 0.00021680, "dt_net": 0.46220276, "epoch": "10/12", "eta": "0:01:13", "gpu_mem": "16.93G", "grad_norm": 5.64944315, "iter": "10/56", "loss": 0.09488805, "lr": 6.5E-7, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:41:52][INFO] train_net.py:  491: Distillation Loss: 0.03046674
[12/17 16:41:52][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:41:56][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.46231696, "dt_data": 0.00098988, "dt_net": 0.46132518, "epoch": "10/12", "eta": "0:01:08", "gpu_mem": "16.93G", "grad_norm": 5.27920341, "iter": "20/56", "loss": 0.08842506, "lr": 5.8E-7, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:41:57][INFO] train_net.py:  491: Distillation Loss: 0.03475696
[12/17 16:41:57][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:42:01][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.46114747, "dt_data": 0.00046202, "dt_net": 0.46068376, "epoch": "10/12", "eta": "0:01:03", "gpu_mem": "16.93G", "grad_norm": 8.14933395, "iter": "30/56", "loss": 0.08425726, "lr": 5.1E-7, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:42:01][INFO] train_net.py:  491: Distillation Loss: 0.03434682
[12/17 16:42:01][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:42:06][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.46346701, "dt_data": 0.00049864, "dt_net": 0.46296598, "epoch": "10/12", "eta": "0:00:59", "gpu_mem": "16.93G", "grad_norm": 21.14211464, "iter": "40/56", "loss": 0.09382837, "lr": 4.5E-7, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:42:06][INFO] train_net.py:  491: Distillation Loss: 0.02504408
[12/17 16:42:06][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:42:10][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.44973462, "dt_data": 0.00017945, "dt_net": 0.44955426, "epoch": "10/12", "eta": "0:00:53", "gpu_mem": "16.93G", "grad_norm": 8.48187637, "iter": "50/56", "loss": 0.10593894, "lr": 3.9E-7, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:42:10][INFO] train_net.py:  491: Distillation Loss: 0.03217769
[12/17 16:42:10][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:42:14][INFO] logging.py:   99: json_stats: {"RAM": "53.97/251.74G", "_type": "train_epoch", "dt": 1.47042918, "dt_data": 1.47042909, "dt_net": 0.44830838, "epoch": "10/12", "eta": "0:02:44", "gpu_mem": "16.93G", "grad_norm": 7.70697212, "loss": 0.10111174, "lr": 3.5E-7, "top1_err": 0.44642857, "top5_err": 0E-8}
[12/17 16:42:14][INFO] train_net.py: 1344: Epoch 9 takes 47.80s. Epochs from 0 to 9 take 47.61s in average and 47.50s in median.
[12/17 16:42:14][INFO] train_net.py: 1350: For epoch 9, each iteraction takes 0.85s in average. From epoch 0 to 9, each iteraction takes 0.85s in average.
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:42:40][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:00:04", "gpu_mem": "16.93G", "iter": "10/25", "time_diff": 0.28979044, "top1_err": 21.87500000, "top5_err": 4.68750000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:42:43][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "10/12", "eta": "0:00:01", "gpu_mem": "16.93G", "iter": "20/25", "time_diff": 0.28386705, "top1_err": 23.43750000, "top5_err": 3.12500000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([16, 512]),bz: 2,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([2, 512])
[12/17 16:42:46][INFO] logging.py:   99: json_stats: {"RAM": "53.94/251.74G", "_type": "val_epoch", "epoch": "10/12", "gpu_mem": "16.93G", "min_top1_err": 23.32474227, "min_top5_err": 3.35051546, "time_diff": 1.35525178, "top1_err": 25.25773196, "top5_err": 4.51030928}
[12/17 16:42:46][INFO] train_net.py:  304: total trainable params:
[12/17 16:42:46][INFO] train_net.py:  307: module.model.positional_embedding
[12/17 16:42:46][INFO] train_net.py:  307: module.model.text_projection
[12/17 16:42:46][INFO] train_net.py:  307: module.model.logit_scale
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.proj
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.ln_final.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.model.ln_final.bias
[12/17 16:42:46][INFO] train_net.py:  307: module.projector_v.0.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.projector_v.2.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.projector_t.0.weight
[12/17 16:42:46][INFO] train_net.py:  307: module.projector_t.2.weight
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:43:06][INFO] train_net.py:  491: Distillation Loss: 0.03025329
[12/17 16:43:06][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:43:11][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.46273045, "dt_data": 0.00031797, "dt_net": 0.46241221, "epoch": "11/12", "eta": "0:00:47", "gpu_mem": "16.93G", "grad_norm": 23.27832603, "iter": "10/56", "loss": 0.10157235, "lr": 3.0E-7, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:43:11][INFO] train_net.py:  491: Distillation Loss: 0.02573526
[12/17 16:43:11][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:43:16][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.46627298, "dt_data": 0.00028722, "dt_net": 0.46598472, "epoch": "11/12", "eta": "0:00:42", "gpu_mem": "16.93G", "grad_norm": 8.03089428, "iter": "20/56", "loss": 0.08816611, "lr": 2.5E-7, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:43:16][INFO] train_net.py:  491: Distillation Loss: 0.03418082
[12/17 16:43:16][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:43:20][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45579801, "dt_data": 0.00028968, "dt_net": 0.45550735, "epoch": "11/12", "eta": "0:00:37", "gpu_mem": "16.93G", "grad_norm": 19.87619019, "iter": "30/56", "loss": 0.09109190, "lr": 2.1E-7, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:43:21][INFO] train_net.py:  491: Distillation Loss: 0.02815986
[12/17 16:43:21][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:43:25][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45374461, "dt_data": 0.00035467, "dt_net": 0.45338887, "epoch": "11/12", "eta": "0:00:32", "gpu_mem": "16.93G", "grad_norm": 8.84880066, "iter": "40/56", "loss": 0.07360000, "lr": 1.7E-7, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:43:25][INFO] train_net.py:  491: Distillation Loss: 0.02554798
[12/17 16:43:25][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:43:30][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.45854814, "dt_data": 0.00016182, "dt_net": 0.45838561, "epoch": "11/12", "eta": "0:00:28", "gpu_mem": "16.93G", "grad_norm": 19.20590019, "iter": "50/56", "loss": 0.08661227, "lr": 1.4E-7, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:43:30][INFO] train_net.py:  491: Distillation Loss: 0.02336776
[12/17 16:43:30][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:43:34][INFO] logging.py:   99: json_stats: {"RAM": "53.94/251.74G", "_type": "train_epoch", "dt": 1.47066506, "dt_data": 1.47066487, "dt_net": 0.46290735, "epoch": "11/12", "eta": "0:01:22", "gpu_mem": "16.93G", "grad_norm": 6.99453354, "loss": 0.09507191, "lr": 1.2E-7, "top1_err": 0.33482143, "top5_err": 0.05580357}
[12/17 16:43:34][INFO] train_net.py: 1344: Epoch 10 takes 47.76s. Epochs from 0 to 10 take 47.62s in average and 47.55s in median.
[12/17 16:43:34][INFO] train_net.py: 1350: For epoch 10, each iteraction takes 0.85s in average. From epoch 0 to 10, each iteraction takes 0.85s in average.
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:44:00][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:00:04", "gpu_mem": "16.93G", "iter": "10/25", "time_diff": 0.29149254, "top1_err": 23.43750000, "top5_err": 3.12500000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:44:02][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "11/12", "eta": "0:00:01", "gpu_mem": "16.93G", "iter": "20/25", "time_diff": 0.28499917, "top1_err": 23.43750000, "top5_err": 3.12500000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([16, 512]),bz: 2,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([2, 512])
[12/17 16:44:05][INFO] logging.py:   99: json_stats: {"RAM": "53.94/251.74G", "_type": "val_epoch", "epoch": "11/12", "gpu_mem": "16.93G", "min_top1_err": 23.32474227, "min_top5_err": 3.35051546, "time_diff": 1.25270020, "top1_err": 24.74226804, "top5_err": 3.60824742}
[12/17 16:44:05][INFO] train_net.py:  304: total trainable params:
[12/17 16:44:05][INFO] train_net.py:  307: module.model.positional_embedding
[12/17 16:44:05][INFO] train_net.py:  307: module.model.text_projection
[12/17 16:44:05][INFO] train_net.py:  307: module.model.logit_scale
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.class_embedding
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.positional_embedding
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.proj
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.conv1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.ln_pre.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.ln_pre.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.0.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.1.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.2.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.3.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.4.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.5.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.6.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.7.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.8.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.9.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.10.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.transformer.resblocks.11.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.ln_post.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.visual.ln_post.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.0.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.0.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.0.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.1.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.1.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.1.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.2.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.2.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.2.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.3.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.3.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.3.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.4.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.4.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.4.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.5.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.5.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.5.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.6.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.6.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.6.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.7.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.7.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.7.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.8.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.8.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.8.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.9.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.9.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.9.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.10.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.10.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.10.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.in_proj_bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.11.attn.out_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_1.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_fc.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.11.mlp.c_proj.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.transformer.resblocks.11.ln_2.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.model.token_embedding.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.ln_final.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.model.ln_final.bias
[12/17 16:44:05][INFO] train_net.py:  307: module.projector_v.0.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.projector_v.2.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.projector_t.0.weight
[12/17 16:44:05][INFO] train_net.py:  307: module.projector_t.2.weight
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:44:26][INFO] train_net.py:  491: Distillation Loss: 0.02927554
[12/17 16:44:26][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:44:31][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.46179913, "dt_data": 0.00029231, "dt_net": 0.46150653, "epoch": "12/12", "eta": "0:00:21", "gpu_mem": "16.93G", "grad_norm": 3.70978546, "iter": "10/56", "loss": 0.09240412, "lr": 9E-8, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:44:31][INFO] train_net.py:  491: Distillation Loss: 0.02508986
[12/17 16:44:31][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:44:35][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.46505137, "dt_data": 0.00026940, "dt_net": 0.46478122, "epoch": "12/12", "eta": "0:00:16", "gpu_mem": "16.93G", "grad_norm": 10.65293026, "iter": "20/56", "loss": 0.09236214, "lr": 7E-8, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:44:35][INFO] train_net.py:  491: Distillation Loss: 0.02624124
[12/17 16:44:35][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:44:40][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.47782325, "dt_data": 0.00041234, "dt_net": 0.47740814, "epoch": "12/12", "eta": "0:00:12", "gpu_mem": "16.93G", "grad_norm": 14.20053005, "iter": "30/56", "loss": 0.08675082, "lr": 5E-8, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:44:40][INFO] train_net.py:  491: Distillation Loss: 0.03094882
[12/17 16:44:40][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:44:45][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.46972626, "dt_data": 0.00056272, "dt_net": 0.46916036, "epoch": "12/12", "eta": "0:00:07", "gpu_mem": "16.93G", "grad_norm": 18.78903198, "iter": "40/56", "loss": 0.08893532, "lr": 4E-8, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:44:45][INFO] train_net.py:  491: Distillation Loss: 0.02598828
[12/17 16:44:45][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:44:49][INFO] logging.py:   99: json_stats: {"_type": "train_iter_", "dt": 0.44953155, "dt_data": 0.00016911, "dt_net": 0.44936225, "epoch": "12/12", "eta": "0:00:02", "gpu_mem": "16.93G", "grad_norm": 6.91823626, "iter": "50/56", "loss": 0.08564042, "lr": 3E-8, "top1_err": 0E-8, "top5_err": 0E-8}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:44:49][INFO] train_net.py:  491: Distillation Loss: 0.02857268
[12/17 16:44:49][INFO] train_net.py:  492: Distillation Loss Ratio: 2.000000
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:44:53][INFO] logging.py:   99: json_stats: {"RAM": "54.54/251.74G", "_type": "train_epoch", "dt": 1.51614844, "dt_data": 1.51614841, "dt_net": 0.45163150, "epoch": "12/12", "eta": "0:00:00", "gpu_mem": "16.93G", "grad_norm": 4.15012407, "loss": 0.09740101, "lr": 3E-8, "top1_err": 0.44642857, "top5_err": 0.05580357}
[12/17 16:44:53][INFO] train_net.py: 1344: Epoch 11 takes 48.16s. Epochs from 0 to 11 take 47.67s in average and 47.56s in median.
[12/17 16:44:53][INFO] train_net.py: 1350: For epoch 11, each iteraction takes 0.86s in average. From epoch 0 to 11, each iteraction takes 0.85s in average.
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:45:20][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:00:04", "gpu_mem": "16.93G", "iter": "10/25", "time_diff": 0.31440830, "top1_err": 28.12500000, "top5_err": 3.12500000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
[12/17 16:45:23][INFO] logging.py:   99: json_stats: {"_type": "val_iter", "epoch": "12/12", "eta": "0:00:01", "gpu_mem": "16.93G", "iter": "20/25", "time_diff": 0.29460719, "top1_err": 21.87500000, "top5_err": 3.12500000}
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([64, 512]),bz: 8,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([8, 512])
img_encode shape: torch.Size([16, 512]),bz: 2,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([2, 512])
[12/17 16:45:25][INFO] logging.py:   99: json_stats: {"RAM": "54.83/251.74G", "_type": "val_epoch", "epoch": "12/12", "gpu_mem": "16.93G", "min_top1_err": 23.32474227, "min_top5_err": 3.35051546, "time_diff": 1.21099116, "top1_err": 25.00000000, "top5_err": 4.38144330}
[12/17 16:45:25][INFO] train_net.py: 1449: training done: _p300.29_f10.00 _t0.79_m16.93 _a76.68 Top5 Acc: 96.65 MEM: 16.93 f: 10.0000
[12/17 16:45:30][INFO] test_net.py:  319: Test with config:
[12/17 16:45:30][INFO] test_net.py:  320: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: False
  GEN_MASK_LOADER: False
  INTERPOLATION: bicubic
  MASK_FRAMES: False
  MASK_RATIO: 0.0
  MASK_TUBE: False
  MASK_WINDOW_SIZE: [8, 7, 7]
  MAX_MASK_PATCHES_PER_BLOCK: None
  NUM_SAMPLE: 1
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  BGR: False
  DETECTION_SCORE_THRESH: 0.9
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: /mnt/fair-flash3-east/ava_trainval_frames.img/
  FRAME_LIST_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  FULL_TEST_ON_VAL: False
  GROUNDTRUTH_FILE: ava_val_v2.2.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: ava_action_list_v2.2_for_activitynet_2019.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_val_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train_v2.2.csv']
  TRAIN_LISTS: ['train_all.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  GLOBAL_SYNC: False
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
CONTRASTIVE:
  BN_MLP: False
  BN_SYNC_MLP: False
  DELTA_CLIPS_MAX: inf
  DELTA_CLIPS_MIN: -inf
  DIM: 128
  INTERP_MEMORY: False
  KNN_ON: True
  LENGTH: 239975
  LOCAL_SHUFFLE_BN: True
  MEM_TYPE: 1d
  MLP_DIM: 2048
  MOCO_MULTI_VIEW_QUEUE: False
  MOMENTUM: 0.5
  MOMENTUM_ANNEALING: False
  NUM_CLASSES_DOWNSTREAM: 400
  NUM_MLP_LAYERS: 1
  PREDICTOR_DEPTHS: []
  QUEUE_LEN: 65536
  SEQUENTIAL: False
  SIMCLR_DIST_ON: True
  SWAV_QEUE_LEN: 0
  T: 0.07
  TYPE: mem
DATA:
  COLOR_RND_GRAYSCALE: 0.0
  DECODING_BACKEND: pyav
  DECODING_SHORT_SIZE: 256
  DUMMY_LOAD: False
  ENSEMBLE_METHOD: sum
  IN22K_TRAINVAL: False
  IN22k_VAL_IN1K: 
  INDEX_LABEL_MAPPING_FILE: /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/train_rephrased.json
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  IN_VAL_CROP_RATIO: 0.875
  LOADER_CHUNK_OVERALL_SIZE: 0
  LOADER_CHUNK_SIZE: 0
  MEAN: [0.48145466, 0.4578275, 0.40821073]
  MULTI_LABEL: False
  NUM_FRAMES: 8
  PATH_LABEL_SEPARATOR: ,
  PATH_PREFIX: /mnt/SSD8T/home/huangwei/projects/FROSTER/data/hmdb51
  PATH_TO_DATA_DIR: /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb
  PATH_TO_PRELOAD_IMDB: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 16
  SKIP_ROWS: 0
  SSL_BLUR_SIGMA_MAX: [0.0, 2.0]
  SSL_BLUR_SIGMA_MIN: [0.0, 0.1]
  SSL_COLOR_BRI_CON_SAT: [0.4, 0.4, 0.4]
  SSL_COLOR_HUE: 0.1
  SSL_COLOR_JITTER: False
  SSL_MOCOV2_AUG: False
  STD: [0.26862954, 0.26130258, 0.27577711]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TIME_DIFF_PROB: 0.0
  TRAIN_CROP_NUM_SPATIAL: 1
  TRAIN_CROP_NUM_TEMPORAL: 1
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: []
  TRAIN_JITTER_FPS: 0.0
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [224, 256]
  TRAIN_JITTER_SCALES_RELATIVE: []
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: False
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
IMAGENET_SIMPLELABEL_PATH: None
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MASK:
  DECODER_DEPTH: 0
  DECODER_EMBED_DIM: 512
  DECODER_SEP_POS_EMBED: False
  DEC_KV_KERNEL: []
  DEC_KV_STRIDE: []
  ENABLE: False
  HEAD_TYPE: separate
  MAE_ON: False
  MAE_RND_MASK: False
  NORM_PRED_PIXEL: True
  PER_FRAME_MASKING: False
  PRED_HOG: False
  PRETRAIN_DEPTH: [15]
  SCALE_INIT_BY_DEPTH: False
  TIME_STRIDE_LOSS: True
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: False
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ADAPT_FINETUNE_FACTOR: 1.0
  ARCH: vitb16
  CLS_LOSS_RATIO: 1.0
  CONTEXT_LENGTH: 77
  DEFAULT_FINETUNE_FACTOR: 1.0
  DETACH_FINAL_FC: False
  DISTILLATION_RATIO: 2.0
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  ENSEMBLE_PRED: False
  ENSEMBLE_RAWMODEL_RATIO: 0.0
  EXPERT_FINETUNE_FACTOR: 1.0
  EXPERT_INSERT_LAYERS: [10, 11]
  FC_INIT_STD: 0.01
  FINETUNE_FACTOR: 1.0
  FP16_ALLREDUCE: False
  FROZEN_BN: False
  HEAD_ACT: softmax
  KEEP_RAW_MODEL: True
  LOSS_FREQ_TYPE: mse
  LOSS_FUNC: soft_cross_entropy
  MLP_FINETUNE_FACTOR: 1.0
  MODEL_NAME: TemporalClipVideo
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 26
  NUM_EXPERTS: 0
  PROMPT_NUM: 1
  RAW_MODEL_DISTILLATION: True
  RECORD_ROUTING: False
  ROUTING_FINETUNE_FACTOR: 1.0
  ROUTING_FREQUENCE_CONSTRAIN: 0.5
  ROUTING_FREQ_CONS_FACTOR: 1.0
  ROUTING_TYPE: patch-level
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'maskmvit', 'vitb32', 'vitb16', 'vitl14']
  STATIC_GRAPH: False
  TEMPORAL_MODELING_TYPE: expand_temporal_view
  TEXT_PROMPT: False
  USE_CHECKPOINT: False
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 16
  DIM_MUL: []
  DIM_MUL_IN_ATT: False
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.1
  EMBED_DIM: 96
  HEAD_INIT_SCALE: 1.0
  HEAD_MUL: []
  LAYER_SCALE_INIT_VALUE: 0.0
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [2, 4, 4]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: None
  POOL_KV_STRIDE: []
  POOL_KV_STRIDE_ADAPTIVE: None
  POOL_Q_STRIDE: []
  QKV_BIAS: True
  REL_POS_SPATIAL: False
  REL_POS_TEMPORAL: False
  REL_POS_ZERO_INIT: False
  RESIDUAL_POOLING: False
  REV:
    BUFFER_LAYERS: []
    ENABLE: False
    PRE_Q_FUSION: avg
    RESPATH_FUSE: concat
    RES_PATH: conv
  SEPARATE_QKV: False
  SEP_POS_EMBED: False
  USE_ABS_POS: True
  USE_FIXED_SINCOS_POS: False
  USE_MEAN_POOLING: False
  ZERO_DECAY_POS_CLS: True
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 4
NUM_SHARDS: 1
OUTPUT_DIR: /mnt/SSD8T/home/huangwei/projects/FROSTER/checkpoints/basetraining/B2N_hmdb51_froster_premean
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
  ZERO_INIT_FINAL_CONV: False
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 3.33e-06
  BASE_LR_SCALE_NUM_SHARDS: True
  BETAS: (0.9, 0.999)
  CLIP_GRAD_L2NORM: 1.0
  CLIP_GRAD_VAL: None
  COSINE_AFTER_WARMUP: True
  COSINE_END_LR: 3.33e-08
  COSINE_RESTART_EPOCH: 0
  DAMPENING: 0.0
  GAMMA: 0.1
  LARS_ON: False
  LAYER_DECAY: 1.0
  LRS: []
  LR_POLICY: cosine
  MAX_EPOCH: 12
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: []
  STEP_SIZE: 1
  WARMUP_EPOCHS: 2.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 3.33e-08
  WEIGHT_DECAY: 0.01
  ZERO_WD_1D_PARAM: True
TASK: 
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 240
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_TYPE: pytorch
  CLIP_ORI_PATH: None
  CUSTOM_LOAD: False
  CUSTOM_LOAD_FILE: None
  DATASET: kinetics
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 3
  NUM_SPATIAL_CROPS: 1
  NUM_TEMPORAL_CLIPS: [3]
  OPENSET: False
  PATCHING_MODEL: False
  PATCHING_RATIO: 0.5
  SAVE_RESULTS_PATH: 
  UPDATE_STATE: False
TEST_FILE: test.csv
TRAIN:
  ADAPT_ZS_CONS_RATIO: False
  AUTO_RESUME: True
  BATCH_SIZE: 32
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_INFLATE: False
  CHECKPOINT_IN_INIT: False
  CHECKPOINT_PERIOD: 1
  CHECKPOINT_TYPE: pytorch
  CLIP_ORI_PATH: /mnt/SSD8T/home/huangwei/.cache/clip/ViT-B-16.pt
  CUSTOM_LOAD: False
  CUSTOM_LOAD_FILE: None
  DATASET: kinetics
  ENABLE: True
  EVAL_PERIOD: 1
  EWC_CONSTRAIN_RATIO: 1.0
  EWC_IDENTITY_FISHER: False
  EWC_IGNORE_LOGIT_SCALE: False
  EWC_LOAD_FILE: None
  EWC_SET: False
  KILL_LOSS_EXPLOSION_FACTOR: 0.0
  LINEAR_CONNECT_CLIMB: False
  LINEAR_CONNECT_LOSS_RATIO: 0.0
  LINEAR_CONNECT_SAMPLE: True
  LINEAR_CONNECT_SAMPLE_L: 0.4
  LINEAR_CONNECT_SAMPLE_R: 0.6
  MIXED_PRECISION: True
  ZS_CONS: False
  ZS_CONS_RATIO: 0.8
  ZS_INIT_CONS: False
  ZS_RESTART_CONS: False
  ZS_RESTART_EPOCH: -1
TRAIN_FILE: train_all.csv
TUNE_HEAD: False
VAL_FILE: val.csv
VAL_MODE: False
VIS_MASK:
  ENABLE: False
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[12/17 16:45:34][INFO] temporalclip_video_model.py:  636: load pretrained CLIP:<All keys matched successfully>
[12/17 16:45:41][INFO] temporalclip_video_model.py:  636: load pretrained CLIP:<All keys matched successfully>
[12/17 16:45:42][INFO] checkpoint.py:  222: Loading network weights from /mnt/SSD8T/home/huangwei/projects/FROSTER/checkpoints/basetraining/B2N_hmdb51_froster_premean/checkpoints/checkpoint_epoch_00012.pyth.
missing keys: []
unexpected keys: []
[12/17 16:45:44][INFO] misc.py:  185: Model:
DistributedDataParallel(
  (module): TemporalClipVideo(
    (model): WCLIP(
      (visual): TemporalVisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): TSTransformer(
          (resblocks): Sequential(
            (0): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (raw_model): WCLIP(
      (visual): TemporalVisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): TSTransformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (projector_v): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): GELU()
      (2): Linear(in_features=512, out_features=512, bias=False)
    )
    (projector_t): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): GELU()
      (2): Linear(in_features=512, out_features=512, bias=False)
    )
  )
)
[12/17 16:45:44][INFO] misc.py:  187: Params: 300,290,050
[12/17 16:45:44][INFO] misc.py:  188: Mem: 1.6999154090881348 MB
[12/17 16:45:44][INFO] misc.py:  197: nvidia-smi
Tue Dec 17 16:45:44 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  Off |
| 42%   32C    P2   102W / 450W |  13414MiB / 24564MiB |     98%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:23:00.0 Off |                  Off |
| 41%   32C    P2    93W / 450W |  13414MiB / 24564MiB |    100%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:41:00.0 Off |                  Off |
| 41%   34C    P2   101W / 450W |  13414MiB / 24564MiB |    100%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:61:00.0 Off |                  Off |
| 40%   33C    P2   102W / 450W |  13414MiB / 24564MiB |    100%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   4  NVIDIA GeForce ...  Off  | 00000000:81:00.0 Off |                  Off |
| 42%   32C    P2    67W / 450W |   5062MiB / 24564MiB |     16%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   5  NVIDIA GeForce ...  Off  | 00000000:A1:00.0 Off |                  Off |
| 41%   31C    P2    67W / 450W |   5062MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   6  NVIDIA GeForce ...  Off  | 00000000:C1:00.0 Off |                  Off |
| 42%   31C    P2    63W / 450W |   5062MiB / 24564MiB |     35%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   7  NVIDIA GeForce ...  Off  | 00000000:E1:00.0 Off |                  Off |
| 40%   30C    P2    67W / 450W |   5062MiB / 24564MiB |     24%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    0   N/A  N/A   1835998      C   ...3/envs/realnet/bin/python    13406MiB |
|    1   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    1   N/A  N/A   1835999      C   ...3/envs/realnet/bin/python    13406MiB |
|    2   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    2   N/A  N/A   1836000      C   ...3/envs/realnet/bin/python    13406MiB |
|    3   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    3   N/A  N/A   1836001      C   ...3/envs/realnet/bin/python    13406MiB |
|    4   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    4   N/A  N/A   2486227      C   .../envs/slowfast/bin/python     5054MiB |
|    5   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    5   N/A  N/A   2486228      C   .../envs/slowfast/bin/python     5054MiB |
|    6   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    6   N/A  N/A   2486229      C   .../envs/slowfast/bin/python     5054MiB |
|    7   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    7   N/A  N/A   2486230      C   .../envs/slowfast/bin/python     5054MiB |
+-----------------------------------------------------------------------------+
[12/17 16:45:45][INFO] misc.py:  185: Model:
DistributedDataParallel(
  (module): TemporalClipVideo(
    (model): WCLIP(
      (visual): TemporalVisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): TSTransformer(
          (resblocks): Sequential(
            (0): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): TimesAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (raw_model): WCLIP(
      (visual): TemporalVisionTransformer(
        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (transformer): TSTransformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=3072, out_features=768, bias=True)
              )
              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=512, out_features=2048, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=2048, out_features=512, bias=True)
            )
            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (token_embedding): Embedding(49408, 512)
      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (projector_v): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): GELU()
      (2): Linear(in_features=512, out_features=512, bias=False)
    )
    (projector_t): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): GELU()
      (2): Linear(in_features=512, out_features=512, bias=False)
    )
  )
)
[12/17 16:45:45][INFO] misc.py:  187: Params: 300,290,050
[12/17 16:45:45][INFO] misc.py:  188: Mem: 1.6999154090881348 MB
[12/17 16:45:45][INFO] misc.py:  197: nvidia-smi
Tue Dec 17 16:45:45 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  Off |
| 42%   32C    P2   104W / 450W |  13414MiB / 24564MiB |     67%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:23:00.0 Off |                  Off |
| 41%   32C    P2   101W / 450W |  13414MiB / 24564MiB |     82%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:41:00.0 Off |                  Off |
| 41%   34C    P2   107W / 450W |  13414MiB / 24564MiB |     85%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:61:00.0 Off |                  Off |
| 40%   33C    P2   105W / 450W |  13414MiB / 24564MiB |     75%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   4  NVIDIA GeForce ...  Off  | 00000000:81:00.0 Off |                  Off |
| 42%   31C    P2    65W / 450W |   5062MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   5  NVIDIA GeForce ...  Off  | 00000000:A1:00.0 Off |                  Off |
| 41%   30C    P2    67W / 450W |   5062MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   6  NVIDIA GeForce ...  Off  | 00000000:C1:00.0 Off |                  Off |
| 42%   30C    P2    55W / 450W |   5062MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   7  NVIDIA GeForce ...  Off  | 00000000:E1:00.0 Off |                  Off |
| 39%   29C    P2    61W / 450W |   5062MiB / 24564MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    0   N/A  N/A   1835998      C   ...3/envs/realnet/bin/python    13406MiB |
|    1   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    1   N/A  N/A   1835999      C   ...3/envs/realnet/bin/python    13406MiB |
|    2   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    2   N/A  N/A   1836000      C   ...3/envs/realnet/bin/python    13406MiB |
|    3   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    3   N/A  N/A   1836001      C   ...3/envs/realnet/bin/python    13406MiB |
|    4   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    4   N/A  N/A   2486227      C   .../envs/slowfast/bin/python     5054MiB |
|    5   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    5   N/A  N/A   2486228      C   .../envs/slowfast/bin/python     5054MiB |
|    6   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    6   N/A  N/A   2486229      C   .../envs/slowfast/bin/python     5054MiB |
|    7   N/A  N/A      3082      G   /usr/lib/xorg/Xorg                  4MiB |
|    7   N/A  N/A   2486230      C   .../envs/slowfast/bin/python     5054MiB |
+-----------------------------------------------------------------------------+
[12/17 16:45:46][INFO] kinetics.py:   94: Constructing Kinetics test...
path: ---------------------------- /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/test.csv
[12/17 16:45:46][INFO] kinetics.py:  172: Constructing kinetics dataloader (size: 2250 skip_rows 0) from /mnt/SSD8T/home/huangwei/projects/FROSTER/zs_label_db/B2N_hmdb/test.csv 
[12/17 16:45:46][INFO] test_net.py:  434: Testing model for 10 iterations
img_encode shape: torch.Size([480, 512]),bz: 60,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([60, 512])
[12/17 16:46:14][INFO] logging.py:   99: json_stats: {"cur_iter": "1", "eta": "0:04:35", "split": "test_iter", "time_diff": 27.54460135}
img_encode shape: torch.Size([480, 512]),bz: 60,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([60, 512])
[12/17 16:46:15][INFO] logging.py:   99: json_stats: {"cur_iter": "2", "eta": "0:00:09", "split": "test_iter", "time_diff": 1.06703937}
img_encode shape: torch.Size([480, 512]),bz: 60,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([60, 512])
[12/17 16:46:16][INFO] logging.py:   99: json_stats: {"cur_iter": "3", "eta": "0:00:07", "split": "test_iter", "time_diff": 0.98798589}
img_encode shape: torch.Size([480, 512]),bz: 60,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([60, 512])
[12/17 16:46:17][INFO] logging.py:   99: json_stats: {"cur_iter": "4", "eta": "0:00:06", "split": "test_iter", "time_diff": 0.98715500}
img_encode shape: torch.Size([480, 512]),bz: 60,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([60, 512])
[12/17 16:46:18][INFO] logging.py:   99: json_stats: {"cur_iter": "5", "eta": "0:00:05", "split": "test_iter", "time_diff": 0.97906067}
img_encode shape: torch.Size([480, 512]),bz: 60,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([60, 512])
[12/17 16:46:19][INFO] logging.py:   99: json_stats: {"cur_iter": "6", "eta": "0:00:04", "split": "test_iter", "time_diff": 0.98749655}
img_encode shape: torch.Size([480, 512]),bz: 60,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([60, 512])
[12/17 16:46:20][INFO] logging.py:   99: json_stats: {"cur_iter": "7", "eta": "0:00:03", "split": "test_iter", "time_diff": 0.99583277}
img_encode shape: torch.Size([480, 512]),bz: 60,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([60, 512])
[12/17 16:46:21][INFO] logging.py:   99: json_stats: {"cur_iter": "8", "eta": "0:00:02", "split": "test_iter", "time_diff": 0.98834211}
img_encode shape: torch.Size([480, 512]),bz: 60,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([60, 512])
[12/17 16:46:22][INFO] logging.py:   99: json_stats: {"cur_iter": "9", "eta": "0:00:01", "split": "test_iter", "time_diff": 0.98763123}
img_encode shape: torch.Size([184, 512]),bz: 23,clip_len: 8
meanpooling in forward,on img_encode,after:img_encode shape:torch.Size([23, 512])
[12/17 16:46:22][INFO] logging.py:   99: json_stats: {"cur_iter": "10", "eta": "0:00:00", "split": "test_iter", "time_diff": 0.48371913}
clip count Ids=tensor([[14, 53]]) = tensor([4, 4]) (should be 3)
clip count Ids=tensor([[14, 53]]) = tensor([4, 4]) (should be 3)
[12/17 16:46:23][WARNING] meters.py:  394: clip count Ids=tensor([[14, 53]]) = tensor([4, 4]) (should be 3)
[12/17 16:46:23][INFO] logging.py:   99: json_stats: {"split": "test_final", "top1_acc": "9.20", "top5_acc": "22.27"}
[12/17 16:46:23][INFO] test_net.py:  474: Finalized testing with 3 temporal clips and 1 spatial crops
[12/17 16:46:23][INFO] test_net.py:  496: _p300.29_f10.00_3a9.20 Top5 Acc: 22.27 MEM: 12.39 f: 10.0000
[12/17 16:46:23][INFO] test_net.py:  497: _p300.29_f10.00_3a9.20
clip count Ids=tensor([[14, 53]]) = tensor([4, 4]) (should be 3)
